{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmF6meTcCjxCa7yoKc7Efg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivoryRabbit/RecSys/blob/master/RBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d3ATkemqT_T"
      },
      "source": [
        "import glob\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from typing import Callable, Tuple, List\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.data import Dataset\r\n",
        "from tensorflow.keras.utils import get_file\r\n",
        "import zipfile"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NvMYwO6xFda"
      },
      "source": [
        "def load_data(data_size: str) -> pd.DataFrame:\r\n",
        "    ''' load Movie Lens data '''\r\n",
        "\r\n",
        "    if data_size == '1m':\r\n",
        "        fname = 'ml-1m.zip'\r\n",
        "        data = 'ml-1m/ratings.dat'\r\n",
        "    elif data_size == '10m':\r\n",
        "        fname = 'ml-10m.zip'\r\n",
        "        data = 'ml-10M100K/ratings.dat'\r\n",
        "    elif data_size == '20m':\r\n",
        "        fname = 'ml-20m.zip'\r\n",
        "        data = 'ml-20m/ratings.csv'\r\n",
        "    elif data_size == '25m':\r\n",
        "        fname = 'ml-25m.zip'\r\n",
        "        data = 'ml-25m/ratings.csv'\r\n",
        "    if not glob.glob(data):\r\n",
        "        origin = f'http://files.grouplens.org/datasets/movielens/{fname}'\r\n",
        "        file = get_file(fname, origin)\r\n",
        "        zip_ref = zipfile.ZipFile(file, 'r')\r\n",
        "        zip_ref.extractall()\r\n",
        "\r\n",
        "    col_names = ['userId', 'movieId', 'rating', 'timestamp']\r\n",
        "    if data_size in ['20m', '25m']:\r\n",
        "        ratings = pd.read_csv(data, engine = 'python')\r\n",
        "    else:\r\n",
        "        ratings = pd.read_csv(data, sep = '|', delimiter = '::', names = col_names, engine = 'python')\r\n",
        "    print(ratings.shape)\r\n",
        "    return ratings"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "LHq7j79rxKYw",
        "outputId": "0744976b-8903-4d38-f41e-82a4b496f3a2"
      },
      "source": [
        "ratings = load_data('1m')\r\n",
        "ratings.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "5922816/5917549 [==============================] - 0s 0us/step\n",
            "(1000209, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1     1193       5  978300760\n",
              "1       1      661       3  978302109\n",
              "2       1      914       3  978301968\n",
              "3       1     3408       4  978300275\n",
              "4       1     2355       5  978824291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hln0Sfk9x1Zj",
        "outputId": "46414b07-b5d7-4504-90bc-fcb083207997"
      },
      "source": [
        "n_user = ratings.userId.nunique()\r\n",
        "n_item = ratings.movieId.nunique()\r\n",
        "\r\n",
        "print('# of user: ', n_user)\r\n",
        "print('# of item: ', n_item)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of user:  6040\n",
            "# of item:  3706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aQE0lI5zF8Q"
      },
      "source": [
        "user_rating = ratings.pivot(index = 'userId', columns = 'movieId', values = 'rating')\r\n",
        "norm_user_rating = user_rating.fillna(0) / 5.0\r\n",
        "\r\n",
        "X = norm_user_rating.values.astype(np.float32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjW4kaLqqZoU"
      },
      "source": [
        "X_train, X_test = train_test_split(X, test_size = 0.2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e-GFnj_9U1y"
      },
      "source": [
        "class RBM(tf.keras.Model):\r\n",
        "    def __init__(\r\n",
        "        self, \r\n",
        "        n_visible,\r\n",
        "        n_hidden,\r\n",
        "        learning_rate = 1e-2,\r\n",
        "        momentum = 0.9,\r\n",
        "        gamma = 1e-2,\r\n",
        "        n_cd_step = 1\r\n",
        "    ):\r\n",
        "        super(RBM, self).__init__()\r\n",
        "\r\n",
        "        self.n_visible = n_visible\r\n",
        "        self.n_hidden = n_hidden\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.momentum = momentum\r\n",
        "        self.gamma = gamma\r\n",
        "        self.n_cd_step = n_cd_step\r\n",
        "\r\n",
        "        self.W = tf.Variable(tf.random.normal(\r\n",
        "            shape = (self.n_visible, self.n_hidden),\r\n",
        "            mean = 0.0, \r\n",
        "            stddev = 1.0 / self.n_visible\r\n",
        "        ))\r\n",
        "        self.B_v = tf.Variable(tf.zeros(shape = (self.n_visible, )))\r\n",
        "        self.B_h = tf.Variable(tf.zeros(shape = (self.n_hidden, )))\r\n",
        "\r\n",
        "    def init_moment(self):\r\n",
        "        self.dW = tf.zeros(shape = tf.shape(self.W))\r\n",
        "        self.dB_v = tf.zeros(shape = tf.shape(self.B_v))\r\n",
        "        self.dB_h = tf.zeros(shape = tf.shape(self.B_h))\r\n",
        "\r\n",
        "    def get_hidden_prob(self, v):\r\n",
        "        logit_h = tf.matmul(v, self.W) + self.B_h\r\n",
        "        return tf.nn.sigmoid(logit_h)\r\n",
        "    \r\n",
        "    def get_visible_prob(self, h):\r\n",
        "        logit_v = tf.matmul(h, tf.transpose(self.W)) + self.B_v\r\n",
        "        return tf.nn.sigmoid(logit_v)\r\n",
        "\r\n",
        "    def get_white_noise(self, shape):\r\n",
        "        return tf.random.normal(shape, 0.0, 1e-2)\r\n",
        "    \r\n",
        "    def get_hidden_sample(self, v, std = 1.0):\r\n",
        "        logit_h = tf.matmul(v, self.W) + self.B_h\r\n",
        "        noise = self.get_white_noise(tf.shape(logit_h))\r\n",
        "        return tf.nn.sigmoid(logit_h + std * noise)\r\n",
        "\r\n",
        "    def get_visible_sample(self, h, std = 1.0):\r\n",
        "        logit_v = tf.matmul(h, tf.transpose(self.W)) + self.B_v\r\n",
        "        noise = self.get_white_noise(tf.shape(logit_v))\r\n",
        "        return tf.nn.sigmoid(logit_v + std * noise)\r\n",
        "\r\n",
        "    def energy(self, v, h):\r\n",
        "        e1 = -tf.einsum('ni,ij,nj->n', v, self.W, h)\r\n",
        "        e2 = -tf.einsum('i,ni->n', self.B_v, v)\r\n",
        "        e3 = -tf.einsum('j,nj->n', self.B_h, h)\r\n",
        "        return tf.reduce_mean(e1 + e2 + e3)\r\n",
        "\r\n",
        "    def free_energy(self, v):\r\n",
        "        e1 = -tf.einsum('i,ni->n', self.B_v, v)\r\n",
        "        e2 = tf.math.log(1 + tf.math.exp(tf.matmul(v, self.W) + self.B_h))\r\n",
        "        e2 = -tf.math.reduce_sum(e2, axis = -1)\r\n",
        "        return (e1 + e2).numpy()\r\n",
        "\r\n",
        "    def get_grad_energy(self, v, h):\r\n",
        "        dW_dE = tf.einsum('ni,nj->ij', v, h)\r\n",
        "        dB_v_dE = tf.math.reduce_sum(v, axis = 0)\r\n",
        "        dB_h_dE = tf.math.reduce_sum(h, axis = 0)\r\n",
        "        return (dW_dE, dB_v_dE, dB_h_dE)\r\n",
        "\r\n",
        "    def gibbs_sampling(self, v):\r\n",
        "        neg_v = tf.identity(v)\r\n",
        "        for _ in range(self.n_cd_step):\r\n",
        "            neg_h = self.get_hidden_sample(neg_v)\r\n",
        "            neg_v = self.get_visible_sample(neg_h)\r\n",
        "        return neg_v\r\n",
        "\r\n",
        "    def train_one_step(self, pos_v): # Contrastive Divergence\r\n",
        "        pos_h = self.get_hidden_prob(pos_v)\r\n",
        "        neg_v = self.gibbs_sampling(pos_v)\r\n",
        "        neg_h = self.get_hidden_prob(neg_v)\r\n",
        "\r\n",
        "        pos_W, pos_B_v, pos_B_h = self.get_grad_energy(pos_v, pos_h)\r\n",
        "        neg_W, neg_B_v, neg_B_h = self.get_grad_energy(neg_v, neg_h)\r\n",
        "\r\n",
        "        lr = self.learning_rate / pos_v.shape[0]\r\n",
        "        self.dW = self.momentum * self.dW \\\r\n",
        "            + lr * (pos_W - neg_W - self.gamma * self.W)\r\n",
        "        self.dB_v = self.momentum * self.dB_v \\\r\n",
        "            + lr * (pos_B_v - neg_B_v - self.gamma * self.B_v)\r\n",
        "        self.dB_h = self.momentum * self.dB_h \\\r\n",
        "            + lr * (pos_B_h - neg_B_h - self.gamma * self.B_h)\r\n",
        "\r\n",
        "        # update\r\n",
        "        self.W = self.W.assign_add(self.dW)\r\n",
        "        self.B_v = self.B_v.assign_add(self.dB_v)\r\n",
        "        self.B_h = self.B_h.assign_add(self.dB_h)\r\n",
        "\r\n",
        "        score = tf.keras.losses.mse(\r\n",
        "            self.free_energy(pos_v),\r\n",
        "            self.free_energy(neg_v)\r\n",
        "        )\r\n",
        "        return tf.math.sqrt(score).numpy()\r\n",
        "\r\n",
        "    def train(self, X, batch_size, epochs):\r\n",
        "        X_train = Dataset.from_tensor_slices(X)\r\n",
        "        for epoch in range(epochs):\r\n",
        "            X_batch = X_train.shuffle(batch_size).batch(batch_size)\r\n",
        "            \r\n",
        "            self.init_moment()\r\n",
        "            for batch in X_batch:\r\n",
        "                score = self.train_one_step(batch)\r\n",
        "\r\n",
        "            if (epoch+1) % 10 == 0:\r\n",
        "                print(f'epoch: {epoch+1:>3}, score: {score:.3f}')\r\n",
        "\r\n",
        "    def transform(self, v):\r\n",
        "        return self.get_hidden_prob(v).numpy()\r\n",
        "\r\n",
        "    def predict(self, v):\r\n",
        "        h = self.get_hidden_prob(v)\r\n",
        "        return self.get_visible_prob(h).numpy()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLkbxf-mxrqX"
      },
      "source": [
        "n_visible = n_item\r\n",
        "n_hidden = 512\r\n",
        "learning_rate = 1e-2\r\n",
        "\r\n",
        "rbm = RBM(n_visible, n_hidden, learning_rate, gamma = 0.01)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_3RPgOOnr0o",
        "outputId": "bacc2867-558f-478e-9631-db82d30e706b"
      },
      "source": [
        "%%time\r\n",
        "batch_size = 258\r\n",
        "epochs = 500\r\n",
        "\r\n",
        "rbm.train(X_train, batch_size, epochs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  10, score: 142.751\n",
            "epoch:  20, score: 69.630\n",
            "epoch:  30, score: 54.482\n",
            "epoch:  40, score: 42.146\n",
            "epoch:  50, score: 35.503\n",
            "epoch:  60, score: 37.950\n",
            "epoch:  70, score: 35.729\n",
            "epoch:  80, score: 29.421\n",
            "epoch:  90, score: 33.277\n",
            "epoch: 100, score: 30.596\n",
            "epoch: 110, score: 29.257\n",
            "epoch: 120, score: 28.852\n",
            "epoch: 130, score: 25.651\n",
            "epoch: 140, score: 25.961\n",
            "epoch: 150, score: 24.625\n",
            "epoch: 160, score: 26.502\n",
            "epoch: 170, score: 23.915\n",
            "epoch: 180, score: 25.666\n",
            "epoch: 190, score: 23.853\n",
            "epoch: 200, score: 24.223\n",
            "epoch: 210, score: 23.260\n",
            "epoch: 220, score: 24.113\n",
            "epoch: 230, score: 22.170\n",
            "epoch: 240, score: 23.823\n",
            "epoch: 250, score: 22.133\n",
            "epoch: 260, score: 21.480\n",
            "epoch: 270, score: 21.456\n",
            "epoch: 280, score: 24.668\n",
            "epoch: 290, score: 22.699\n",
            "epoch: 300, score: 22.640\n",
            "epoch: 310, score: 22.977\n",
            "epoch: 320, score: 22.807\n",
            "epoch: 330, score: 21.336\n",
            "epoch: 340, score: 21.671\n",
            "epoch: 350, score: 22.385\n",
            "epoch: 360, score: 21.095\n",
            "epoch: 370, score: 21.977\n",
            "epoch: 380, score: 20.217\n",
            "epoch: 390, score: 22.415\n",
            "epoch: 400, score: 24.682\n",
            "epoch: 410, score: 22.991\n",
            "epoch: 420, score: 21.396\n",
            "epoch: 430, score: 21.063\n",
            "epoch: 440, score: 22.512\n",
            "epoch: 450, score: 24.154\n",
            "epoch: 460, score: 22.819\n",
            "epoch: 470, score: 22.234\n",
            "epoch: 480, score: 25.354\n",
            "epoch: 490, score: 20.122\n",
            "epoch: 500, score: 23.276\n",
            "CPU times: user 1min 42s, sys: 4.25 s, total: 1min 46s\n",
            "Wall time: 1min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nErGD-gdTMJ_",
        "outputId": "5710eff5-cdc4-4b83-991c-e7a25d0bea95"
      },
      "source": [
        "pred = rbm.predict(X_test)\r\n",
        "\r\n",
        "rmse = np.mean(np.sqrt(np.mean(np.square(X_test - pred), axis = -1)))\r\n",
        "print(rmse)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.085405126\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}