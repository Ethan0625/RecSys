{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepAutoRec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viikY8IQdVTY",
        "colab_type": "text"
      },
      "source": [
        "# DeepAutoRec\n",
        "\n",
        "- [Training Deep AutoEncoders for Collaborative Filtering](https://arxiv.org/pdf/1708.01715.pdf)\n",
        "\n",
        "## Experiment\n",
        "\n",
        "- Relation of latent dimension and the size of data\n",
        "    - For small size of data, too large latent dimension makes it overfitting\n",
        "- Going deeper increases the capacity of model\n",
        "- Dropout rate?\n",
        "- Re-feeding?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8FDcw4rVboe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Callable, Tuple\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('bmh')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Reshape, Dense, Dropout, Layer, Subtract\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.initializers import TruncatedNormal, RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.utils import get_file\n",
        "import zipfile"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdjqodyYVf9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data_size : str) -> pd.DataFrame:\n",
        "    ''' load Movie Lens data '''\n",
        "    if data_size == '100k':\n",
        "        file = get_file('ml-100k.zip', 'http://files.grouplens.org/datasets/movielens/ml-100k.zip')\n",
        "        file_name = 'ml-100k/*'\n",
        "    elif data_size == '1m':\n",
        "        file = get_file('ml-1m.zip', 'http://files.grouplens.org/datasets/movielens/ml-1m.zip')\n",
        "        file_name = 'ml-1m/ratings.dat'\n",
        "    elif data_size == '10m':\n",
        "        file = get_file('ml-10m.zip', 'http://files.grouplens.org/datasets/movielens/ml-10m.zip')\n",
        "        file_name = 'ml-10M100K/ratings.dat'\n",
        "    elif data_size == '20m':\n",
        "        file = get_file('ml-20m.zip', 'http://files.grouplens.org/datasets/movielens/ml-20m.zip')\n",
        "        file_name = 'ml-20m/ratings.csv'\n",
        "    zip_ref = zipfile.ZipFile(file, 'r')\n",
        "    zip_ref.extractall()\n",
        "\n",
        "    col_names = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "    ratings = pd.read_csv(file_name, sep = '|', delimiter = '::', names = col_names, engine = 'python')\n",
        "    print(ratings.shape)\n",
        "    return ratings"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZf8Gzf0VhYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "04e02e24-50f5-45c1-f106-ee2a16014918"
      },
      "source": [
        "ratings = load_data('1m')\n",
        "ratings.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000209, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1     1193       5  978300760\n",
              "1       1      661       3  978302109\n",
              "2       1      914       3  978301968\n",
              "3       1     3408       4  978300275\n",
              "4       1     2355       5  978824291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGuhgUB67uKF",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q61otQWA3tFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef11ce13-2ffa-4836-85b3-4a579469b792"
      },
      "source": [
        "idx_user_map = ratings.userId.unique()\n",
        "user_idx_map = {e: i for i, e in enumerate(idx_user_map)}\n",
        "n_user = idx_user_map.shape[0]\n",
        "print(n_user)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EMat5wW3nCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97613d2c-f120-4326-e994-b6e2efd9eb76"
      },
      "source": [
        "idx_item_map = ratings.movieId.unique()\n",
        "item_idx_map = {e: i for i, e in enumerate(idx_item_map)}\n",
        "n_item = idx_item_map.shape[0]\n",
        "print(n_item)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJvVnvKX3uNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Id2idx(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.assign(userId = lambda x: x.userId.map(user_idx_map), \n",
        "                     movieId = lambda x: x.movieId.map(item_idx_map))\n",
        "\n",
        "def idx2Id(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.assign(userId = lambda x: x.userId.apply(lambda x: idx_user_map[x]), \n",
        "                     movieId = lambda x: x.movieId.apply(lambda x: idx_item_map[x]))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS1B1fPw3whx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4dc4eb0e-3723-4877-e29d-9c2954cb865a"
      },
      "source": [
        "ratings = Id2idx(ratings)\n",
        "ratings.head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       0        0       5  978300760\n",
              "1       0        1       3  978302109\n",
              "2       0        2       3  978301968\n",
              "3       0        3       4  978300275\n",
              "4       0        4       5  978824291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PTNottGHBv1p",
        "colab": {}
      },
      "source": [
        "def make_interaction(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.groupby('userId', as_index = False)[['movieId', 'rating']].agg(list)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO0a_3NEFstw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_split(df: pd.DataFrame, test_size = 0.1) -> pd.DataFrame:\n",
        "    timeorder = df.groupby(by = 'userId')['timestamp'].rank(method = 'first', ascending = True)\n",
        "    seen_cnt = df.groupby(by = 'userId', as_index = False)['movieId'].agg('count').rename(columns = {'movieId': 'cnts'})\n",
        "\n",
        "    df = df.merge(seen_cnt, how = 'left', on = 'userId')\n",
        "    df = df.assign(timeorder = timeorder)\n",
        "    df = df.assign(split_type = lambda x: np.where(x.timeorder > x.cnts * test_size, 'train', 'test')) # 시간을 기준으로 train과 valid&test 분할\n",
        "\n",
        "    train = df[df.split_type == 'train']\n",
        "    test = df[df.split_type == 'test']\n",
        "    \n",
        "    valid, test = train_test_split(test, test_size = 0.5, random_state = 7777)\n",
        "    valid, test = map(lambda df: df[df.userId.isin(train.userId.unique()) & df.movieId.isin(train.movieId.unique())], (valid, test)) # train에 속하지 않는 user 및 movie 삭제\n",
        "\n",
        "    train, valid, test = map(lambda df: df.reset_index(drop = True), (train, valid, test))\n",
        "    train, valid, test = map(lambda df: df.drop(columns = ['cnts', 'timeorder', 'split_type']), (train, valid, test))\n",
        "\n",
        "    return train, valid, test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZLAac2E-Bv1u",
        "colab": {}
      },
      "source": [
        "def make_generator(df: pd.DataFrame,\n",
        "                   n_item: int,\n",
        "                   batch_size: int,\n",
        "                   implicit = False,\n",
        "                   threshold = 3.5,\n",
        "                   refeed = True) -> Tuple[np.array, Tuple[np.array, np.array]]:\n",
        "\n",
        "    n_row = df.index.size\n",
        "    n_col = n_item\n",
        "\n",
        "    Ids = np.arange(n_row)\n",
        "    profiles = df['movieId']\n",
        "    ratings = df['rating'] if not implicit else df['rating'].apply(lambda x: [1 if r > threshold else 0 for r in x])\n",
        "\n",
        "    n_batch = int(np.ceil(n_row / batch_size))\n",
        "    while True:\n",
        "        np.random.shuffle(Ids)\n",
        "        \n",
        "        for batch_step in range(n_batch):\n",
        "            lower = batch_step * batch_size\n",
        "            upper = lower + batch_size\n",
        "            \n",
        "            batch_Id = Ids[lower: upper]\n",
        "            batch = np.zeros(shape = (batch_Id.size, n_col))\n",
        "            for i, idx in enumerate(batch_Id):\n",
        "                batch[i, profiles[idx]] = ratings[idx]\n",
        "            \n",
        "            zeros = np.zeros(shape = (batch_Id.size, n_col))\n",
        "            if refeed:\n",
        "                yield batch, (batch, zeros)\n",
        "            else:\n",
        "                yield batch, batch"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nNPv41eMBv1v",
        "colab": {}
      },
      "source": [
        "def mse(y_true: np.array, y_pred: np.array) -> np.array:\n",
        "    se = K.square(y_true - y_pred)\n",
        "    return K.mean(se, axis = -1)\n",
        "\n",
        "def rmse(y_true: np.array, y_pred: np.array) -> np.array:\n",
        "    se = K.square(y_true - y_pred)\n",
        "    return K.sqrt(K.mean(se, axis = -1))\n",
        "    \n",
        "def masked_mse(y_true: np.array, y_pred: np.array, masked_value = 0) -> np.array:\n",
        "    mask_true = K.cast(K.not_equal(y_true, masked_value), dtype = 'float32')\n",
        "    masked_se = K.square(mask_true * (y_true - y_pred))\n",
        "    return K.sum(masked_se, axis = -1) / K.sum(mask_true, axis = -1)\n",
        "\n",
        "def masked_rmse(y_true: np.array, y_pred: np.array, masked_value = 0) -> np.array:\n",
        "    mask_true = K.cast(K.not_equal(y_true, masked_value), dtype = 'float32')\n",
        "    masked_se = K.square(mask_true * (y_true - y_pred))\n",
        "    masked_mse = K.sum(masked_se, axis = -1) / K.sum(mask_true, axis = -1)\n",
        "    return K.sqrt(masked_mse)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcXGIVs7PtdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DeepAutoRec(n_item: int, \n",
        "                n_layer = 3,\n",
        "                latent_dim = 1024,\n",
        "                activation = 'selu', \n",
        "                optimizer = 'adam', \n",
        "                learning_rate = 0.001,\n",
        "                kernel_initializer = None,\n",
        "                kernel_regularizer = None, \n",
        "                dropout_rate = 0.8,\n",
        "                refeed = True) -> Callable:\n",
        "\n",
        "    if not kernel_initializer:\n",
        "        kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.05, seed = None)\n",
        "    if not kernel_regularizer:\n",
        "        kernel_regularizer = l2(0.0001)\n",
        "    \n",
        "    input_shape = n_item\n",
        "\n",
        "    # encoder\n",
        "    encoders = []\n",
        "    for i in range(n_layer-1):\n",
        "        encoders.append(Dense(latent_dim // 2, activation = activation, kernel_initializer = kernel_initializer, kernel_regularizer = kernel_regularizer, name = f'encoder_{i+1}'))\n",
        "    encoders.append(Dense(latent_dim, activation = activation, kernel_initializer = kernel_initializer, kernel_regularizer = kernel_regularizer, name = f'encoder_{n_layer}'))\n",
        "\n",
        "    # decoder\n",
        "    decoders = []\n",
        "    for i in range(n_layer-1):\n",
        "        decoders.append(Dense(latent_dim // 2, activation = activation, kernel_initializer = kernel_initializer, kernel_regularizer = kernel_regularizer, name = f'decoder_{i+1}'))\n",
        "    decoders.append(Dense(input_shape, activation = activation, kernel_initializer = kernel_initializer, kernel_regularizer = kernel_regularizer, name = f'decoder_{n_layer}'))\n",
        "\n",
        "    # forward propagate\n",
        "    inputs = x = Input(shape = (input_shape, ), name = 'input')\n",
        "    for i in range(n_layer):\n",
        "        x = encoders[i](x)\n",
        "    x = Dropout(dropout_rate, name = 'dropout')(x)\n",
        "\n",
        "    for i in range(n_layer):\n",
        "        x = decoders[i](x)\n",
        "    outputs = y = Layer(name = 'output')(x)\n",
        "    \n",
        "    # re-feeding\n",
        "    if refeed:\n",
        "        for i in range(n_layer):\n",
        "            y = encoders[i](y)\n",
        "\n",
        "        for i in range(n_layer):\n",
        "            y = decoders[i](y)\n",
        "        refeeded = Subtract(name = 'refeeded')([outputs, y]) # f(x) - f(f(x))\n",
        "\n",
        "        model = Model(inputs = [inputs], outputs = [outputs, refeeded])\n",
        "        model.compile(optimizer = optimizer, loss = {'output': masked_mse, 'refeeded': mse}, loss_weights = [0.8, 0.2], metrics = {'output': masked_rmse, 'refeeded': rmse})\n",
        "    \n",
        "    else:\n",
        "        model = Model(inputs = inputs, outputs = outputs)\n",
        "        model.compile(optimizer = optimizer, loss = masked_mse, metrics = masked_rmse)\n",
        "    return model"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwvA4hA0Ja34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predictor(df: pd.DataFrame, \n",
        "                   model: Callable, \n",
        "                   n_item: int, \n",
        "                   batch_size: int, \n",
        "                   implicit = False, \n",
        "                   threshold = 3.5,\n",
        "                   refeed = True) -> float:\n",
        "\n",
        "    n_row = df.index.size\n",
        "    n_col = n_item\n",
        "\n",
        "    Ids = np.arange(n_row)\n",
        "    profiles = df['movieId']\n",
        "    ratings = df['rating'] if not implicit else df['rating'].apply(lambda x: [1 if r > threshold else 0 for r in x])\n",
        "\n",
        "    res: float = 0.0\n",
        "    N: int = 0\n",
        "    steps = int(np.ceil(n_row / batch_size))\n",
        "    for batch_step in range(steps):\n",
        "        lower = batch_step * batch_size\n",
        "        upper = lower + batch_size\n",
        "\n",
        "        batch_Id = Ids[lower: upper]\n",
        "        y_true = np.zeros(shape = (batch_Id.size, n_col))\n",
        "        for i, idx in enumerate(batch_Id):\n",
        "            y_true[i, profiles[idx]] = ratings[idx]\n",
        "\n",
        "        if refeed:\n",
        "            y_pred = model.predict(y_true, verbose = 0)[0]\n",
        "        else:\n",
        "            y_pred = model.predict(y_true, verbose = 0)\n",
        "\n",
        "        res += np.sum(masked_rmse(y_true, y_pred).numpy())\n",
        "        N += batch_Id.size\n",
        "    return res / N"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2quTiHQJlpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_history(hist, loss: str, metric: str) -> None:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 4))\n",
        "\n",
        "    ax1.plot(hist.history[f'{loss}'])\n",
        "    ax1.plot(hist.history[f'val_{loss}'])\n",
        "    ax1.set_title('Loss', fontsize = 20)\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_xlabel('epoch')\n",
        "    ax1.legend(['loss', 'val_loss'], loc = 'upper right')\n",
        "\n",
        "    ax2.plot(hist.history[f'{metric}'])\n",
        "    ax2.plot(hist.history[f'val_{metric}'])\n",
        "    ax2.set_title('Metric', fontsize = 20)\n",
        "    ax2.set_ylabel('metric')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['masked_rmse', 'val_masked_rmse'], loc = 'upper right')\n",
        "    plt.show()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZc_fV0DmRA",
        "colab_type": "text"
      },
      "source": [
        "## 2. Vanilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hc2ipkeeHy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 500\n",
        "batch_size = 128\n",
        "\n",
        "train, valid, test = data_split(ratings)\n",
        "train, valid, test = map(make_interaction, (train, valid, test))\n",
        "train_gen, valid_gen = map(lambda x: make_generator(x, n_item, batch_size, refeed = False), (train, valid))\n",
        "\n",
        "steps_per_epoch = train.index.size // batch_size + 1\n",
        "validation_steps = valid.index.size // batch_size + 1"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXapzZTTBv13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "7ec145c3-d19e-4beb-a2a5-29677ba8ecda"
      },
      "source": [
        "# optimizer = SGD(lr = 0.001, decay = 1e-5, momentum = 0.9, nesterov = True)\n",
        "optimizer = Adam(learning_rate = 0.001, decay = 1e-5)\n",
        "model = DeepAutoRec(n_item, n_layer = 2, latent_dim = 512, optimizer = optimizer, dropout_rate = 0.0, refeed = False)\n",
        "model.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3706)]            0         \n",
            "_________________________________________________________________\n",
            "encoder_1 (Dense)            (None, 256)               948992    \n",
            "_________________________________________________________________\n",
            "encoder_2 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "decoder_1 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "decoder_2 (Dense)            (None, 3706)              952442    \n",
            "_________________________________________________________________\n",
            "output (Layer)               (None, 3706)              0         \n",
            "=================================================================\n",
            "Total params: 2,164,346\n",
            "Trainable params: 2,164,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OBjwW0pQBv16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95a81d4b-6d3d-4485-d2f5-4b28e107b139"
      },
      "source": [
        "%%time\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 50)\n",
        "model_checkpoint = ModelCheckpoint('DeepAutoRec_1M.h5', monitor = 'val_loss', mode = 'min', save_best_only = True)\n",
        "\n",
        "hist = model.fit(x = train_gen, validation_data = valid_gen, epochs = epochs,\n",
        "                 steps_per_epoch = steps_per_epoch, validation_steps = validation_steps, \n",
        "                 verbose = 1, callbacks = [early_stopping, model_checkpoint])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 1/48 [..............................] - ETA: 0s - loss: 16.5926 - masked_rmse: 3.9848WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_train_batch_end` time: 0.0121s). Check your callbacks.\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 3.9883 - masked_rmse: 1.6479 - val_loss: 2.5380 - val_masked_rmse: 1.2783\n",
            "Epoch 2/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 1.5043 - masked_rmse: 0.9948 - val_loss: 2.6557 - val_masked_rmse: 1.3201\n",
            "Epoch 3/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 1.3813 - masked_rmse: 0.9477 - val_loss: 2.8353 - val_masked_rmse: 1.3819\n",
            "Epoch 4/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 1.2640 - masked_rmse: 0.8987 - val_loss: 2.7486 - val_masked_rmse: 1.3570\n",
            "Epoch 5/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 1.1626 - masked_rmse: 0.8525 - val_loss: 2.7902 - val_masked_rmse: 1.3848\n",
            "Epoch 6/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 1.0679 - masked_rmse: 0.8067 - val_loss: 2.8912 - val_masked_rmse: 1.4118\n",
            "Epoch 7/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.9953 - masked_rmse: 0.7702 - val_loss: 2.7726 - val_masked_rmse: 1.3869\n",
            "Epoch 8/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.9295 - masked_rmse: 0.7346 - val_loss: 2.5582 - val_masked_rmse: 1.3256\n",
            "Epoch 9/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.8676 - masked_rmse: 0.6996 - val_loss: 2.5466 - val_masked_rmse: 1.3281\n",
            "Epoch 10/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.8251 - masked_rmse: 0.6752 - val_loss: 2.3659 - val_masked_rmse: 1.2770\n",
            "Epoch 11/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.7808 - masked_rmse: 0.6495 - val_loss: 2.3248 - val_masked_rmse: 1.2656\n",
            "Epoch 12/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.7399 - masked_rmse: 0.6243 - val_loss: 2.2578 - val_masked_rmse: 1.2503\n",
            "Epoch 13/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.7026 - masked_rmse: 0.6013 - val_loss: 2.2059 - val_masked_rmse: 1.2376\n",
            "Epoch 14/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.6739 - masked_rmse: 0.5836 - val_loss: 2.2258 - val_masked_rmse: 1.2455\n",
            "Epoch 15/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.6426 - masked_rmse: 0.5642 - val_loss: 2.1595 - val_masked_rmse: 1.2249\n",
            "Epoch 16/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.6215 - masked_rmse: 0.5511 - val_loss: 2.0681 - val_masked_rmse: 1.1979\n",
            "Epoch 17/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.5989 - masked_rmse: 0.5370 - val_loss: 2.0112 - val_masked_rmse: 1.1811\n",
            "Epoch 18/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.5783 - masked_rmse: 0.5248 - val_loss: 2.0239 - val_masked_rmse: 1.1900\n",
            "Epoch 19/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.5550 - masked_rmse: 0.5094 - val_loss: 2.0002 - val_masked_rmse: 1.1831\n",
            "Epoch 20/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.5431 - masked_rmse: 0.5027 - val_loss: 1.9481 - val_masked_rmse: 1.1673\n",
            "Epoch 21/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.5247 - masked_rmse: 0.4904 - val_loss: 1.9830 - val_masked_rmse: 1.1817\n",
            "Epoch 22/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.5041 - masked_rmse: 0.4756 - val_loss: 1.9042 - val_masked_rmse: 1.1551\n",
            "Epoch 23/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.4926 - masked_rmse: 0.4686 - val_loss: 1.9001 - val_masked_rmse: 1.1580\n",
            "Epoch 24/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.4819 - masked_rmse: 0.4631 - val_loss: 1.8273 - val_masked_rmse: 1.1307\n",
            "Epoch 25/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.4719 - masked_rmse: 0.4577 - val_loss: 1.8016 - val_masked_rmse: 1.1212\n",
            "Epoch 26/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.4603 - masked_rmse: 0.4497 - val_loss: 1.8091 - val_masked_rmse: 1.1267\n",
            "Epoch 27/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.4521 - masked_rmse: 0.4456 - val_loss: 1.8225 - val_masked_rmse: 1.1350\n",
            "Epoch 28/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.4453 - masked_rmse: 0.4423 - val_loss: 1.7351 - val_masked_rmse: 1.1067\n",
            "Epoch 29/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.4324 - masked_rmse: 0.4334 - val_loss: 1.7371 - val_masked_rmse: 1.1027\n",
            "Epoch 30/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.4230 - masked_rmse: 0.4257 - val_loss: 1.6661 - val_masked_rmse: 1.0820\n",
            "Epoch 31/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.4121 - masked_rmse: 0.4183 - val_loss: 1.7007 - val_masked_rmse: 1.0941\n",
            "Epoch 32/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.4031 - masked_rmse: 0.4111 - val_loss: 1.6691 - val_masked_rmse: 1.0846\n",
            "Epoch 33/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3952 - masked_rmse: 0.4054 - val_loss: 1.6803 - val_masked_rmse: 1.0874\n",
            "Epoch 34/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3923 - masked_rmse: 0.4054 - val_loss: 1.6211 - val_masked_rmse: 1.0641\n",
            "Epoch 35/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3884 - masked_rmse: 0.4040 - val_loss: 1.6242 - val_masked_rmse: 1.0713\n",
            "Epoch 36/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3863 - masked_rmse: 0.4049 - val_loss: 1.6330 - val_masked_rmse: 1.0731\n",
            "Epoch 37/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3842 - masked_rmse: 0.4050 - val_loss: 1.6215 - val_masked_rmse: 1.0704\n",
            "Epoch 38/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3761 - masked_rmse: 0.3991 - val_loss: 1.5477 - val_masked_rmse: 1.0446\n",
            "Epoch 39/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3718 - masked_rmse: 0.3967 - val_loss: 1.5681 - val_masked_rmse: 1.0474\n",
            "Epoch 40/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3679 - masked_rmse: 0.3930 - val_loss: 1.4935 - val_masked_rmse: 1.0211\n",
            "Epoch 41/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3586 - masked_rmse: 0.3855 - val_loss: 1.5380 - val_masked_rmse: 1.0417\n",
            "Epoch 42/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3548 - masked_rmse: 0.3815 - val_loss: 1.5113 - val_masked_rmse: 1.0278\n",
            "Epoch 43/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3483 - masked_rmse: 0.3768 - val_loss: 1.4857 - val_masked_rmse: 1.0176\n",
            "Epoch 44/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3471 - masked_rmse: 0.3775 - val_loss: 1.4650 - val_masked_rmse: 1.0081\n",
            "Epoch 45/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3422 - masked_rmse: 0.3732 - val_loss: 1.4713 - val_masked_rmse: 1.0166\n",
            "Epoch 46/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3401 - masked_rmse: 0.3728 - val_loss: 1.4446 - val_masked_rmse: 1.0036\n",
            "Epoch 47/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3365 - masked_rmse: 0.3709 - val_loss: 1.4716 - val_masked_rmse: 1.0178\n",
            "Epoch 48/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3386 - masked_rmse: 0.3743 - val_loss: 1.4113 - val_masked_rmse: 0.9914\n",
            "Epoch 49/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3319 - masked_rmse: 0.3677 - val_loss: 1.4079 - val_masked_rmse: 0.9911\n",
            "Epoch 50/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3316 - masked_rmse: 0.3685 - val_loss: 1.3956 - val_masked_rmse: 0.9868\n",
            "Epoch 51/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3258 - masked_rmse: 0.3634 - val_loss: 1.4072 - val_masked_rmse: 0.9925\n",
            "Epoch 52/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3273 - masked_rmse: 0.3659 - val_loss: 1.3624 - val_masked_rmse: 0.9752\n",
            "Epoch 53/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3230 - masked_rmse: 0.3618 - val_loss: 1.3769 - val_masked_rmse: 0.9793\n",
            "Epoch 54/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3212 - masked_rmse: 0.3613 - val_loss: 1.3306 - val_masked_rmse: 0.9634\n",
            "Epoch 55/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3188 - masked_rmse: 0.3587 - val_loss: 1.3817 - val_masked_rmse: 0.9784\n",
            "Epoch 56/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3143 - masked_rmse: 0.3546 - val_loss: 1.3262 - val_masked_rmse: 0.9596\n",
            "Epoch 57/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3135 - masked_rmse: 0.3542 - val_loss: 1.3126 - val_masked_rmse: 0.9547\n",
            "Epoch 58/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3106 - masked_rmse: 0.3518 - val_loss: 1.3064 - val_masked_rmse: 0.9526\n",
            "Epoch 59/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3082 - masked_rmse: 0.3499 - val_loss: 1.2773 - val_masked_rmse: 0.9408\n",
            "Epoch 60/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3085 - masked_rmse: 0.3517 - val_loss: 1.2801 - val_masked_rmse: 0.9405\n",
            "Epoch 61/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3091 - masked_rmse: 0.3530 - val_loss: 1.3006 - val_masked_rmse: 0.9482\n",
            "Epoch 62/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3048 - masked_rmse: 0.3494 - val_loss: 1.2569 - val_masked_rmse: 0.9301\n",
            "Epoch 63/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3054 - masked_rmse: 0.3497 - val_loss: 1.2664 - val_masked_rmse: 0.9363\n",
            "Epoch 64/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3027 - masked_rmse: 0.3478 - val_loss: 1.2367 - val_masked_rmse: 0.9228\n",
            "Epoch 65/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3026 - masked_rmse: 0.3483 - val_loss: 1.2543 - val_masked_rmse: 0.9301\n",
            "Epoch 66/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2963 - masked_rmse: 0.3420 - val_loss: 1.2279 - val_masked_rmse: 0.9195\n",
            "Epoch 67/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3016 - masked_rmse: 0.3473 - val_loss: 1.2160 - val_masked_rmse: 0.9175\n",
            "Epoch 68/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3077 - masked_rmse: 0.3574 - val_loss: 1.2160 - val_masked_rmse: 0.9159\n",
            "Epoch 69/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3046 - masked_rmse: 0.3538 - val_loss: 1.1884 - val_masked_rmse: 0.9038\n",
            "Epoch 70/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2992 - masked_rmse: 0.3476 - val_loss: 1.1574 - val_masked_rmse: 0.8897\n",
            "Epoch 71/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2917 - masked_rmse: 0.3384 - val_loss: 1.1935 - val_masked_rmse: 0.9067\n",
            "Epoch 72/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2921 - masked_rmse: 0.3382 - val_loss: 1.1685 - val_masked_rmse: 0.8947\n",
            "Epoch 73/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2903 - masked_rmse: 0.3367 - val_loss: 1.1661 - val_masked_rmse: 0.8957\n",
            "Epoch 74/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2864 - masked_rmse: 0.3333 - val_loss: 1.1755 - val_masked_rmse: 0.8958\n",
            "Epoch 75/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2903 - masked_rmse: 0.3382 - val_loss: 1.1397 - val_masked_rmse: 0.8848\n",
            "Epoch 76/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2931 - masked_rmse: 0.3418 - val_loss: 1.1328 - val_masked_rmse: 0.8787\n",
            "Epoch 77/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2916 - masked_rmse: 0.3415 - val_loss: 1.1105 - val_masked_rmse: 0.8726\n",
            "Epoch 78/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2879 - masked_rmse: 0.3370 - val_loss: 1.1159 - val_masked_rmse: 0.8721\n",
            "Epoch 79/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2819 - masked_rmse: 0.3298 - val_loss: 1.1682 - val_masked_rmse: 0.8950\n",
            "Epoch 80/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2816 - masked_rmse: 0.3289 - val_loss: 1.0937 - val_masked_rmse: 0.8658\n",
            "Epoch 81/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2821 - masked_rmse: 0.3298 - val_loss: 1.1214 - val_masked_rmse: 0.8748\n",
            "Epoch 82/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2814 - masked_rmse: 0.3300 - val_loss: 1.0974 - val_masked_rmse: 0.8644\n",
            "Epoch 83/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2840 - masked_rmse: 0.3346 - val_loss: 1.0927 - val_masked_rmse: 0.8615\n",
            "Epoch 84/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2848 - masked_rmse: 0.3357 - val_loss: 1.1417 - val_masked_rmse: 0.8827\n",
            "Epoch 85/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2803 - masked_rmse: 0.3301 - val_loss: 1.0458 - val_masked_rmse: 0.8405\n",
            "Epoch 86/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2792 - masked_rmse: 0.3289 - val_loss: 1.0740 - val_masked_rmse: 0.8592\n",
            "Epoch 87/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2778 - masked_rmse: 0.3272 - val_loss: 1.0859 - val_masked_rmse: 0.8569\n",
            "Epoch 88/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2766 - masked_rmse: 0.3256 - val_loss: 1.0506 - val_masked_rmse: 0.8451\n",
            "Epoch 89/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2755 - masked_rmse: 0.3250 - val_loss: 1.0371 - val_masked_rmse: 0.8390\n",
            "Epoch 90/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2721 - masked_rmse: 0.3212 - val_loss: 1.0542 - val_masked_rmse: 0.8431\n",
            "Epoch 91/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2734 - masked_rmse: 0.3222 - val_loss: 1.0431 - val_masked_rmse: 0.8447\n",
            "Epoch 92/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2734 - masked_rmse: 0.3242 - val_loss: 1.0537 - val_masked_rmse: 0.8455\n",
            "Epoch 93/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2754 - masked_rmse: 0.3259 - val_loss: 1.0095 - val_masked_rmse: 0.8265\n",
            "Epoch 94/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2805 - masked_rmse: 0.3326 - val_loss: 1.0451 - val_masked_rmse: 0.8418\n",
            "Epoch 95/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2836 - masked_rmse: 0.3377 - val_loss: 1.0267 - val_masked_rmse: 0.8347\n",
            "Epoch 96/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2771 - masked_rmse: 0.3292 - val_loss: 1.0217 - val_masked_rmse: 0.8332\n",
            "Epoch 97/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2759 - masked_rmse: 0.3274 - val_loss: 1.0248 - val_masked_rmse: 0.8364\n",
            "Epoch 98/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2719 - masked_rmse: 0.3225 - val_loss: 1.0013 - val_masked_rmse: 0.8210\n",
            "Epoch 99/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2688 - masked_rmse: 0.3183 - val_loss: 1.0034 - val_masked_rmse: 0.8239\n",
            "Epoch 100/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2716 - masked_rmse: 0.3223 - val_loss: 1.0127 - val_masked_rmse: 0.8302\n",
            "Epoch 101/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2681 - masked_rmse: 0.3179 - val_loss: 1.0041 - val_masked_rmse: 0.8254\n",
            "Epoch 102/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2664 - masked_rmse: 0.3155 - val_loss: 0.9803 - val_masked_rmse: 0.8120\n",
            "Epoch 103/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2709 - masked_rmse: 0.3217 - val_loss: 1.0024 - val_masked_rmse: 0.8235\n",
            "Epoch 104/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2686 - masked_rmse: 0.3197 - val_loss: 1.0020 - val_masked_rmse: 0.8251\n",
            "Epoch 105/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2677 - masked_rmse: 0.3189 - val_loss: 0.9637 - val_masked_rmse: 0.8059\n",
            "Epoch 106/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2639 - masked_rmse: 0.3148 - val_loss: 0.9777 - val_masked_rmse: 0.8120\n",
            "Epoch 107/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2668 - masked_rmse: 0.3164 - val_loss: 0.9758 - val_masked_rmse: 0.8114\n",
            "Epoch 108/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2620 - masked_rmse: 0.3117 - val_loss: 0.9699 - val_masked_rmse: 0.8100\n",
            "Epoch 109/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2628 - masked_rmse: 0.3133 - val_loss: 0.9904 - val_masked_rmse: 0.8172\n",
            "Epoch 110/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2659 - masked_rmse: 0.3168 - val_loss: 0.9782 - val_masked_rmse: 0.8119\n",
            "Epoch 111/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2641 - masked_rmse: 0.3160 - val_loss: 0.9619 - val_masked_rmse: 0.8059\n",
            "Epoch 112/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2628 - masked_rmse: 0.3136 - val_loss: 0.9724 - val_masked_rmse: 0.8105\n",
            "Epoch 113/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2623 - masked_rmse: 0.3139 - val_loss: 0.9833 - val_masked_rmse: 0.8169\n",
            "Epoch 114/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2630 - masked_rmse: 0.3153 - val_loss: 0.9649 - val_masked_rmse: 0.8039\n",
            "Epoch 115/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2616 - masked_rmse: 0.3132 - val_loss: 0.9471 - val_masked_rmse: 0.7986\n",
            "Epoch 116/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2632 - masked_rmse: 0.3160 - val_loss: 0.9538 - val_masked_rmse: 0.8018\n",
            "Epoch 117/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2617 - masked_rmse: 0.3138 - val_loss: 0.9512 - val_masked_rmse: 0.7991\n",
            "Epoch 118/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2618 - masked_rmse: 0.3144 - val_loss: 0.9567 - val_masked_rmse: 0.8045\n",
            "Epoch 119/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2612 - masked_rmse: 0.3131 - val_loss: 0.9642 - val_masked_rmse: 0.8082\n",
            "Epoch 120/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2566 - masked_rmse: 0.3085 - val_loss: 0.9750 - val_masked_rmse: 0.8123\n",
            "Epoch 121/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2592 - masked_rmse: 0.3107 - val_loss: 0.9285 - val_masked_rmse: 0.7897\n",
            "Epoch 122/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2586 - masked_rmse: 0.3111 - val_loss: 0.9751 - val_masked_rmse: 0.8138\n",
            "Epoch 123/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2590 - masked_rmse: 0.3114 - val_loss: 0.9463 - val_masked_rmse: 0.7970\n",
            "Epoch 124/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2548 - masked_rmse: 0.3066 - val_loss: 0.9474 - val_masked_rmse: 0.8022\n",
            "Epoch 125/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2564 - masked_rmse: 0.3081 - val_loss: 0.9296 - val_masked_rmse: 0.7902\n",
            "Epoch 126/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2559 - masked_rmse: 0.3078 - val_loss: 0.9372 - val_masked_rmse: 0.7971\n",
            "Epoch 127/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2597 - masked_rmse: 0.3128 - val_loss: 0.9495 - val_masked_rmse: 0.8013\n",
            "Epoch 128/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2605 - masked_rmse: 0.3152 - val_loss: 0.9353 - val_masked_rmse: 0.7941\n",
            "Epoch 129/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2590 - masked_rmse: 0.3131 - val_loss: 0.9294 - val_masked_rmse: 0.7915\n",
            "Epoch 130/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2589 - masked_rmse: 0.3132 - val_loss: 0.9431 - val_masked_rmse: 0.7995\n",
            "Epoch 131/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2568 - masked_rmse: 0.3106 - val_loss: 0.9260 - val_masked_rmse: 0.7901\n",
            "Epoch 132/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2530 - masked_rmse: 0.3050 - val_loss: 0.9341 - val_masked_rmse: 0.7932\n",
            "Epoch 133/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2526 - masked_rmse: 0.3037 - val_loss: 0.9264 - val_masked_rmse: 0.7943\n",
            "Epoch 134/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2514 - masked_rmse: 0.3027 - val_loss: 0.9263 - val_masked_rmse: 0.7862\n",
            "Epoch 135/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2507 - masked_rmse: 0.3022 - val_loss: 0.9171 - val_masked_rmse: 0.7881\n",
            "Epoch 136/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2523 - masked_rmse: 0.3046 - val_loss: 0.9159 - val_masked_rmse: 0.7836\n",
            "Epoch 137/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2506 - masked_rmse: 0.3022 - val_loss: 0.9236 - val_masked_rmse: 0.7867\n",
            "Epoch 138/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2523 - masked_rmse: 0.3055 - val_loss: 0.9255 - val_masked_rmse: 0.7933\n",
            "Epoch 139/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2548 - masked_rmse: 0.3087 - val_loss: 0.9040 - val_masked_rmse: 0.7787\n",
            "Epoch 140/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2544 - masked_rmse: 0.3088 - val_loss: 0.9194 - val_masked_rmse: 0.7854\n",
            "Epoch 141/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2535 - masked_rmse: 0.3074 - val_loss: 0.9050 - val_masked_rmse: 0.7803\n",
            "Epoch 142/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2537 - masked_rmse: 0.3076 - val_loss: 0.9081 - val_masked_rmse: 0.7807\n",
            "Epoch 143/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2526 - masked_rmse: 0.3066 - val_loss: 0.9036 - val_masked_rmse: 0.7799\n",
            "Epoch 144/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2502 - masked_rmse: 0.3028 - val_loss: 0.9182 - val_masked_rmse: 0.7870\n",
            "Epoch 145/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2521 - masked_rmse: 0.3046 - val_loss: 0.8828 - val_masked_rmse: 0.7670\n",
            "Epoch 146/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2477 - masked_rmse: 0.3003 - val_loss: 0.9086 - val_masked_rmse: 0.7843\n",
            "Epoch 147/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2480 - masked_rmse: 0.2999 - val_loss: 0.9078 - val_masked_rmse: 0.7823\n",
            "Epoch 148/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2463 - masked_rmse: 0.2977 - val_loss: 0.8916 - val_masked_rmse: 0.7726\n",
            "Epoch 149/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2492 - masked_rmse: 0.3013 - val_loss: 0.9037 - val_masked_rmse: 0.7797\n",
            "Epoch 150/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2487 - masked_rmse: 0.3017 - val_loss: 0.8926 - val_masked_rmse: 0.7753\n",
            "Epoch 151/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2488 - masked_rmse: 0.3023 - val_loss: 0.8830 - val_masked_rmse: 0.7699\n",
            "Epoch 152/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2484 - masked_rmse: 0.3016 - val_loss: 0.9109 - val_masked_rmse: 0.7847\n",
            "Epoch 153/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2516 - masked_rmse: 0.3049 - val_loss: 0.8866 - val_masked_rmse: 0.7717\n",
            "Epoch 154/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2508 - masked_rmse: 0.3050 - val_loss: 0.8963 - val_masked_rmse: 0.7782\n",
            "Epoch 155/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2479 - masked_rmse: 0.3016 - val_loss: 0.8848 - val_masked_rmse: 0.7724\n",
            "Epoch 156/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2509 - masked_rmse: 0.3050 - val_loss: 0.8786 - val_masked_rmse: 0.7687\n",
            "Epoch 157/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2503 - masked_rmse: 0.3041 - val_loss: 0.8866 - val_masked_rmse: 0.7724\n",
            "Epoch 158/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2448 - masked_rmse: 0.2972 - val_loss: 0.8834 - val_masked_rmse: 0.7713\n",
            "Epoch 159/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2423 - masked_rmse: 0.2932 - val_loss: 0.8706 - val_masked_rmse: 0.7626\n",
            "Epoch 160/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2429 - masked_rmse: 0.2940 - val_loss: 0.8894 - val_masked_rmse: 0.7751\n",
            "Epoch 161/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2447 - masked_rmse: 0.2972 - val_loss: 0.8765 - val_masked_rmse: 0.7692\n",
            "Epoch 162/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2460 - masked_rmse: 0.2983 - val_loss: 0.8711 - val_masked_rmse: 0.7622\n",
            "Epoch 163/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2467 - masked_rmse: 0.3003 - val_loss: 0.8717 - val_masked_rmse: 0.7644\n",
            "Epoch 164/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2491 - masked_rmse: 0.3043 - val_loss: 0.8844 - val_masked_rmse: 0.7710\n",
            "Epoch 165/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2462 - masked_rmse: 0.3000 - val_loss: 0.8703 - val_masked_rmse: 0.7646\n",
            "Epoch 166/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2441 - masked_rmse: 0.2970 - val_loss: 0.8781 - val_masked_rmse: 0.7682\n",
            "Epoch 167/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2408 - masked_rmse: 0.2916 - val_loss: 0.8545 - val_masked_rmse: 0.7581\n",
            "Epoch 168/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2388 - masked_rmse: 0.2897 - val_loss: 0.8700 - val_masked_rmse: 0.7657\n",
            "Epoch 169/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2401 - masked_rmse: 0.2911 - val_loss: 0.8626 - val_masked_rmse: 0.7592\n",
            "Epoch 170/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2411 - masked_rmse: 0.2927 - val_loss: 0.8645 - val_masked_rmse: 0.7645\n",
            "Epoch 171/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2429 - masked_rmse: 0.2952 - val_loss: 0.8713 - val_masked_rmse: 0.7634\n",
            "Epoch 172/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2428 - masked_rmse: 0.2960 - val_loss: 0.8627 - val_masked_rmse: 0.7612\n",
            "Epoch 173/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2470 - masked_rmse: 0.3022 - val_loss: 0.8553 - val_masked_rmse: 0.7580\n",
            "Epoch 174/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2440 - masked_rmse: 0.2984 - val_loss: 0.8674 - val_masked_rmse: 0.7626\n",
            "Epoch 175/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2407 - masked_rmse: 0.2929 - val_loss: 0.8636 - val_masked_rmse: 0.7621\n",
            "Epoch 176/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2395 - masked_rmse: 0.2912 - val_loss: 0.8558 - val_masked_rmse: 0.7572\n",
            "Epoch 177/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2391 - masked_rmse: 0.2907 - val_loss: 0.8458 - val_masked_rmse: 0.7515\n",
            "Epoch 178/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2385 - masked_rmse: 0.2898 - val_loss: 0.8675 - val_masked_rmse: 0.7639\n",
            "Epoch 179/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2393 - masked_rmse: 0.2907 - val_loss: 0.8660 - val_masked_rmse: 0.7635\n",
            "Epoch 180/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2412 - masked_rmse: 0.2947 - val_loss: 0.8678 - val_masked_rmse: 0.7625\n",
            "Epoch 181/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2446 - masked_rmse: 0.2988 - val_loss: 0.8418 - val_masked_rmse: 0.7543\n",
            "Epoch 182/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2440 - masked_rmse: 0.2987 - val_loss: 0.8489 - val_masked_rmse: 0.7569\n",
            "Epoch 183/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2425 - masked_rmse: 0.2966 - val_loss: 0.8524 - val_masked_rmse: 0.7542\n",
            "Epoch 184/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2383 - masked_rmse: 0.2904 - val_loss: 0.8333 - val_masked_rmse: 0.7460\n",
            "Epoch 185/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2376 - masked_rmse: 0.2896 - val_loss: 0.8645 - val_masked_rmse: 0.7644\n",
            "Epoch 186/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2381 - masked_rmse: 0.2887 - val_loss: 0.8554 - val_masked_rmse: 0.7566\n",
            "Epoch 187/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2363 - masked_rmse: 0.2873 - val_loss: 0.8445 - val_masked_rmse: 0.7541\n",
            "Epoch 188/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2373 - masked_rmse: 0.2884 - val_loss: 0.8525 - val_masked_rmse: 0.7581\n",
            "Epoch 189/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2381 - masked_rmse: 0.2897 - val_loss: 0.8532 - val_masked_rmse: 0.7570\n",
            "Epoch 190/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2398 - masked_rmse: 0.2920 - val_loss: 0.8338 - val_masked_rmse: 0.7457\n",
            "Epoch 191/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2377 - masked_rmse: 0.2897 - val_loss: 0.8415 - val_masked_rmse: 0.7495\n",
            "Epoch 192/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2390 - masked_rmse: 0.2914 - val_loss: 0.8352 - val_masked_rmse: 0.7504\n",
            "Epoch 193/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2402 - masked_rmse: 0.2933 - val_loss: 0.8516 - val_masked_rmse: 0.7557\n",
            "Epoch 194/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2407 - masked_rmse: 0.2942 - val_loss: 0.8432 - val_masked_rmse: 0.7516\n",
            "Epoch 195/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2392 - masked_rmse: 0.2915 - val_loss: 0.8397 - val_masked_rmse: 0.7502\n",
            "Epoch 196/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2367 - masked_rmse: 0.2878 - val_loss: 0.8399 - val_masked_rmse: 0.7511\n",
            "Epoch 197/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2364 - masked_rmse: 0.2870 - val_loss: 0.8278 - val_masked_rmse: 0.7442\n",
            "Epoch 198/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2354 - masked_rmse: 0.2860 - val_loss: 0.8379 - val_masked_rmse: 0.7503\n",
            "Epoch 199/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2383 - masked_rmse: 0.2900 - val_loss: 0.8318 - val_masked_rmse: 0.7456\n",
            "Epoch 200/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2356 - masked_rmse: 0.2865 - val_loss: 0.8314 - val_masked_rmse: 0.7459\n",
            "Epoch 201/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2347 - masked_rmse: 0.2859 - val_loss: 0.8216 - val_masked_rmse: 0.7419\n",
            "Epoch 202/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2359 - masked_rmse: 0.2871 - val_loss: 0.8268 - val_masked_rmse: 0.7423\n",
            "Epoch 203/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2350 - masked_rmse: 0.2859 - val_loss: 0.8296 - val_masked_rmse: 0.7463\n",
            "Epoch 204/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2344 - masked_rmse: 0.2852 - val_loss: 0.8301 - val_masked_rmse: 0.7461\n",
            "Epoch 205/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2336 - masked_rmse: 0.2838 - val_loss: 0.8244 - val_masked_rmse: 0.7433\n",
            "Epoch 206/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2333 - masked_rmse: 0.2847 - val_loss: 0.8237 - val_masked_rmse: 0.7422\n",
            "Epoch 207/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2329 - masked_rmse: 0.2840 - val_loss: 0.8191 - val_masked_rmse: 0.7409\n",
            "Epoch 208/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2334 - masked_rmse: 0.2837 - val_loss: 0.8221 - val_masked_rmse: 0.7405\n",
            "Epoch 209/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2337 - masked_rmse: 0.2840 - val_loss: 0.8306 - val_masked_rmse: 0.7453\n",
            "Epoch 210/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2336 - masked_rmse: 0.2845 - val_loss: 0.8070 - val_masked_rmse: 0.7367\n",
            "Epoch 211/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2336 - masked_rmse: 0.2849 - val_loss: 0.8293 - val_masked_rmse: 0.7448\n",
            "Epoch 212/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2333 - masked_rmse: 0.2844 - val_loss: 0.8202 - val_masked_rmse: 0.7408\n",
            "Epoch 213/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2331 - masked_rmse: 0.2844 - val_loss: 0.8068 - val_masked_rmse: 0.7369\n",
            "Epoch 214/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2320 - masked_rmse: 0.2825 - val_loss: 0.8214 - val_masked_rmse: 0.7419\n",
            "Epoch 215/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2318 - masked_rmse: 0.2824 - val_loss: 0.8152 - val_masked_rmse: 0.7366\n",
            "Epoch 216/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2366 - masked_rmse: 0.2900 - val_loss: 0.8126 - val_masked_rmse: 0.7353\n",
            "Epoch 217/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2340 - masked_rmse: 0.2870 - val_loss: 0.8099 - val_masked_rmse: 0.7350\n",
            "Epoch 218/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2347 - masked_rmse: 0.2869 - val_loss: 0.8185 - val_masked_rmse: 0.7413\n",
            "Epoch 219/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2323 - masked_rmse: 0.2832 - val_loss: 0.8099 - val_masked_rmse: 0.7343\n",
            "Epoch 220/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2335 - masked_rmse: 0.2841 - val_loss: 0.8127 - val_masked_rmse: 0.7376\n",
            "Epoch 221/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2302 - masked_rmse: 0.2799 - val_loss: 0.7988 - val_masked_rmse: 0.7329\n",
            "Epoch 222/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2345 - masked_rmse: 0.2871 - val_loss: 0.8159 - val_masked_rmse: 0.7396\n",
            "Epoch 223/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2339 - masked_rmse: 0.2860 - val_loss: 0.8137 - val_masked_rmse: 0.7378\n",
            "Epoch 224/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2333 - masked_rmse: 0.2846 - val_loss: 0.7978 - val_masked_rmse: 0.7307\n",
            "Epoch 225/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2334 - masked_rmse: 0.2844 - val_loss: 0.7958 - val_masked_rmse: 0.7303\n",
            "Epoch 226/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2322 - masked_rmse: 0.2826 - val_loss: 0.8147 - val_masked_rmse: 0.7386\n",
            "Epoch 227/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2282 - masked_rmse: 0.2774 - val_loss: 0.8113 - val_masked_rmse: 0.7349\n",
            "Epoch 228/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2333 - masked_rmse: 0.2842 - val_loss: 0.8090 - val_masked_rmse: 0.7375\n",
            "Epoch 229/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2336 - masked_rmse: 0.2850 - val_loss: 0.7986 - val_masked_rmse: 0.7316\n",
            "Epoch 230/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2323 - masked_rmse: 0.2831 - val_loss: 0.8047 - val_masked_rmse: 0.7323\n",
            "Epoch 231/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2303 - masked_rmse: 0.2795 - val_loss: 0.7925 - val_masked_rmse: 0.7290\n",
            "Epoch 232/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2303 - masked_rmse: 0.2800 - val_loss: 0.7901 - val_masked_rmse: 0.7262\n",
            "Epoch 233/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2298 - masked_rmse: 0.2796 - val_loss: 0.8040 - val_masked_rmse: 0.7344\n",
            "Epoch 234/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2307 - masked_rmse: 0.2806 - val_loss: 0.8026 - val_masked_rmse: 0.7325\n",
            "Epoch 235/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2314 - masked_rmse: 0.2812 - val_loss: 0.7913 - val_masked_rmse: 0.7263\n",
            "Epoch 236/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2311 - masked_rmse: 0.2818 - val_loss: 0.7972 - val_masked_rmse: 0.7301\n",
            "Epoch 237/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2287 - masked_rmse: 0.2780 - val_loss: 0.7860 - val_masked_rmse: 0.7247\n",
            "Epoch 238/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2290 - masked_rmse: 0.2789 - val_loss: 0.7901 - val_masked_rmse: 0.7272\n",
            "Epoch 239/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2286 - masked_rmse: 0.2780 - val_loss: 0.7963 - val_masked_rmse: 0.7300\n",
            "Epoch 240/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2279 - masked_rmse: 0.2771 - val_loss: 0.7802 - val_masked_rmse: 0.7193\n",
            "Epoch 241/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2260 - masked_rmse: 0.2746 - val_loss: 0.7945 - val_masked_rmse: 0.7294\n",
            "Epoch 242/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2272 - masked_rmse: 0.2760 - val_loss: 0.7869 - val_masked_rmse: 0.7251\n",
            "Epoch 243/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2276 - masked_rmse: 0.2769 - val_loss: 0.7872 - val_masked_rmse: 0.7245\n",
            "Epoch 244/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2279 - masked_rmse: 0.2773 - val_loss: 0.7904 - val_masked_rmse: 0.7282\n",
            "Epoch 245/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2313 - masked_rmse: 0.2825 - val_loss: 0.7953 - val_masked_rmse: 0.7295\n",
            "Epoch 246/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2307 - masked_rmse: 0.2825 - val_loss: 0.7791 - val_masked_rmse: 0.7204\n",
            "Epoch 247/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2288 - masked_rmse: 0.2794 - val_loss: 0.7882 - val_masked_rmse: 0.7265\n",
            "Epoch 248/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2274 - masked_rmse: 0.2771 - val_loss: 0.7856 - val_masked_rmse: 0.7242\n",
            "Epoch 249/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2274 - masked_rmse: 0.2768 - val_loss: 0.7809 - val_masked_rmse: 0.7220\n",
            "Epoch 250/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2254 - masked_rmse: 0.2741 - val_loss: 0.7745 - val_masked_rmse: 0.7182\n",
            "Epoch 251/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2260 - masked_rmse: 0.2750 - val_loss: 0.7808 - val_masked_rmse: 0.7240\n",
            "Epoch 252/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2272 - masked_rmse: 0.2768 - val_loss: 0.7849 - val_masked_rmse: 0.7232\n",
            "Epoch 253/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2263 - masked_rmse: 0.2759 - val_loss: 0.7760 - val_masked_rmse: 0.7218\n",
            "Epoch 254/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2280 - masked_rmse: 0.2773 - val_loss: 0.7810 - val_masked_rmse: 0.7207\n",
            "Epoch 255/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2289 - masked_rmse: 0.2795 - val_loss: 0.7805 - val_masked_rmse: 0.7225\n",
            "Epoch 256/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2277 - masked_rmse: 0.2777 - val_loss: 0.7856 - val_masked_rmse: 0.7230\n",
            "Epoch 257/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2285 - masked_rmse: 0.2781 - val_loss: 0.7734 - val_masked_rmse: 0.7184\n",
            "Epoch 258/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2270 - masked_rmse: 0.2763 - val_loss: 0.7747 - val_masked_rmse: 0.7187\n",
            "Epoch 259/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2271 - masked_rmse: 0.2768 - val_loss: 0.7867 - val_masked_rmse: 0.7233\n",
            "Epoch 260/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2281 - masked_rmse: 0.2783 - val_loss: 0.7847 - val_masked_rmse: 0.7255\n",
            "Epoch 261/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2277 - masked_rmse: 0.2780 - val_loss: 0.7760 - val_masked_rmse: 0.7201\n",
            "Epoch 262/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2254 - masked_rmse: 0.2741 - val_loss: 0.7805 - val_masked_rmse: 0.7237\n",
            "Epoch 263/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2241 - masked_rmse: 0.2729 - val_loss: 0.7704 - val_masked_rmse: 0.7167\n",
            "Epoch 264/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2221 - masked_rmse: 0.2694 - val_loss: 0.7912 - val_masked_rmse: 0.7268\n",
            "Epoch 265/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2240 - masked_rmse: 0.2723 - val_loss: 0.7596 - val_masked_rmse: 0.7107\n",
            "Epoch 266/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2267 - masked_rmse: 0.2758 - val_loss: 0.7849 - val_masked_rmse: 0.7237\n",
            "Epoch 267/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2306 - masked_rmse: 0.2825 - val_loss: 0.7762 - val_masked_rmse: 0.7206\n",
            "Epoch 268/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2311 - masked_rmse: 0.2845 - val_loss: 0.7700 - val_masked_rmse: 0.7168\n",
            "Epoch 269/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2277 - masked_rmse: 0.2786 - val_loss: 0.7789 - val_masked_rmse: 0.7222\n",
            "Epoch 270/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2280 - masked_rmse: 0.2787 - val_loss: 0.7692 - val_masked_rmse: 0.7155\n",
            "Epoch 271/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2267 - masked_rmse: 0.2766 - val_loss: 0.7821 - val_masked_rmse: 0.7270\n",
            "Epoch 272/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2242 - masked_rmse: 0.2730 - val_loss: 0.7700 - val_masked_rmse: 0.7160\n",
            "Epoch 273/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2244 - masked_rmse: 0.2726 - val_loss: 0.7847 - val_masked_rmse: 0.7226\n",
            "Epoch 274/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2250 - masked_rmse: 0.2737 - val_loss: 0.7641 - val_masked_rmse: 0.7165\n",
            "Epoch 275/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2252 - masked_rmse: 0.2742 - val_loss: 0.7719 - val_masked_rmse: 0.7184\n",
            "Epoch 276/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2264 - masked_rmse: 0.2752 - val_loss: 0.7710 - val_masked_rmse: 0.7193\n",
            "Epoch 277/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2264 - masked_rmse: 0.2758 - val_loss: 0.7743 - val_masked_rmse: 0.7182\n",
            "Epoch 278/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2262 - masked_rmse: 0.2765 - val_loss: 0.7811 - val_masked_rmse: 0.7232\n",
            "Epoch 279/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2296 - masked_rmse: 0.2796 - val_loss: 0.7767 - val_masked_rmse: 0.7210\n",
            "Epoch 280/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2308 - masked_rmse: 0.2831 - val_loss: 0.7727 - val_masked_rmse: 0.7204\n",
            "Epoch 281/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2270 - masked_rmse: 0.2774 - val_loss: 0.7680 - val_masked_rmse: 0.7139\n",
            "Epoch 282/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2264 - masked_rmse: 0.2763 - val_loss: 0.7736 - val_masked_rmse: 0.7206\n",
            "Epoch 283/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2261 - masked_rmse: 0.2753 - val_loss: 0.7635 - val_masked_rmse: 0.7145\n",
            "Epoch 284/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2265 - masked_rmse: 0.2753 - val_loss: 0.7710 - val_masked_rmse: 0.7181\n",
            "Epoch 285/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2253 - masked_rmse: 0.2742 - val_loss: 0.7699 - val_masked_rmse: 0.7171\n",
            "Epoch 286/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2233 - masked_rmse: 0.2714 - val_loss: 0.7598 - val_masked_rmse: 0.7124\n",
            "Epoch 287/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2215 - masked_rmse: 0.2692 - val_loss: 0.7668 - val_masked_rmse: 0.7166\n",
            "Epoch 288/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2235 - masked_rmse: 0.2714 - val_loss: 0.7625 - val_masked_rmse: 0.7138\n",
            "Epoch 289/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2246 - masked_rmse: 0.2737 - val_loss: 0.7683 - val_masked_rmse: 0.7173\n",
            "Epoch 290/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2252 - masked_rmse: 0.2740 - val_loss: 0.7645 - val_masked_rmse: 0.7144\n",
            "Epoch 291/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2253 - masked_rmse: 0.2747 - val_loss: 0.7664 - val_masked_rmse: 0.7153\n",
            "Epoch 292/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2268 - masked_rmse: 0.2769 - val_loss: 0.7672 - val_masked_rmse: 0.7167\n",
            "Epoch 293/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2247 - masked_rmse: 0.2742 - val_loss: 0.7712 - val_masked_rmse: 0.7169\n",
            "Epoch 294/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2222 - masked_rmse: 0.2700 - val_loss: 0.7637 - val_masked_rmse: 0.7146\n",
            "Epoch 295/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2206 - masked_rmse: 0.2673 - val_loss: 0.7619 - val_masked_rmse: 0.7132\n",
            "Epoch 296/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2210 - masked_rmse: 0.2674 - val_loss: 0.7685 - val_masked_rmse: 0.7169\n",
            "Epoch 297/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2191 - masked_rmse: 0.2652 - val_loss: 0.7619 - val_masked_rmse: 0.7118\n",
            "Epoch 298/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2196 - masked_rmse: 0.2663 - val_loss: 0.7615 - val_masked_rmse: 0.7121\n",
            "Epoch 299/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2201 - masked_rmse: 0.2668 - val_loss: 0.7557 - val_masked_rmse: 0.7098\n",
            "Epoch 300/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2190 - masked_rmse: 0.2657 - val_loss: 0.7657 - val_masked_rmse: 0.7152\n",
            "Epoch 301/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2227 - masked_rmse: 0.2702 - val_loss: 0.7594 - val_masked_rmse: 0.7133\n",
            "Epoch 302/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2219 - masked_rmse: 0.2702 - val_loss: 0.7565 - val_masked_rmse: 0.7104\n",
            "Epoch 303/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2212 - masked_rmse: 0.2695 - val_loss: 0.7642 - val_masked_rmse: 0.7154\n",
            "Epoch 304/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2222 - masked_rmse: 0.2711 - val_loss: 0.7579 - val_masked_rmse: 0.7111\n",
            "Epoch 305/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2225 - masked_rmse: 0.2717 - val_loss: 0.7697 - val_masked_rmse: 0.7190\n",
            "Epoch 306/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2244 - masked_rmse: 0.2745 - val_loss: 0.7558 - val_masked_rmse: 0.7066\n",
            "Epoch 307/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2259 - masked_rmse: 0.2766 - val_loss: 0.7684 - val_masked_rmse: 0.7181\n",
            "Epoch 308/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2248 - masked_rmse: 0.2755 - val_loss: 0.7521 - val_masked_rmse: 0.7099\n",
            "Epoch 309/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2259 - masked_rmse: 0.2752 - val_loss: 0.7607 - val_masked_rmse: 0.7129\n",
            "Epoch 310/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2219 - masked_rmse: 0.2701 - val_loss: 0.7695 - val_masked_rmse: 0.7168\n",
            "Epoch 311/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2208 - masked_rmse: 0.2685 - val_loss: 0.7536 - val_masked_rmse: 0.7100\n",
            "Epoch 312/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2204 - masked_rmse: 0.2677 - val_loss: 0.7557 - val_masked_rmse: 0.7078\n",
            "Epoch 313/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2180 - masked_rmse: 0.2644 - val_loss: 0.7505 - val_masked_rmse: 0.7060\n",
            "Epoch 314/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2180 - masked_rmse: 0.2646 - val_loss: 0.7602 - val_masked_rmse: 0.7152\n",
            "Epoch 315/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2222 - masked_rmse: 0.2702 - val_loss: 0.7581 - val_masked_rmse: 0.7104\n",
            "Epoch 316/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2240 - masked_rmse: 0.2729 - val_loss: 0.7597 - val_masked_rmse: 0.7124\n",
            "Epoch 317/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2231 - masked_rmse: 0.2722 - val_loss: 0.7583 - val_masked_rmse: 0.7116\n",
            "Epoch 318/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2220 - masked_rmse: 0.2713 - val_loss: 0.7623 - val_masked_rmse: 0.7112\n",
            "Epoch 319/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2242 - masked_rmse: 0.2751 - val_loss: 0.7633 - val_masked_rmse: 0.7152\n",
            "Epoch 320/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2240 - masked_rmse: 0.2738 - val_loss: 0.7552 - val_masked_rmse: 0.7105\n",
            "Epoch 321/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2223 - masked_rmse: 0.2701 - val_loss: 0.7604 - val_masked_rmse: 0.7122\n",
            "Epoch 322/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2209 - masked_rmse: 0.2680 - val_loss: 0.7470 - val_masked_rmse: 0.7042\n",
            "Epoch 323/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2213 - masked_rmse: 0.2694 - val_loss: 0.7601 - val_masked_rmse: 0.7131\n",
            "Epoch 324/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2195 - masked_rmse: 0.2670 - val_loss: 0.7409 - val_masked_rmse: 0.7020\n",
            "Epoch 325/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2188 - masked_rmse: 0.2656 - val_loss: 0.7470 - val_masked_rmse: 0.7036\n",
            "Epoch 326/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2172 - masked_rmse: 0.2635 - val_loss: 0.7579 - val_masked_rmse: 0.7098\n",
            "Epoch 327/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2199 - masked_rmse: 0.2667 - val_loss: 0.7539 - val_masked_rmse: 0.7094\n",
            "Epoch 328/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2221 - masked_rmse: 0.2710 - val_loss: 0.7510 - val_masked_rmse: 0.7091\n",
            "Epoch 329/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2194 - masked_rmse: 0.2677 - val_loss: 0.7673 - val_masked_rmse: 0.7168\n",
            "Epoch 330/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2200 - masked_rmse: 0.2676 - val_loss: 0.7479 - val_masked_rmse: 0.7081\n",
            "Epoch 331/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2192 - masked_rmse: 0.2658 - val_loss: 0.7542 - val_masked_rmse: 0.7081\n",
            "Epoch 332/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2212 - masked_rmse: 0.2694 - val_loss: 0.7530 - val_masked_rmse: 0.7095\n",
            "Epoch 333/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2199 - masked_rmse: 0.2678 - val_loss: 0.7561 - val_masked_rmse: 0.7112\n",
            "Epoch 334/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2186 - masked_rmse: 0.2651 - val_loss: 0.7483 - val_masked_rmse: 0.7080\n",
            "Epoch 335/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2170 - masked_rmse: 0.2630 - val_loss: 0.7561 - val_masked_rmse: 0.7109\n",
            "Epoch 336/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2197 - masked_rmse: 0.2655 - val_loss: 0.7520 - val_masked_rmse: 0.7096\n",
            "Epoch 337/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2211 - masked_rmse: 0.2693 - val_loss: 0.7475 - val_masked_rmse: 0.7043\n",
            "Epoch 338/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2220 - masked_rmse: 0.2704 - val_loss: 0.7560 - val_masked_rmse: 0.7110\n",
            "Epoch 339/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2214 - masked_rmse: 0.2703 - val_loss: 0.7522 - val_masked_rmse: 0.7084\n",
            "Epoch 340/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2214 - masked_rmse: 0.2697 - val_loss: 0.7490 - val_masked_rmse: 0.7066\n",
            "Epoch 341/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2200 - masked_rmse: 0.2684 - val_loss: 0.7466 - val_masked_rmse: 0.7038\n",
            "Epoch 342/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2178 - masked_rmse: 0.2646 - val_loss: 0.7505 - val_masked_rmse: 0.7081\n",
            "Epoch 343/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2161 - masked_rmse: 0.2618 - val_loss: 0.7495 - val_masked_rmse: 0.7071\n",
            "Epoch 344/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2157 - masked_rmse: 0.2608 - val_loss: 0.7511 - val_masked_rmse: 0.7087\n",
            "Epoch 345/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2171 - masked_rmse: 0.2632 - val_loss: 0.7537 - val_masked_rmse: 0.7106\n",
            "Epoch 346/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2177 - masked_rmse: 0.2644 - val_loss: 0.7490 - val_masked_rmse: 0.7063\n",
            "Epoch 347/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2193 - masked_rmse: 0.2673 - val_loss: 0.7498 - val_masked_rmse: 0.7103\n",
            "Epoch 348/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2200 - masked_rmse: 0.2683 - val_loss: 0.7498 - val_masked_rmse: 0.7069\n",
            "Epoch 349/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2198 - masked_rmse: 0.2675 - val_loss: 0.7446 - val_masked_rmse: 0.7051\n",
            "Epoch 350/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2211 - masked_rmse: 0.2702 - val_loss: 0.7539 - val_masked_rmse: 0.7104\n",
            "Epoch 351/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2182 - masked_rmse: 0.2662 - val_loss: 0.7463 - val_masked_rmse: 0.7040\n",
            "Epoch 352/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2189 - masked_rmse: 0.2666 - val_loss: 0.7492 - val_masked_rmse: 0.7082\n",
            "Epoch 353/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2185 - masked_rmse: 0.2656 - val_loss: 0.7558 - val_masked_rmse: 0.7109\n",
            "Epoch 354/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2180 - masked_rmse: 0.2650 - val_loss: 0.7280 - val_masked_rmse: 0.6950\n",
            "Epoch 355/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2157 - masked_rmse: 0.2618 - val_loss: 0.7641 - val_masked_rmse: 0.7132\n",
            "Epoch 356/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2134 - masked_rmse: 0.2578 - val_loss: 0.7390 - val_masked_rmse: 0.7050\n",
            "Epoch 357/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2152 - masked_rmse: 0.2601 - val_loss: 0.7385 - val_masked_rmse: 0.6981\n",
            "Epoch 358/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2176 - masked_rmse: 0.2640 - val_loss: 0.7458 - val_masked_rmse: 0.7077\n",
            "Epoch 359/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2175 - masked_rmse: 0.2640 - val_loss: 0.7418 - val_masked_rmse: 0.7050\n",
            "Epoch 360/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2188 - masked_rmse: 0.2662 - val_loss: 0.7616 - val_masked_rmse: 0.7122\n",
            "Epoch 361/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2204 - masked_rmse: 0.2683 - val_loss: 0.7472 - val_masked_rmse: 0.7062\n",
            "Epoch 362/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2239 - masked_rmse: 0.2745 - val_loss: 0.7448 - val_masked_rmse: 0.7059\n",
            "Epoch 363/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2215 - masked_rmse: 0.2719 - val_loss: 0.7455 - val_masked_rmse: 0.7072\n",
            "Epoch 364/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2219 - masked_rmse: 0.2718 - val_loss: 0.7538 - val_masked_rmse: 0.7081\n",
            "Epoch 365/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2186 - masked_rmse: 0.2666 - val_loss: 0.7418 - val_masked_rmse: 0.7037\n",
            "Epoch 366/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2161 - masked_rmse: 0.2627 - val_loss: 0.7432 - val_masked_rmse: 0.7056\n",
            "Epoch 367/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2160 - masked_rmse: 0.2620 - val_loss: 0.7499 - val_masked_rmse: 0.7069\n",
            "Epoch 368/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2151 - masked_rmse: 0.2608 - val_loss: 0.7467 - val_masked_rmse: 0.7072\n",
            "Epoch 369/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2151 - masked_rmse: 0.2606 - val_loss: 0.7392 - val_masked_rmse: 0.7011\n",
            "Epoch 370/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2139 - masked_rmse: 0.2589 - val_loss: 0.7500 - val_masked_rmse: 0.7055\n",
            "Epoch 371/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2154 - masked_rmse: 0.2604 - val_loss: 0.7427 - val_masked_rmse: 0.7032\n",
            "Epoch 372/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2150 - masked_rmse: 0.2609 - val_loss: 0.7561 - val_masked_rmse: 0.7125\n",
            "Epoch 373/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2181 - masked_rmse: 0.2652 - val_loss: 0.7422 - val_masked_rmse: 0.7046\n",
            "Epoch 374/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2175 - masked_rmse: 0.2653 - val_loss: 0.7471 - val_masked_rmse: 0.7061\n",
            "Epoch 375/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2161 - masked_rmse: 0.2636 - val_loss: 0.7400 - val_masked_rmse: 0.7034\n",
            "Epoch 376/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2168 - masked_rmse: 0.2635 - val_loss: 0.7545 - val_masked_rmse: 0.7076\n",
            "Epoch 377/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2186 - masked_rmse: 0.2659 - val_loss: 0.7414 - val_masked_rmse: 0.7049\n",
            "Epoch 378/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2148 - masked_rmse: 0.2609 - val_loss: 0.7482 - val_masked_rmse: 0.7072\n",
            "Epoch 379/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2132 - masked_rmse: 0.2581 - val_loss: 0.7394 - val_masked_rmse: 0.7022\n",
            "Epoch 380/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2136 - masked_rmse: 0.2586 - val_loss: 0.7434 - val_masked_rmse: 0.7040\n",
            "Epoch 381/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2132 - masked_rmse: 0.2583 - val_loss: 0.7430 - val_masked_rmse: 0.7039\n",
            "Epoch 382/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2138 - masked_rmse: 0.2589 - val_loss: 0.7419 - val_masked_rmse: 0.7041\n",
            "Epoch 383/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2155 - masked_rmse: 0.2616 - val_loss: 0.7480 - val_masked_rmse: 0.7068\n",
            "Epoch 384/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2167 - masked_rmse: 0.2639 - val_loss: 0.7362 - val_masked_rmse: 0.7011\n",
            "Epoch 385/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2176 - masked_rmse: 0.2653 - val_loss: 0.7471 - val_masked_rmse: 0.7069\n",
            "Epoch 386/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2170 - masked_rmse: 0.2645 - val_loss: 0.7404 - val_masked_rmse: 0.7030\n",
            "Epoch 387/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2163 - masked_rmse: 0.2639 - val_loss: 0.7437 - val_masked_rmse: 0.7045\n",
            "Epoch 388/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2177 - masked_rmse: 0.2660 - val_loss: 0.7443 - val_masked_rmse: 0.7056\n",
            "Epoch 389/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2202 - masked_rmse: 0.2693 - val_loss: 0.7542 - val_masked_rmse: 0.7102\n",
            "Epoch 390/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2199 - masked_rmse: 0.2684 - val_loss: 0.7330 - val_masked_rmse: 0.6990\n",
            "Epoch 391/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2180 - masked_rmse: 0.2651 - val_loss: 0.7461 - val_masked_rmse: 0.7052\n",
            "Epoch 392/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2144 - masked_rmse: 0.2605 - val_loss: 0.7270 - val_masked_rmse: 0.6964\n",
            "Epoch 393/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2128 - masked_rmse: 0.2566 - val_loss: 0.7557 - val_masked_rmse: 0.7091\n",
            "Epoch 394/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2127 - masked_rmse: 0.2567 - val_loss: 0.7323 - val_masked_rmse: 0.7004\n",
            "Epoch 395/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2128 - masked_rmse: 0.2572 - val_loss: 0.7357 - val_masked_rmse: 0.6997\n",
            "Epoch 396/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2140 - masked_rmse: 0.2589 - val_loss: 0.7354 - val_masked_rmse: 0.7004\n",
            "Epoch 397/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2133 - masked_rmse: 0.2581 - val_loss: 0.7524 - val_masked_rmse: 0.7087\n",
            "Epoch 398/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2134 - masked_rmse: 0.2576 - val_loss: 0.7375 - val_masked_rmse: 0.7015\n",
            "Epoch 399/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2168 - masked_rmse: 0.2622 - val_loss: 0.7360 - val_masked_rmse: 0.6986\n",
            "Epoch 400/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2151 - masked_rmse: 0.2616 - val_loss: 0.7435 - val_masked_rmse: 0.7031\n",
            "Epoch 401/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2145 - masked_rmse: 0.2594 - val_loss: 0.7397 - val_masked_rmse: 0.7037\n",
            "Epoch 402/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2128 - masked_rmse: 0.2577 - val_loss: 0.7375 - val_masked_rmse: 0.6996\n",
            "Epoch 403/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2149 - masked_rmse: 0.2609 - val_loss: 0.7404 - val_masked_rmse: 0.7031\n",
            "Epoch 404/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2153 - masked_rmse: 0.2621 - val_loss: 0.7375 - val_masked_rmse: 0.7022\n",
            "Epoch 405/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2167 - masked_rmse: 0.2644 - val_loss: 0.7471 - val_masked_rmse: 0.7074\n",
            "Epoch 406/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2155 - masked_rmse: 0.2616 - val_loss: 0.7320 - val_masked_rmse: 0.7003\n",
            "Epoch 407/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2138 - masked_rmse: 0.2593 - val_loss: 0.7445 - val_masked_rmse: 0.7043\n",
            "Epoch 408/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2130 - masked_rmse: 0.2581 - val_loss: 0.7332 - val_masked_rmse: 0.6966\n",
            "Epoch 409/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2127 - masked_rmse: 0.2575 - val_loss: 0.7397 - val_masked_rmse: 0.7028\n",
            "Epoch 410/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2122 - masked_rmse: 0.2571 - val_loss: 0.7412 - val_masked_rmse: 0.7031\n",
            "Epoch 411/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2123 - masked_rmse: 0.2571 - val_loss: 0.7381 - val_masked_rmse: 0.7020\n",
            "Epoch 412/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2153 - masked_rmse: 0.2617 - val_loss: 0.7323 - val_masked_rmse: 0.6977\n",
            "Epoch 413/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2148 - masked_rmse: 0.2616 - val_loss: 0.7458 - val_masked_rmse: 0.7083\n",
            "Epoch 414/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2136 - masked_rmse: 0.2594 - val_loss: 0.7321 - val_masked_rmse: 0.6981\n",
            "Epoch 415/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2110 - masked_rmse: 0.2551 - val_loss: 0.7433 - val_masked_rmse: 0.7026\n",
            "Epoch 416/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2134 - masked_rmse: 0.2596 - val_loss: 0.7383 - val_masked_rmse: 0.7009\n",
            "Epoch 417/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2121 - masked_rmse: 0.2564 - val_loss: 0.7311 - val_masked_rmse: 0.6969\n",
            "Epoch 418/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2109 - masked_rmse: 0.2549 - val_loss: 0.7390 - val_masked_rmse: 0.7022\n",
            "Epoch 419/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2124 - masked_rmse: 0.2567 - val_loss: 0.7410 - val_masked_rmse: 0.7035\n",
            "Epoch 420/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2141 - masked_rmse: 0.2593 - val_loss: 0.7366 - val_masked_rmse: 0.6998\n",
            "Epoch 421/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2122 - masked_rmse: 0.2575 - val_loss: 0.7378 - val_masked_rmse: 0.7004\n",
            "Epoch 422/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2132 - masked_rmse: 0.2592 - val_loss: 0.7330 - val_masked_rmse: 0.6980\n",
            "Epoch 423/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2129 - masked_rmse: 0.2592 - val_loss: 0.7404 - val_masked_rmse: 0.7042\n",
            "Epoch 424/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2128 - masked_rmse: 0.2589 - val_loss: 0.7349 - val_masked_rmse: 0.6995\n",
            "Epoch 425/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2117 - masked_rmse: 0.2571 - val_loss: 0.7367 - val_masked_rmse: 0.7017\n",
            "Epoch 426/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2120 - masked_rmse: 0.2570 - val_loss: 0.7383 - val_masked_rmse: 0.7017\n",
            "Epoch 427/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2120 - masked_rmse: 0.2568 - val_loss: 0.7304 - val_masked_rmse: 0.6983\n",
            "Epoch 428/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2119 - masked_rmse: 0.2572 - val_loss: 0.7378 - val_masked_rmse: 0.7015\n",
            "Epoch 429/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2138 - masked_rmse: 0.2599 - val_loss: 0.7308 - val_masked_rmse: 0.6969\n",
            "Epoch 430/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2151 - masked_rmse: 0.2623 - val_loss: 0.7348 - val_masked_rmse: 0.6999\n",
            "Epoch 431/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2146 - masked_rmse: 0.2613 - val_loss: 0.7440 - val_masked_rmse: 0.7037\n",
            "Epoch 432/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2144 - masked_rmse: 0.2601 - val_loss: 0.7362 - val_masked_rmse: 0.7004\n",
            "Epoch 433/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2152 - masked_rmse: 0.2605 - val_loss: 0.7386 - val_masked_rmse: 0.7044\n",
            "Epoch 434/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2129 - masked_rmse: 0.2585 - val_loss: 0.7376 - val_masked_rmse: 0.7014\n",
            "Epoch 435/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2137 - masked_rmse: 0.2585 - val_loss: 0.7403 - val_masked_rmse: 0.7053\n",
            "Epoch 436/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2130 - masked_rmse: 0.2583 - val_loss: 0.7306 - val_masked_rmse: 0.6962\n",
            "Epoch 437/500\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2121 - masked_rmse: 0.2565 - val_loss: 0.7369 - val_masked_rmse: 0.7009\n",
            "Epoch 438/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2114 - masked_rmse: 0.2556 - val_loss: 0.7370 - val_masked_rmse: 0.7021\n",
            "Epoch 439/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2115 - masked_rmse: 0.2561 - val_loss: 0.7346 - val_masked_rmse: 0.7013\n",
            "Epoch 440/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2111 - masked_rmse: 0.2547 - val_loss: 0.7377 - val_masked_rmse: 0.6988\n",
            "Epoch 441/500\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2121 - masked_rmse: 0.2565 - val_loss: 0.7372 - val_masked_rmse: 0.7021\n",
            "Epoch 442/500\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2111 - masked_rmse: 0.2560 - val_loss: 0.7312 - val_masked_rmse: 0.6984\n",
            "Epoch 00442: early stopping\n",
            "CPU times: user 11min 55s, sys: 1min 6s, total: 13min 1s\n",
            "Wall time: 10min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25rNsyqNr1qi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2ea281f4-e2f4-44b9-94f0-1234959ad00c"
      },
      "source": [
        "show_history(hist, 'loss', 'masked_rmse')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnzAcyi0O_J6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ae87de3-1771-4cc1-ece8-972f7dbfd17d"
      },
      "source": [
        "test_pred = make_predictor(test, model, n_item, batch_size, refeed = False)\n",
        "print(f'Mean of masked RMSE: {test_pred:.4f}')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of masked RMSE: 0.7029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xw_S_HgkiYH",
        "colab_type": "text"
      },
      "source": [
        "- No Dropout: 0.7029\n",
        "- 0.2: 0.7517\n",
        "- 0.4: 0.7987\n",
        "- 0.6: 0.8334\n",
        "- 0.8: 0.8667\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RqW69xohu70",
        "colab_type": "text"
      },
      "source": [
        "## 3. Re-feeding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF-Fd3g_J4tX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 500\n",
        "batch_size = 128\n",
        "\n",
        "train, valid, test = data_split(ratings)\n",
        "train, valid, test = map(make_interaction, (train, valid, test))\n",
        "train_gen, valid_gen = map(lambda x: make_generator(x, n_item, batch_size), (train, valid))\n",
        "\n",
        "steps_per_epoch = train.index.size // batch_size + 1\n",
        "validation_steps = valid.index.size // batch_size + 1"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqrnlLXlP4-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "6564d0dd-1513-4ed4-d8ec-f1ff139002c5"
      },
      "source": [
        "# optimizer = SGD(lr = 0.001, decay = 1e-5, momentum = 0.9, nesterov = True)\n",
        "optimizer = Adam(learning_rate = 0.001, decay = 1e-5)\n",
        "model = DeepAutoRec(n_item, n_layer = 2, latent_dim = 512, optimizer = optimizer, dropout_rate = 0.2)\n",
        "model.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_23\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 3706)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1 (Dense)               (None, 256)          948992      input[0][0]                      \n",
            "                                                                 output[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_2 (Dense)               (None, 512)          131584      encoder_1[0][0]                  \n",
            "                                                                 encoder_1[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           encoder_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_1 (Dense)               (None, 256)          131328      dropout[0][0]                    \n",
            "                                                                 encoder_2[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_2 (Dense)               (None, 3706)         952442      decoder_1[0][0]                  \n",
            "                                                                 decoder_1[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output (Layer)                  (None, 3706)         0           decoder_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "refeeded (Subtract)             (None, 3706)         0           output[0][0]                     \n",
            "                                                                 decoder_2[1][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,164,346\n",
            "Trainable params: 2,164,346\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQkcfiRbP5o1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64fab6ba-362a-49ad-9e71-d643696779b0"
      },
      "source": [
        "%%time\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 50)\n",
        "model_checkpoint = ModelCheckpoint('DeepAutoRec_1M.h5', monitor = 'val_loss', mode = 'min', save_best_only = True)\n",
        "\n",
        "hist = model.fit(x = train_gen, validation_data = valid_gen, epochs = epochs,\n",
        "                 steps_per_epoch = steps_per_epoch, validation_steps = validation_steps, \n",
        "                 verbose = 1, callbacks = [early_stopping, model_checkpoint])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 1/48 [..............................] - ETA: 0s - loss: 13.6903 - output_loss: 15.7314 - refeeded_loss: 2.8239 - output_masked_rmse: 3.9420 - refeeded_rmse: 1.6703WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0108s). Check your callbacks.\n",
            "48/48 [==============================] - 2s 39ms/step - loss: 3.7054 - output_loss: 3.7880 - refeeded_loss: 0.7264 - output_masked_rmse: 1.7536 - refeeded_rmse: 0.7767 - val_loss: 2.1290 - val_output_loss: 1.9371 - val_refeeded_loss: 0.3140 - val_output_masked_rmse: 1.2534 - val_refeeded_rmse: 0.5132\n",
            "Epoch 2/500\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 1.4667 - output_loss: 1.1711 - refeeded_loss: 0.1419 - output_masked_rmse: 1.0635 - refeeded_rmse: 0.3732 - val_loss: 2.0284 - val_output_loss: 1.8595 - val_refeeded_loss: 0.2784 - val_output_masked_rmse: 1.2285 - val_refeeded_rmse: 0.4797\n",
            "Epoch 3/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 1.3357 - output_loss: 1.0497 - refeeded_loss: 0.1277 - output_masked_rmse: 1.0070 - refeeded_rmse: 0.3520 - val_loss: 2.0411 - val_output_loss: 1.8876 - val_refeeded_loss: 0.3802 - val_output_masked_rmse: 1.2345 - val_refeeded_rmse: 0.5564\n",
            "Epoch 4/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 1.2471 - output_loss: 0.9767 - refeeded_loss: 0.1199 - output_masked_rmse: 0.9712 - refeeded_rmse: 0.3350 - val_loss: 1.9796 - val_output_loss: 1.8357 - val_refeeded_loss: 0.4151 - val_output_masked_rmse: 1.2155 - val_refeeded_rmse: 0.5938\n",
            "Epoch 5/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 1.1705 - output_loss: 0.9074 - refeeded_loss: 0.1418 - output_masked_rmse: 0.9359 - refeeded_rmse: 0.3671 - val_loss: 1.8865 - val_output_loss: 1.7830 - val_refeeded_loss: 0.2817 - val_output_masked_rmse: 1.1984 - val_refeeded_rmse: 0.5022\n",
            "Epoch 6/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 1.0886 - output_loss: 0.8412 - refeeded_loss: 0.1126 - output_masked_rmse: 0.9003 - refeeded_rmse: 0.3274 - val_loss: 1.9324 - val_output_loss: 1.8703 - val_refeeded_loss: 0.2711 - val_output_masked_rmse: 1.2228 - val_refeeded_rmse: 0.4820\n",
            "Epoch 7/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 1.0200 - output_loss: 0.7837 - refeeded_loss: 0.1035 - output_masked_rmse: 0.8683 - refeeded_rmse: 0.3133 - val_loss: 1.7698 - val_output_loss: 1.7086 - val_refeeded_loss: 0.2041 - val_output_masked_rmse: 1.1699 - val_refeeded_rmse: 0.4206\n",
            "Epoch 8/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.9598 - output_loss: 0.7339 - refeeded_loss: 0.0968 - output_masked_rmse: 0.8388 - refeeded_rmse: 0.3023 - val_loss: 1.7403 - val_output_loss: 1.6910 - val_refeeded_loss: 0.2174 - val_output_masked_rmse: 1.1663 - val_refeeded_rmse: 0.4384\n",
            "Epoch 9/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.9135 - output_loss: 0.6927 - refeeded_loss: 0.1178 - output_masked_rmse: 0.8135 - refeeded_rmse: 0.3315 - val_loss: 1.6373 - val_output_loss: 1.5954 - val_refeeded_loss: 0.1673 - val_output_masked_rmse: 1.1289 - val_refeeded_rmse: 0.3877\n",
            "Epoch 10/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.8616 - output_loss: 0.6532 - refeeded_loss: 0.0949 - output_masked_rmse: 0.7884 - refeeded_rmse: 0.2991 - val_loss: 1.6374 - val_output_loss: 1.6171 - val_refeeded_loss: 0.1572 - val_output_masked_rmse: 1.1411 - val_refeeded_rmse: 0.3799\n",
            "Epoch 11/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.8190 - output_loss: 0.6181 - refeeded_loss: 0.0955 - output_masked_rmse: 0.7656 - refeeded_rmse: 0.3002 - val_loss: 1.5673 - val_output_loss: 1.5197 - val_refeeded_loss: 0.2664 - val_output_masked_rmse: 1.1068 - val_refeeded_rmse: 0.4908\n",
            "Epoch 12/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.7802 - output_loss: 0.5879 - refeeded_loss: 0.0896 - output_masked_rmse: 0.7452 - refeeded_rmse: 0.2901 - val_loss: 1.4895 - val_output_loss: 1.4660 - val_refeeded_loss: 0.1568 - val_output_masked_rmse: 1.0856 - val_refeeded_rmse: 0.3809\n",
            "Epoch 13/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.7505 - output_loss: 0.5657 - refeeded_loss: 0.0912 - output_masked_rmse: 0.7292 - refeeded_rmse: 0.2930 - val_loss: 1.4846 - val_output_loss: 1.4711 - val_refeeded_loss: 0.1700 - val_output_masked_rmse: 1.0885 - val_refeeded_rmse: 0.3952\n",
            "Epoch 14/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.7160 - output_loss: 0.5375 - refeeded_loss: 0.0888 - output_masked_rmse: 0.7090 - refeeded_rmse: 0.2892 - val_loss: 1.4191 - val_output_loss: 1.3953 - val_refeeded_loss: 0.2006 - val_output_masked_rmse: 1.0569 - val_refeeded_rmse: 0.4297\n",
            "Epoch 15/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.6900 - output_loss: 0.5175 - refeeded_loss: 0.0915 - output_masked_rmse: 0.6942 - refeeded_rmse: 0.2941 - val_loss: 1.4168 - val_output_loss: 1.3853 - val_refeeded_loss: 0.2797 - val_output_masked_rmse: 1.0520 - val_refeeded_rmse: 0.5063\n",
            "Epoch 16/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.6667 - output_loss: 0.5008 - refeeded_loss: 0.0899 - output_masked_rmse: 0.6818 - refeeded_rmse: 0.2907 - val_loss: 1.3285 - val_output_loss: 1.2973 - val_refeeded_loss: 0.2354 - val_output_masked_rmse: 1.0269 - val_refeeded_rmse: 0.4588\n",
            "Epoch 17/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.6452 - output_loss: 0.4852 - refeeded_loss: 0.0872 - output_masked_rmse: 0.6692 - refeeded_rmse: 0.2871 - val_loss: 1.3338 - val_output_loss: 1.3367 - val_refeeded_loss: 0.1457 - val_output_masked_rmse: 1.0388 - val_refeeded_rmse: 0.3671\n",
            "Epoch 18/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.6177 - output_loss: 0.4618 - refeeded_loss: 0.0841 - output_masked_rmse: 0.6512 - refeeded_rmse: 0.2807 - val_loss: 1.3193 - val_output_loss: 1.2992 - val_refeeded_loss: 0.2634 - val_output_masked_rmse: 1.0236 - val_refeeded_rmse: 0.4884\n",
            "Epoch 19/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.5971 - output_loss: 0.4460 - refeeded_loss: 0.0833 - output_masked_rmse: 0.6391 - refeeded_rmse: 0.2805 - val_loss: 1.3030 - val_output_loss: 1.3010 - val_refeeded_loss: 0.2120 - val_output_masked_rmse: 1.0223 - val_refeeded_rmse: 0.4361\n",
            "Epoch 20/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.5790 - output_loss: 0.4324 - refeeded_loss: 0.0839 - output_masked_rmse: 0.6281 - refeeded_rmse: 0.2818 - val_loss: 1.2877 - val_output_loss: 1.3046 - val_refeeded_loss: 0.1560 - val_output_masked_rmse: 1.0271 - val_refeeded_rmse: 0.3797\n",
            "Epoch 21/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.5646 - output_loss: 0.4221 - refeeded_loss: 0.0855 - output_masked_rmse: 0.6200 - refeeded_rmse: 0.2846 - val_loss: 1.2538 - val_output_loss: 1.2813 - val_refeeded_loss: 0.1106 - val_output_masked_rmse: 1.0125 - val_refeeded_rmse: 0.3226\n",
            "Epoch 22/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.5495 - output_loss: 0.4107 - refeeded_loss: 0.0856 - output_masked_rmse: 0.6108 - refeeded_rmse: 0.2849 - val_loss: 1.1951 - val_output_loss: 1.2116 - val_refeeded_loss: 0.1248 - val_output_masked_rmse: 0.9877 - val_refeeded_rmse: 0.3403\n",
            "Epoch 23/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.5350 - output_loss: 0.4000 - refeeded_loss: 0.0842 - output_masked_rmse: 0.6019 - refeeded_rmse: 0.2828 - val_loss: 1.2546 - val_output_loss: 1.2736 - val_refeeded_loss: 0.2015 - val_output_masked_rmse: 1.0135 - val_refeeded_rmse: 0.4318\n",
            "Epoch 24/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.5200 - output_loss: 0.3887 - refeeded_loss: 0.0799 - output_masked_rmse: 0.5922 - refeeded_rmse: 0.2757 - val_loss: 1.2014 - val_output_loss: 1.2263 - val_refeeded_loss: 0.1494 - val_output_masked_rmse: 0.9972 - val_refeeded_rmse: 0.3716\n",
            "Epoch 25/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.5094 - output_loss: 0.3803 - refeeded_loss: 0.0849 - output_masked_rmse: 0.5854 - refeeded_rmse: 0.2845 - val_loss: 1.1735 - val_output_loss: 1.2067 - val_refeeded_loss: 0.1119 - val_output_masked_rmse: 0.9847 - val_refeeded_rmse: 0.3232\n",
            "Epoch 26/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.4965 - output_loss: 0.3707 - refeeded_loss: 0.0811 - output_masked_rmse: 0.5773 - refeeded_rmse: 0.2781 - val_loss: 1.1482 - val_output_loss: 1.1770 - val_refeeded_loss: 0.1253 - val_output_masked_rmse: 0.9762 - val_refeeded_rmse: 0.3399\n",
            "Epoch 27/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.4870 - output_loss: 0.3642 - refeeded_loss: 0.0800 - output_masked_rmse: 0.5709 - refeeded_rmse: 0.2759 - val_loss: 1.1509 - val_output_loss: 1.1810 - val_refeeded_loss: 0.1419 - val_output_masked_rmse: 0.9772 - val_refeeded_rmse: 0.3633\n",
            "Epoch 28/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.4759 - output_loss: 0.3556 - refeeded_loss: 0.0774 - output_masked_rmse: 0.5643 - refeeded_rmse: 0.2716 - val_loss: 1.1424 - val_output_loss: 1.1541 - val_refeeded_loss: 0.2253 - val_output_masked_rmse: 0.9639 - val_refeeded_rmse: 0.4568\n",
            "Epoch 29/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.4682 - output_loss: 0.3490 - refeeded_loss: 0.0835 - output_masked_rmse: 0.5583 - refeeded_rmse: 0.2824 - val_loss: 1.1026 - val_output_loss: 1.1378 - val_refeeded_loss: 0.1091 - val_output_masked_rmse: 0.9592 - val_refeeded_rmse: 0.3189\n",
            "Epoch 30/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.4650 - output_loss: 0.3485 - refeeded_loss: 0.0847 - output_masked_rmse: 0.5580 - refeeded_rmse: 0.2845 - val_loss: 1.0752 - val_output_loss: 1.1007 - val_refeeded_loss: 0.1328 - val_output_masked_rmse: 0.9460 - val_refeeded_rmse: 0.3469\n",
            "Epoch 31/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.4503 - output_loss: 0.3357 - refeeded_loss: 0.0768 - output_masked_rmse: 0.5477 - refeeded_rmse: 0.2708 - val_loss: 1.0742 - val_output_loss: 1.1030 - val_refeeded_loss: 0.1350 - val_output_masked_rmse: 0.9462 - val_refeeded_rmse: 0.3503\n",
            "Epoch 32/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.4447 - output_loss: 0.3325 - refeeded_loss: 0.0760 - output_masked_rmse: 0.5443 - refeeded_rmse: 0.2696 - val_loss: 1.0936 - val_output_loss: 1.1290 - val_refeeded_loss: 0.1414 - val_output_masked_rmse: 0.9555 - val_refeeded_rmse: 0.3636\n",
            "Epoch 33/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.4366 - output_loss: 0.3257 - refeeded_loss: 0.0759 - output_masked_rmse: 0.5386 - refeeded_rmse: 0.2696 - val_loss: 1.0566 - val_output_loss: 1.0996 - val_refeeded_loss: 0.0866 - val_output_masked_rmse: 0.9479 - val_refeeded_rmse: 0.2866\n",
            "Epoch 34/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.4321 - output_loss: 0.3220 - refeeded_loss: 0.0797 - output_masked_rmse: 0.5355 - refeeded_rmse: 0.2767 - val_loss: 1.0567 - val_output_loss: 1.0756 - val_refeeded_loss: 0.1936 - val_output_masked_rmse: 0.9323 - val_refeeded_rmse: 0.4238\n",
            "Epoch 35/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.4307 - output_loss: 0.3202 - refeeded_loss: 0.0904 - output_masked_rmse: 0.5339 - refeeded_rmse: 0.2946 - val_loss: 1.0341 - val_output_loss: 1.0763 - val_refeeded_loss: 0.0884 - val_output_masked_rmse: 0.9344 - val_refeeded_rmse: 0.2888\n",
            "Epoch 36/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.4220 - output_loss: 0.3137 - refeeded_loss: 0.0833 - output_masked_rmse: 0.5286 - refeeded_rmse: 0.2830 - val_loss: 1.0635 - val_output_loss: 1.1169 - val_refeeded_loss: 0.0835 - val_output_masked_rmse: 0.9527 - val_refeeded_rmse: 0.2830\n",
            "Epoch 37/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.4160 - output_loss: 0.3081 - refeeded_loss: 0.0858 - output_masked_rmse: 0.5234 - refeeded_rmse: 0.2863 - val_loss: 1.0015 - val_output_loss: 1.0396 - val_refeeded_loss: 0.0915 - val_output_masked_rmse: 0.9216 - val_refeeded_rmse: 0.2949\n",
            "Epoch 38/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.4083 - output_loss: 0.3028 - refeeded_loss: 0.0775 - output_masked_rmse: 0.5183 - refeeded_rmse: 0.2729 - val_loss: 1.0243 - val_output_loss: 1.0658 - val_refeeded_loss: 0.1098 - val_output_masked_rmse: 0.9320 - val_refeeded_rmse: 0.3211\n",
            "Epoch 39/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.4045 - output_loss: 0.3004 - refeeded_loss: 0.0773 - output_masked_rmse: 0.5160 - refeeded_rmse: 0.2725 - val_loss: 0.9679 - val_output_loss: 1.0046 - val_refeeded_loss: 0.0810 - val_output_masked_rmse: 0.9072 - val_refeeded_rmse: 0.2773\n",
            "Epoch 40/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.4028 - output_loss: 0.2990 - refeeded_loss: 0.0812 - output_masked_rmse: 0.5152 - refeeded_rmse: 0.2798 - val_loss: 0.9739 - val_output_loss: 1.0117 - val_refeeded_loss: 0.0883 - val_output_masked_rmse: 0.9090 - val_refeeded_rmse: 0.2887\n",
            "Epoch 41/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.4010 - output_loss: 0.2966 - refeeded_loss: 0.0872 - output_masked_rmse: 0.5134 - refeeded_rmse: 0.2892 - val_loss: 0.9886 - val_output_loss: 1.0096 - val_refeeded_loss: 0.1768 - val_output_masked_rmse: 0.9062 - val_refeeded_rmse: 0.4046\n",
            "Epoch 42/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3947 - output_loss: 0.2930 - refeeded_loss: 0.0768 - output_masked_rmse: 0.5102 - refeeded_rmse: 0.2718 - val_loss: 0.9363 - val_output_loss: 0.9698 - val_refeeded_loss: 0.0808 - val_output_masked_rmse: 0.8893 - val_refeeded_rmse: 0.2755\n",
            "Epoch 43/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3913 - output_loss: 0.2895 - refeeded_loss: 0.0806 - output_masked_rmse: 0.5069 - refeeded_rmse: 0.2789 - val_loss: 0.9478 - val_output_loss: 0.9626 - val_refeeded_loss: 0.1735 - val_output_masked_rmse: 0.8873 - val_refeeded_rmse: 0.4014\n",
            "Epoch 44/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3876 - output_loss: 0.2855 - refeeded_loss: 0.0841 - output_masked_rmse: 0.5033 - refeeded_rmse: 0.2851 - val_loss: 0.9328 - val_output_loss: 0.9632 - val_refeeded_loss: 0.1022 - val_output_masked_rmse: 0.8887 - val_refeeded_rmse: 0.3090\n",
            "Epoch 45/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3822 - output_loss: 0.2818 - refeeded_loss: 0.0777 - output_masked_rmse: 0.4998 - refeeded_rmse: 0.2737 - val_loss: 0.9339 - val_output_loss: 0.9549 - val_refeeded_loss: 0.1462 - val_output_masked_rmse: 0.8829 - val_refeeded_rmse: 0.3683\n",
            "Epoch 46/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3813 - output_loss: 0.2807 - refeeded_loss: 0.0827 - output_masked_rmse: 0.4991 - refeeded_rmse: 0.2829 - val_loss: 0.9522 - val_output_loss: 0.9954 - val_refeeded_loss: 0.0799 - val_output_masked_rmse: 0.9010 - val_refeeded_rmse: 0.2753\n",
            "Epoch 47/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3771 - output_loss: 0.2769 - refeeded_loss: 0.0813 - output_masked_rmse: 0.4957 - refeeded_rmse: 0.2805 - val_loss: 0.9286 - val_output_loss: 0.9528 - val_refeeded_loss: 0.1379 - val_output_masked_rmse: 0.8828 - val_refeeded_rmse: 0.3581\n",
            "Epoch 48/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3752 - output_loss: 0.2759 - refeeded_loss: 0.0802 - output_masked_rmse: 0.4950 - refeeded_rmse: 0.2786 - val_loss: 0.9363 - val_output_loss: 0.9493 - val_refeeded_loss: 0.1935 - val_output_masked_rmse: 0.8809 - val_refeeded_rmse: 0.4275\n",
            "Epoch 49/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3746 - output_loss: 0.2754 - refeeded_loss: 0.0830 - output_masked_rmse: 0.4940 - refeeded_rmse: 0.2835 - val_loss: 0.8996 - val_output_loss: 0.9292 - val_refeeded_loss: 0.0940 - val_output_masked_rmse: 0.8726 - val_refeeded_rmse: 0.2953\n",
            "Epoch 50/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3709 - output_loss: 0.2719 - refeeded_loss: 0.0819 - output_masked_rmse: 0.4911 - refeeded_rmse: 0.2815 - val_loss: 0.9443 - val_output_loss: 0.9873 - val_refeeded_loss: 0.0890 - val_output_masked_rmse: 0.8974 - val_refeeded_rmse: 0.2884\n",
            "Epoch 51/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3677 - output_loss: 0.2687 - refeeded_loss: 0.0823 - output_masked_rmse: 0.4882 - refeeded_rmse: 0.2824 - val_loss: 0.8940 - val_output_loss: 0.9176 - val_refeeded_loss: 0.1198 - val_output_masked_rmse: 0.8676 - val_refeeded_rmse: 0.3358\n",
            "Epoch 52/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3648 - output_loss: 0.2665 - refeeded_loss: 0.0809 - output_masked_rmse: 0.4866 - refeeded_rmse: 0.2799 - val_loss: 0.8814 - val_output_loss: 0.9083 - val_refeeded_loss: 0.0980 - val_output_masked_rmse: 0.8632 - val_refeeded_rmse: 0.3032\n",
            "Epoch 53/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3697 - output_loss: 0.2725 - refeeded_loss: 0.0838 - output_masked_rmse: 0.4924 - refeeded_rmse: 0.2852 - val_loss: 0.8938 - val_output_loss: 0.9274 - val_refeeded_loss: 0.0845 - val_output_masked_rmse: 0.8720 - val_refeeded_rmse: 0.2824\n",
            "Epoch 54/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3643 - output_loss: 0.2663 - refeeded_loss: 0.0829 - output_masked_rmse: 0.4867 - refeeded_rmse: 0.2835 - val_loss: 0.8952 - val_output_loss: 0.9308 - val_refeeded_loss: 0.0815 - val_output_masked_rmse: 0.8739 - val_refeeded_rmse: 0.2775\n",
            "Epoch 55/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3602 - output_loss: 0.2624 - refeeded_loss: 0.0814 - output_masked_rmse: 0.4828 - refeeded_rmse: 0.2809 - val_loss: 0.8954 - val_output_loss: 0.9244 - val_refeeded_loss: 0.1108 - val_output_masked_rmse: 0.8726 - val_refeeded_rmse: 0.3235\n",
            "Epoch 56/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3579 - output_loss: 0.2604 - refeeded_loss: 0.0809 - output_masked_rmse: 0.4804 - refeeded_rmse: 0.2800 - val_loss: 0.8882 - val_output_loss: 0.9276 - val_refeeded_loss: 0.0650 - val_output_masked_rmse: 0.8730 - val_refeeded_rmse: 0.2504\n",
            "Epoch 57/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3589 - output_loss: 0.2597 - refeeded_loss: 0.0913 - output_masked_rmse: 0.4797 - refeeded_rmse: 0.2971 - val_loss: 0.8886 - val_output_loss: 0.9155 - val_refeeded_loss: 0.1173 - val_output_masked_rmse: 0.8641 - val_refeeded_rmse: 0.3306\n",
            "Epoch 58/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3544 - output_loss: 0.2569 - refeeded_loss: 0.0823 - output_masked_rmse: 0.4773 - refeeded_rmse: 0.2827 - val_loss: 0.8695 - val_output_loss: 0.9032 - val_refeeded_loss: 0.0734 - val_output_masked_rmse: 0.8621 - val_refeeded_rmse: 0.2637\n",
            "Epoch 59/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3524 - output_loss: 0.2545 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4750 - refeeded_rmse: 0.2860 - val_loss: 0.8754 - val_output_loss: 0.9098 - val_refeeded_loss: 0.0788 - val_output_masked_rmse: 0.8668 - val_refeeded_rmse: 0.2722\n",
            "Epoch 60/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3513 - output_loss: 0.2530 - refeeded_loss: 0.0868 - output_masked_rmse: 0.4739 - refeeded_rmse: 0.2903 - val_loss: 0.8686 - val_output_loss: 0.9028 - val_refeeded_loss: 0.0747 - val_output_masked_rmse: 0.8592 - val_refeeded_rmse: 0.2651\n",
            "Epoch 61/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3485 - output_loss: 0.2515 - refeeded_loss: 0.0806 - output_masked_rmse: 0.4725 - refeeded_rmse: 0.2797 - val_loss: 0.8717 - val_output_loss: 0.9061 - val_refeeded_loss: 0.0787 - val_output_masked_rmse: 0.8628 - val_refeeded_rmse: 0.2722\n",
            "Epoch 62/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3471 - output_loss: 0.2497 - refeeded_loss: 0.0833 - output_masked_rmse: 0.4709 - refeeded_rmse: 0.2845 - val_loss: 0.8640 - val_output_loss: 0.8986 - val_refeeded_loss: 0.0729 - val_output_masked_rmse: 0.8609 - val_refeeded_rmse: 0.2638\n",
            "Epoch 63/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3463 - output_loss: 0.2497 - refeeded_loss: 0.0811 - output_masked_rmse: 0.4712 - refeeded_rmse: 0.2806 - val_loss: 0.8563 - val_output_loss: 0.8858 - val_refeeded_loss: 0.0874 - val_output_masked_rmse: 0.8525 - val_refeeded_rmse: 0.2871\n",
            "Epoch 64/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3449 - output_loss: 0.2483 - refeeded_loss: 0.0819 - output_masked_rmse: 0.4694 - refeeded_rmse: 0.2822 - val_loss: 0.8471 - val_output_loss: 0.8757 - val_refeeded_loss: 0.0833 - val_output_masked_rmse: 0.8486 - val_refeeded_rmse: 0.2802\n",
            "Epoch 65/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3438 - output_loss: 0.2474 - refeeded_loss: 0.0806 - output_masked_rmse: 0.4685 - refeeded_rmse: 0.2797 - val_loss: 0.8522 - val_output_loss: 0.8766 - val_refeeded_loss: 0.1051 - val_output_masked_rmse: 0.8516 - val_refeeded_rmse: 0.3146\n",
            "Epoch 66/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3431 - output_loss: 0.2451 - refeeded_loss: 0.0873 - output_masked_rmse: 0.4666 - refeeded_rmse: 0.2913 - val_loss: 0.8521 - val_output_loss: 0.8885 - val_refeeded_loss: 0.0598 - val_output_masked_rmse: 0.8549 - val_refeeded_rmse: 0.2395\n",
            "Epoch 67/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3422 - output_loss: 0.2452 - refeeded_loss: 0.0844 - output_masked_rmse: 0.4663 - refeeded_rmse: 0.2862 - val_loss: 0.8123 - val_output_loss: 0.8347 - val_refeeded_loss: 0.0767 - val_output_masked_rmse: 0.8321 - val_refeeded_rmse: 0.2734\n",
            "Epoch 68/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3431 - output_loss: 0.2458 - refeeded_loss: 0.0874 - output_masked_rmse: 0.4671 - refeeded_rmse: 0.2916 - val_loss: 0.8594 - val_output_loss: 0.8956 - val_refeeded_loss: 0.0693 - val_output_masked_rmse: 0.8571 - val_refeeded_rmse: 0.2585\n",
            "Epoch 69/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3410 - output_loss: 0.2442 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4661 - refeeded_rmse: 0.2861 - val_loss: 0.8375 - val_output_loss: 0.8604 - val_refeeded_loss: 0.1016 - val_output_masked_rmse: 0.8454 - val_refeeded_rmse: 0.3121\n",
            "Epoch 70/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3399 - output_loss: 0.2436 - refeeded_loss: 0.0820 - output_masked_rmse: 0.4649 - refeeded_rmse: 0.2825 - val_loss: 0.8067 - val_output_loss: 0.8338 - val_refeeded_loss: 0.0561 - val_output_masked_rmse: 0.8287 - val_refeeded_rmse: 0.2321\n",
            "Epoch 71/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.3406 - output_loss: 0.2439 - refeeded_loss: 0.0850 - output_masked_rmse: 0.4657 - refeeded_rmse: 0.2877 - val_loss: 0.8039 - val_output_loss: 0.8300 - val_refeeded_loss: 0.0570 - val_output_masked_rmse: 0.8314 - val_refeeded_rmse: 0.2349\n",
            "Epoch 72/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3378 - output_loss: 0.2406 - refeeded_loss: 0.0849 - output_masked_rmse: 0.4623 - refeeded_rmse: 0.2875 - val_loss: 0.8132 - val_output_loss: 0.8378 - val_refeeded_loss: 0.0735 - val_output_masked_rmse: 0.8300 - val_refeeded_rmse: 0.2664\n",
            "Epoch 73/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3365 - output_loss: 0.2400 - refeeded_loss: 0.0822 - output_masked_rmse: 0.4616 - refeeded_rmse: 0.2828 - val_loss: 0.8215 - val_output_loss: 0.8534 - val_refeeded_loss: 0.0532 - val_output_masked_rmse: 0.8407 - val_refeeded_rmse: 0.2266\n",
            "Epoch 74/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3378 - output_loss: 0.2405 - refeeded_loss: 0.0871 - output_masked_rmse: 0.4621 - refeeded_rmse: 0.2914 - val_loss: 0.8099 - val_output_loss: 0.8365 - val_refeeded_loss: 0.0641 - val_output_masked_rmse: 0.8338 - val_refeeded_rmse: 0.2487\n",
            "Epoch 75/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3372 - output_loss: 0.2407 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4628 - refeeded_rmse: 0.2866 - val_loss: 0.7938 - val_output_loss: 0.8146 - val_refeeded_loss: 0.0711 - val_output_masked_rmse: 0.8174 - val_refeeded_rmse: 0.2621\n",
            "Epoch 76/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3341 - output_loss: 0.2374 - refeeded_loss: 0.0830 - output_masked_rmse: 0.4596 - refeeded_rmse: 0.2843 - val_loss: 0.8101 - val_output_loss: 0.8380 - val_refeeded_loss: 0.0607 - val_output_masked_rmse: 0.8353 - val_refeeded_rmse: 0.2424\n",
            "Epoch 77/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3308 - output_loss: 0.2340 - refeeded_loss: 0.0818 - output_masked_rmse: 0.4566 - refeeded_rmse: 0.2821 - val_loss: 0.8082 - val_output_loss: 0.8351 - val_refeeded_loss: 0.0645 - val_output_masked_rmse: 0.8280 - val_refeeded_rmse: 0.2490\n",
            "Epoch 78/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3305 - output_loss: 0.2332 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4554 - refeeded_rmse: 0.2873 - val_loss: 0.8208 - val_output_loss: 0.8419 - val_refeeded_loss: 0.1013 - val_output_masked_rmse: 0.8351 - val_refeeded_rmse: 0.3123\n",
            "Epoch 79/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3318 - output_loss: 0.2350 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4570 - refeeded_rmse: 0.2866 - val_loss: 0.7970 - val_output_loss: 0.8230 - val_refeeded_loss: 0.0582 - val_output_masked_rmse: 0.8245 - val_refeeded_rmse: 0.2373\n",
            "Epoch 80/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3299 - output_loss: 0.2321 - refeeded_loss: 0.0869 - output_masked_rmse: 0.4543 - refeeded_rmse: 0.2911 - val_loss: 0.8459 - val_output_loss: 0.8665 - val_refeeded_loss: 0.1290 - val_output_masked_rmse: 0.8447 - val_refeeded_rmse: 0.3515\n",
            "Epoch 81/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3295 - output_loss: 0.2324 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4545 - refeeded_rmse: 0.2863 - val_loss: 0.8137 - val_output_loss: 0.8332 - val_refeeded_loss: 0.1017 - val_output_masked_rmse: 0.8286 - val_refeeded_rmse: 0.3121\n",
            "Epoch 82/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3284 - output_loss: 0.2312 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4540 - refeeded_rmse: 0.2872 - val_loss: 0.8098 - val_output_loss: 0.8347 - val_refeeded_loss: 0.0774 - val_output_masked_rmse: 0.8305 - val_refeeded_rmse: 0.2709\n",
            "Epoch 83/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3273 - output_loss: 0.2300 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4529 - refeeded_rmse: 0.2873 - val_loss: 0.8089 - val_output_loss: 0.8333 - val_refeeded_loss: 0.0801 - val_output_masked_rmse: 0.8313 - val_refeeded_rmse: 0.2775\n",
            "Epoch 84/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3259 - output_loss: 0.2290 - refeeded_loss: 0.0829 - output_masked_rmse: 0.4514 - refeeded_rmse: 0.2843 - val_loss: 0.8045 - val_output_loss: 0.8323 - val_refeeded_loss: 0.0621 - val_output_masked_rmse: 0.8291 - val_refeeded_rmse: 0.2442\n",
            "Epoch 85/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3297 - output_loss: 0.2319 - refeeded_loss: 0.0907 - output_masked_rmse: 0.4544 - refeeded_rmse: 0.2977 - val_loss: 0.8259 - val_output_loss: 0.8554 - val_refeeded_loss: 0.0766 - val_output_masked_rmse: 0.8408 - val_refeeded_rmse: 0.2701\n",
            "Epoch 86/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3286 - output_loss: 0.2319 - refeeded_loss: 0.0849 - output_masked_rmse: 0.4549 - refeeded_rmse: 0.2876 - val_loss: 0.8202 - val_output_loss: 0.8441 - val_refeeded_loss: 0.0927 - val_output_masked_rmse: 0.8356 - val_refeeded_rmse: 0.2969\n",
            "Epoch 87/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3273 - output_loss: 0.2300 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4526 - refeeded_rmse: 0.2883 - val_loss: 0.8191 - val_output_loss: 0.8372 - val_refeeded_loss: 0.1150 - val_output_masked_rmse: 0.8329 - val_refeeded_rmse: 0.3311\n",
            "Epoch 88/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3251 - output_loss: 0.2275 - refeeded_loss: 0.0855 - output_masked_rmse: 0.4501 - refeeded_rmse: 0.2888 - val_loss: 0.8086 - val_output_loss: 0.8321 - val_refeeded_loss: 0.0847 - val_output_masked_rmse: 0.8301 - val_refeeded_rmse: 0.2839\n",
            "Epoch 89/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3239 - output_loss: 0.2262 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4492 - refeeded_rmse: 0.2883 - val_loss: 0.8133 - val_output_loss: 0.8426 - val_refeeded_loss: 0.0671 - val_output_masked_rmse: 0.8353 - val_refeeded_rmse: 0.2543\n",
            "Epoch 90/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3237 - output_loss: 0.2258 - refeeded_loss: 0.0868 - output_masked_rmse: 0.4485 - refeeded_rmse: 0.2910 - val_loss: 0.8009 - val_output_loss: 0.8269 - val_refeeded_loss: 0.0681 - val_output_masked_rmse: 0.8278 - val_refeeded_rmse: 0.2556\n",
            "Epoch 91/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3245 - output_loss: 0.2275 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4503 - refeeded_rmse: 0.2873 - val_loss: 0.8152 - val_output_loss: 0.8455 - val_refeeded_loss: 0.0656 - val_output_masked_rmse: 0.8357 - val_refeeded_rmse: 0.2518\n",
            "Epoch 92/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3238 - output_loss: 0.2270 - refeeded_loss: 0.0833 - output_masked_rmse: 0.4500 - refeeded_rmse: 0.2850 - val_loss: 0.7978 - val_output_loss: 0.8262 - val_refeeded_loss: 0.0557 - val_output_masked_rmse: 0.8268 - val_refeeded_rmse: 0.2319\n",
            "Epoch 93/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3231 - output_loss: 0.2258 - refeeded_loss: 0.0850 - output_masked_rmse: 0.4486 - refeeded_rmse: 0.2880 - val_loss: 0.7988 - val_output_loss: 0.8283 - val_refeeded_loss: 0.0526 - val_output_masked_rmse: 0.8289 - val_refeeded_rmse: 0.2250\n",
            "Epoch 94/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3226 - output_loss: 0.2249 - refeeded_loss: 0.0868 - output_masked_rmse: 0.4477 - refeeded_rmse: 0.2910 - val_loss: 0.8032 - val_output_loss: 0.8312 - val_refeeded_loss: 0.0645 - val_output_masked_rmse: 0.8292 - val_refeeded_rmse: 0.2494\n",
            "Epoch 95/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3225 - output_loss: 0.2253 - refeeded_loss: 0.0850 - output_masked_rmse: 0.4478 - refeeded_rmse: 0.2880 - val_loss: 0.7904 - val_output_loss: 0.8155 - val_refeeded_loss: 0.0631 - val_output_masked_rmse: 0.8253 - val_refeeded_rmse: 0.2462\n",
            "Epoch 96/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.3199 - output_loss: 0.2226 - refeeded_loss: 0.0834 - output_masked_rmse: 0.4454 - refeeded_rmse: 0.2851 - val_loss: 0.7784 - val_output_loss: 0.7992 - val_refeeded_loss: 0.0686 - val_output_masked_rmse: 0.8136 - val_refeeded_rmse: 0.2571\n",
            "Epoch 97/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3202 - output_loss: 0.2227 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4456 - refeeded_rmse: 0.2886 - val_loss: 0.8050 - val_output_loss: 0.8355 - val_refeeded_loss: 0.0577 - val_output_masked_rmse: 0.8304 - val_refeeded_rmse: 0.2365\n",
            "Epoch 98/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3188 - output_loss: 0.2211 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4437 - refeeded_rmse: 0.2893 - val_loss: 0.7954 - val_output_loss: 0.8236 - val_refeeded_loss: 0.0573 - val_output_masked_rmse: 0.8255 - val_refeeded_rmse: 0.2352\n",
            "Epoch 99/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3185 - output_loss: 0.2206 - refeeded_loss: 0.0850 - output_masked_rmse: 0.4435 - refeeded_rmse: 0.2880 - val_loss: 0.7921 - val_output_loss: 0.8208 - val_refeeded_loss: 0.0524 - val_output_masked_rmse: 0.8265 - val_refeeded_rmse: 0.2251\n",
            "Epoch 100/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3210 - output_loss: 0.2225 - refeeded_loss: 0.0908 - output_masked_rmse: 0.4451 - refeeded_rmse: 0.2974 - val_loss: 0.7719 - val_output_loss: 0.7779 - val_refeeded_loss: 0.1227 - val_output_masked_rmse: 0.8028 - val_refeeded_rmse: 0.3464\n",
            "Epoch 101/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3201 - output_loss: 0.2222 - refeeded_loss: 0.0862 - output_masked_rmse: 0.4453 - refeeded_rmse: 0.2899 - val_loss: 0.7735 - val_output_loss: 0.7960 - val_refeeded_loss: 0.0573 - val_output_masked_rmse: 0.8142 - val_refeeded_rmse: 0.2361\n",
            "Epoch 102/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3169 - output_loss: 0.2189 - refeeded_loss: 0.0839 - output_masked_rmse: 0.4416 - refeeded_rmse: 0.2862 - val_loss: 0.7690 - val_output_loss: 0.7889 - val_refeeded_loss: 0.0642 - val_output_masked_rmse: 0.8100 - val_refeeded_rmse: 0.2503\n",
            "Epoch 103/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3163 - output_loss: 0.2181 - refeeded_loss: 0.0851 - output_masked_rmse: 0.4409 - refeeded_rmse: 0.2883 - val_loss: 0.7902 - val_output_loss: 0.8191 - val_refeeded_loss: 0.0503 - val_output_masked_rmse: 0.8247 - val_refeeded_rmse: 0.2209\n",
            "Epoch 104/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3201 - output_loss: 0.2218 - refeeded_loss: 0.0888 - output_masked_rmse: 0.4446 - refeeded_rmse: 0.2945 - val_loss: 0.7751 - val_output_loss: 0.8013 - val_refeeded_loss: 0.0459 - val_output_masked_rmse: 0.8156 - val_refeeded_rmse: 0.2110\n",
            "Epoch 105/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3191 - output_loss: 0.2212 - refeeded_loss: 0.0866 - output_masked_rmse: 0.4444 - refeeded_rmse: 0.2909 - val_loss: 0.7852 - val_output_loss: 0.8104 - val_refeeded_loss: 0.0602 - val_output_masked_rmse: 0.8208 - val_refeeded_rmse: 0.2417\n",
            "Epoch 106/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3201 - output_loss: 0.2227 - refeeded_loss: 0.0861 - output_masked_rmse: 0.4457 - refeeded_rmse: 0.2900 - val_loss: 0.7926 - val_output_loss: 0.8183 - val_refeeded_loss: 0.0646 - val_output_masked_rmse: 0.8263 - val_refeeded_rmse: 0.2501\n",
            "Epoch 107/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3181 - output_loss: 0.2202 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4432 - refeeded_rmse: 0.2885 - val_loss: 0.7560 - val_output_loss: 0.7741 - val_refeeded_loss: 0.0583 - val_output_masked_rmse: 0.8003 - val_refeeded_rmse: 0.2380\n",
            "Epoch 108/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3152 - output_loss: 0.2165 - refeeded_loss: 0.0866 - output_masked_rmse: 0.4396 - refeeded_rmse: 0.2907 - val_loss: 0.7812 - val_output_loss: 0.8091 - val_refeeded_loss: 0.0459 - val_output_masked_rmse: 0.8193 - val_refeeded_rmse: 0.2106\n",
            "Epoch 109/500\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.3155 - output_loss: 0.2171 - refeeded_loss: 0.0863 - output_masked_rmse: 0.4395 - refeeded_rmse: 0.2905 - val_loss: 0.7718 - val_output_loss: 0.7915 - val_refeeded_loss: 0.0696 - val_output_masked_rmse: 0.8129 - val_refeeded_rmse: 0.2606\n",
            "Epoch 110/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3146 - output_loss: 0.2163 - refeeded_loss: 0.0852 - output_masked_rmse: 0.4393 - refeeded_rmse: 0.2886 - val_loss: 0.7842 - val_output_loss: 0.8121 - val_refeeded_loss: 0.0492 - val_output_masked_rmse: 0.8196 - val_refeeded_rmse: 0.2188\n",
            "Epoch 111/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3162 - output_loss: 0.2176 - refeeded_loss: 0.0882 - output_masked_rmse: 0.4405 - refeeded_rmse: 0.2934 - val_loss: 0.7752 - val_output_loss: 0.7985 - val_refeeded_loss: 0.0593 - val_output_masked_rmse: 0.8155 - val_refeeded_rmse: 0.2407\n",
            "Epoch 112/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3142 - output_loss: 0.2163 - refeeded_loss: 0.0840 - output_masked_rmse: 0.4393 - refeeded_rmse: 0.2864 - val_loss: 0.7569 - val_output_loss: 0.7780 - val_refeeded_loss: 0.0502 - val_output_masked_rmse: 0.8060 - val_refeeded_rmse: 0.2213\n",
            "Epoch 113/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3128 - output_loss: 0.2145 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4375 - refeeded_rmse: 0.2868 - val_loss: 0.7660 - val_output_loss: 0.7906 - val_refeeded_loss: 0.0453 - val_output_masked_rmse: 0.8095 - val_refeeded_rmse: 0.2094\n",
            "Epoch 114/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3122 - output_loss: 0.2135 - refeeded_loss: 0.0866 - output_masked_rmse: 0.4362 - refeeded_rmse: 0.2909 - val_loss: 0.7684 - val_output_loss: 0.7934 - val_refeeded_loss: 0.0470 - val_output_masked_rmse: 0.8118 - val_refeeded_rmse: 0.2136\n",
            "Epoch 115/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3117 - output_loss: 0.2132 - refeeded_loss: 0.0855 - output_masked_rmse: 0.4360 - refeeded_rmse: 0.2890 - val_loss: 0.7580 - val_output_loss: 0.7720 - val_refeeded_loss: 0.0806 - val_output_masked_rmse: 0.7991 - val_refeeded_rmse: 0.2812\n",
            "Epoch 116/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3176 - output_loss: 0.2185 - refeeded_loss: 0.0932 - output_masked_rmse: 0.4406 - refeeded_rmse: 0.3015 - val_loss: 0.7708 - val_output_loss: 0.7931 - val_refeeded_loss: 0.0596 - val_output_masked_rmse: 0.8150 - val_refeeded_rmse: 0.2414\n",
            "Epoch 117/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3155 - output_loss: 0.2174 - refeeded_loss: 0.0866 - output_masked_rmse: 0.4402 - refeeded_rmse: 0.2910 - val_loss: 0.7648 - val_output_loss: 0.7875 - val_refeeded_loss: 0.0513 - val_output_masked_rmse: 0.8069 - val_refeeded_rmse: 0.2241\n",
            "Epoch 118/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3130 - output_loss: 0.2142 - refeeded_loss: 0.0872 - output_masked_rmse: 0.4372 - refeeded_rmse: 0.2921 - val_loss: 0.7850 - val_output_loss: 0.8145 - val_refeeded_loss: 0.0461 - val_output_masked_rmse: 0.8250 - val_refeeded_rmse: 0.2111\n",
            "Epoch 119/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3122 - output_loss: 0.2136 - refeeded_loss: 0.0859 - output_masked_rmse: 0.4364 - refeeded_rmse: 0.2896 - val_loss: 0.7388 - val_output_loss: 0.7568 - val_refeeded_loss: 0.0455 - val_output_masked_rmse: 0.7970 - val_refeeded_rmse: 0.2087\n",
            "Epoch 120/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3098 - output_loss: 0.2112 - refeeded_loss: 0.0845 - output_masked_rmse: 0.4340 - refeeded_rmse: 0.2872 - val_loss: 0.7429 - val_output_loss: 0.7643 - val_refeeded_loss: 0.0373 - val_output_masked_rmse: 0.7937 - val_refeeded_rmse: 0.1898\n",
            "Epoch 121/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3095 - output_loss: 0.2112 - refeeded_loss: 0.0838 - output_masked_rmse: 0.4344 - refeeded_rmse: 0.2861 - val_loss: 0.7319 - val_output_loss: 0.7503 - val_refeeded_loss: 0.0380 - val_output_masked_rmse: 0.7937 - val_refeeded_rmse: 0.1913\n",
            "Epoch 122/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3111 - output_loss: 0.2121 - refeeded_loss: 0.0869 - output_masked_rmse: 0.4349 - refeeded_rmse: 0.2914 - val_loss: 0.7543 - val_output_loss: 0.7764 - val_refeeded_loss: 0.0451 - val_output_masked_rmse: 0.8046 - val_refeeded_rmse: 0.2101\n",
            "Epoch 123/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3121 - output_loss: 0.2141 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4368 - refeeded_rmse: 0.2874 - val_loss: 0.7394 - val_output_loss: 0.7554 - val_refeeded_loss: 0.0552 - val_output_masked_rmse: 0.7922 - val_refeeded_rmse: 0.2335\n",
            "Epoch 124/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3130 - output_loss: 0.2143 - refeeded_loss: 0.0884 - output_masked_rmse: 0.4371 - refeeded_rmse: 0.2941 - val_loss: 0.7611 - val_output_loss: 0.7848 - val_refeeded_loss: 0.0456 - val_output_masked_rmse: 0.8076 - val_refeeded_rmse: 0.2115\n",
            "Epoch 125/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3105 - output_loss: 0.2119 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4350 - refeeded_rmse: 0.2878 - val_loss: 0.7557 - val_output_loss: 0.7755 - val_refeeded_loss: 0.0564 - val_output_masked_rmse: 0.8027 - val_refeeded_rmse: 0.2359\n",
            "Epoch 126/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3107 - output_loss: 0.2124 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4355 - refeeded_rmse: 0.2876 - val_loss: 0.7494 - val_output_loss: 0.7701 - val_refeeded_loss: 0.0471 - val_output_masked_rmse: 0.8024 - val_refeeded_rmse: 0.2142\n",
            "Epoch 127/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3130 - output_loss: 0.2137 - refeeded_loss: 0.0903 - output_masked_rmse: 0.4365 - refeeded_rmse: 0.2973 - val_loss: 0.7662 - val_output_loss: 0.7887 - val_refeeded_loss: 0.0546 - val_output_masked_rmse: 0.8070 - val_refeeded_rmse: 0.2320\n",
            "Epoch 128/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3092 - output_loss: 0.2104 - refeeded_loss: 0.0844 - output_masked_rmse: 0.4336 - refeeded_rmse: 0.2871 - val_loss: 0.7363 - val_output_loss: 0.7534 - val_refeeded_loss: 0.0477 - val_output_masked_rmse: 0.7936 - val_refeeded_rmse: 0.2166\n",
            "Epoch 129/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3082 - output_loss: 0.2091 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4320 - refeeded_rmse: 0.2877 - val_loss: 0.7572 - val_output_loss: 0.7809 - val_refeeded_loss: 0.0429 - val_output_masked_rmse: 0.8047 - val_refeeded_rmse: 0.2048\n",
            "Epoch 130/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3086 - output_loss: 0.2096 - refeeded_loss: 0.0859 - output_masked_rmse: 0.4322 - refeeded_rmse: 0.2897 - val_loss: 0.7510 - val_output_loss: 0.7732 - val_refeeded_loss: 0.0439 - val_output_masked_rmse: 0.8033 - val_refeeded_rmse: 0.2072\n",
            "Epoch 131/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3081 - output_loss: 0.2092 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4321 - refeeded_rmse: 0.2894 - val_loss: 0.7621 - val_output_loss: 0.7806 - val_refeeded_loss: 0.0699 - val_output_masked_rmse: 0.8061 - val_refeeded_rmse: 0.2622\n",
            "Epoch 132/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3066 - output_loss: 0.2077 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4306 - refeeded_rmse: 0.2877 - val_loss: 0.7449 - val_output_loss: 0.7661 - val_refeeded_loss: 0.0421 - val_output_masked_rmse: 0.7987 - val_refeeded_rmse: 0.2031\n",
            "Epoch 133/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3056 - output_loss: 0.2067 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4297 - refeeded_rmse: 0.2866 - val_loss: 0.7538 - val_output_loss: 0.7775 - val_refeeded_loss: 0.0410 - val_output_masked_rmse: 0.8038 - val_refeeded_rmse: 0.1999\n",
            "Epoch 134/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3070 - output_loss: 0.2077 - refeeded_loss: 0.0870 - output_masked_rmse: 0.4305 - refeeded_rmse: 0.2917 - val_loss: 0.7403 - val_output_loss: 0.7589 - val_refeeded_loss: 0.0472 - val_output_masked_rmse: 0.7942 - val_refeeded_rmse: 0.2153\n",
            "Epoch 135/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3074 - output_loss: 0.2074 - refeeded_loss: 0.0907 - output_masked_rmse: 0.4303 - refeeded_rmse: 0.2976 - val_loss: 0.7624 - val_output_loss: 0.7794 - val_refeeded_loss: 0.0771 - val_output_masked_rmse: 0.8064 - val_refeeded_rmse: 0.2760\n",
            "Epoch 136/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3073 - output_loss: 0.2081 - refeeded_loss: 0.0876 - output_masked_rmse: 0.4311 - refeeded_rmse: 0.2926 - val_loss: 0.7567 - val_output_loss: 0.7793 - val_refeeded_loss: 0.0493 - val_output_masked_rmse: 0.8053 - val_refeeded_rmse: 0.2204\n",
            "Epoch 137/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3067 - output_loss: 0.2078 - refeeded_loss: 0.0856 - output_masked_rmse: 0.4309 - refeeded_rmse: 0.2893 - val_loss: 0.7516 - val_output_loss: 0.7740 - val_refeeded_loss: 0.0444 - val_output_masked_rmse: 0.8027 - val_refeeded_rmse: 0.2086\n",
            "Epoch 138/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3054 - output_loss: 0.2062 - refeeded_loss: 0.0857 - output_masked_rmse: 0.4291 - refeeded_rmse: 0.2894 - val_loss: 0.7458 - val_output_loss: 0.7641 - val_refeeded_loss: 0.0551 - val_output_masked_rmse: 0.7984 - val_refeeded_rmse: 0.2333\n",
            "Epoch 139/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3058 - output_loss: 0.2060 - refeeded_loss: 0.0880 - output_masked_rmse: 0.4286 - refeeded_rmse: 0.2934 - val_loss: 0.7491 - val_output_loss: 0.7691 - val_refeeded_loss: 0.0523 - val_output_masked_rmse: 0.8001 - val_refeeded_rmse: 0.2272\n",
            "Epoch 140/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3042 - output_loss: 0.2053 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4280 - refeeded_rmse: 0.2855 - val_loss: 0.7484 - val_output_loss: 0.7692 - val_refeeded_loss: 0.0484 - val_output_masked_rmse: 0.7969 - val_refeeded_rmse: 0.2183\n",
            "Epoch 141/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3069 - output_loss: 0.2083 - refeeded_loss: 0.0840 - output_masked_rmse: 0.4311 - refeeded_rmse: 0.2866 - val_loss: 0.7629 - val_output_loss: 0.7882 - val_refeeded_loss: 0.0436 - val_output_masked_rmse: 0.8103 - val_refeeded_rmse: 0.2049\n",
            "Epoch 142/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3093 - output_loss: 0.2098 - refeeded_loss: 0.0899 - output_masked_rmse: 0.4329 - refeeded_rmse: 0.2965 - val_loss: 0.7462 - val_output_loss: 0.7675 - val_refeeded_loss: 0.0428 - val_output_masked_rmse: 0.7993 - val_refeeded_rmse: 0.2050\n",
            "Epoch 143/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3070 - output_loss: 0.2079 - refeeded_loss: 0.0865 - output_masked_rmse: 0.4311 - refeeded_rmse: 0.2908 - val_loss: 0.7360 - val_output_loss: 0.7520 - val_refeeded_loss: 0.0537 - val_output_masked_rmse: 0.7933 - val_refeeded_rmse: 0.2304\n",
            "Epoch 144/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3046 - output_loss: 0.2054 - refeeded_loss: 0.0850 - output_masked_rmse: 0.4283 - refeeded_rmse: 0.2882 - val_loss: 0.7441 - val_output_loss: 0.7642 - val_refeeded_loss: 0.0466 - val_output_masked_rmse: 0.7974 - val_refeeded_rmse: 0.2143\n",
            "Epoch 145/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3056 - output_loss: 0.2059 - refeeded_loss: 0.0885 - output_masked_rmse: 0.4288 - refeeded_rmse: 0.2942 - val_loss: 0.7438 - val_output_loss: 0.7649 - val_refeeded_loss: 0.0433 - val_output_masked_rmse: 0.8003 - val_refeeded_rmse: 0.2058\n",
            "Epoch 146/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3042 - output_loss: 0.2052 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4278 - refeeded_rmse: 0.2870 - val_loss: 0.7548 - val_output_loss: 0.7778 - val_refeeded_loss: 0.0459 - val_output_masked_rmse: 0.8038 - val_refeeded_rmse: 0.2123\n",
            "Epoch 147/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3038 - output_loss: 0.2039 - refeeded_loss: 0.0869 - output_masked_rmse: 0.4267 - refeeded_rmse: 0.2915 - val_loss: 0.7490 - val_output_loss: 0.7723 - val_refeeded_loss: 0.0389 - val_output_masked_rmse: 0.8011 - val_refeeded_rmse: 0.1943\n",
            "Epoch 148/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3025 - output_loss: 0.2032 - refeeded_loss: 0.0845 - output_masked_rmse: 0.4258 - refeeded_rmse: 0.2874 - val_loss: 0.7360 - val_output_loss: 0.7561 - val_refeeded_loss: 0.0398 - val_output_masked_rmse: 0.7921 - val_refeeded_rmse: 0.1968\n",
            "Epoch 149/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3039 - output_loss: 0.2050 - refeeded_loss: 0.0850 - output_masked_rmse: 0.4280 - refeeded_rmse: 0.2882 - val_loss: 0.7538 - val_output_loss: 0.7755 - val_refeeded_loss: 0.0515 - val_output_masked_rmse: 0.8025 - val_refeeded_rmse: 0.2256\n",
            "Epoch 150/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3041 - output_loss: 0.2049 - refeeded_loss: 0.0856 - output_masked_rmse: 0.4275 - refeeded_rmse: 0.2893 - val_loss: 0.7390 - val_output_loss: 0.7600 - val_refeeded_loss: 0.0391 - val_output_masked_rmse: 0.7977 - val_refeeded_rmse: 0.1948\n",
            "Epoch 151/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3014 - output_loss: 0.2021 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4248 - refeeded_rmse: 0.2866 - val_loss: 0.7422 - val_output_loss: 0.7590 - val_refeeded_loss: 0.0601 - val_output_masked_rmse: 0.7942 - val_refeeded_rmse: 0.2441\n",
            "Epoch 152/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3010 - output_loss: 0.2015 - refeeded_loss: 0.0849 - output_masked_rmse: 0.4240 - refeeded_rmse: 0.2881 - val_loss: 0.7465 - val_output_loss: 0.7697 - val_refeeded_loss: 0.0394 - val_output_masked_rmse: 0.8018 - val_refeeded_rmse: 0.1958\n",
            "Epoch 153/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3029 - output_loss: 0.2040 - refeeded_loss: 0.0844 - output_masked_rmse: 0.4266 - refeeded_rmse: 0.2873 - val_loss: 0.7379 - val_output_loss: 0.7582 - val_refeeded_loss: 0.0413 - val_output_masked_rmse: 0.7954 - val_refeeded_rmse: 0.2013\n",
            "Epoch 154/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3036 - output_loss: 0.2046 - refeeded_loss: 0.0852 - output_masked_rmse: 0.4274 - refeeded_rmse: 0.2886 - val_loss: 0.7358 - val_output_loss: 0.7560 - val_refeeded_loss: 0.0394 - val_output_masked_rmse: 0.7924 - val_refeeded_rmse: 0.1956\n",
            "Epoch 155/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3027 - output_loss: 0.2034 - refeeded_loss: 0.0852 - output_masked_rmse: 0.4265 - refeeded_rmse: 0.2887 - val_loss: 0.7319 - val_output_loss: 0.7514 - val_refeeded_loss: 0.0381 - val_output_masked_rmse: 0.7896 - val_refeeded_rmse: 0.1925\n",
            "Epoch 156/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3028 - output_loss: 0.2031 - refeeded_loss: 0.0874 - output_masked_rmse: 0.4261 - refeeded_rmse: 0.2924 - val_loss: 0.7338 - val_output_loss: 0.7531 - val_refeeded_loss: 0.0413 - val_output_masked_rmse: 0.7933 - val_refeeded_rmse: 0.2010\n",
            "Epoch 157/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.3011 - output_loss: 0.2016 - refeeded_loss: 0.0859 - output_masked_rmse: 0.4240 - refeeded_rmse: 0.2899 - val_loss: 0.7216 - val_output_loss: 0.7395 - val_refeeded_loss: 0.0367 - val_output_masked_rmse: 0.7843 - val_refeeded_rmse: 0.1884\n",
            "Epoch 158/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2999 - output_loss: 0.2008 - refeeded_loss: 0.0839 - output_masked_rmse: 0.4235 - refeeded_rmse: 0.2865 - val_loss: 0.7425 - val_output_loss: 0.7608 - val_refeeded_loss: 0.0555 - val_output_masked_rmse: 0.7935 - val_refeeded_rmse: 0.2344\n",
            "Epoch 159/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3004 - output_loss: 0.2008 - refeeded_loss: 0.0851 - output_masked_rmse: 0.4235 - refeeded_rmse: 0.2884 - val_loss: 0.7385 - val_output_loss: 0.7529 - val_refeeded_loss: 0.0665 - val_output_masked_rmse: 0.7947 - val_refeeded_rmse: 0.2570\n",
            "Epoch 160/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2998 - output_loss: 0.1997 - refeeded_loss: 0.0867 - output_masked_rmse: 0.4222 - refeeded_rmse: 0.2913 - val_loss: 0.7339 - val_output_loss: 0.7534 - val_refeeded_loss: 0.0421 - val_output_masked_rmse: 0.7902 - val_refeeded_rmse: 0.2022\n",
            "Epoch 161/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3003 - output_loss: 0.2008 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4230 - refeeded_rmse: 0.2897 - val_loss: 0.7603 - val_output_loss: 0.7847 - val_refeeded_loss: 0.0494 - val_output_masked_rmse: 0.8083 - val_refeeded_rmse: 0.2209\n",
            "Epoch 162/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3002 - output_loss: 0.2011 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4241 - refeeded_rmse: 0.2877 - val_loss: 0.7302 - val_output_loss: 0.7490 - val_refeeded_loss: 0.0422 - val_output_masked_rmse: 0.7920 - val_refeeded_rmse: 0.2025\n",
            "Epoch 163/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3017 - output_loss: 0.2024 - refeeded_loss: 0.0864 - output_masked_rmse: 0.4254 - refeeded_rmse: 0.2908 - val_loss: 0.7426 - val_output_loss: 0.7645 - val_refeeded_loss: 0.0414 - val_output_masked_rmse: 0.7955 - val_refeeded_rmse: 0.2001\n",
            "Epoch 164/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3000 - output_loss: 0.2005 - refeeded_loss: 0.0848 - output_masked_rmse: 0.4235 - refeeded_rmse: 0.2880 - val_loss: 0.7468 - val_output_loss: 0.7703 - val_refeeded_loss: 0.0393 - val_output_masked_rmse: 0.8014 - val_refeeded_rmse: 0.1947\n",
            "Epoch 165/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2993 - output_loss: 0.1989 - refeeded_loss: 0.0888 - output_masked_rmse: 0.4216 - refeeded_rmse: 0.2948 - val_loss: 0.7457 - val_output_loss: 0.7683 - val_refeeded_loss: 0.0425 - val_output_masked_rmse: 0.7991 - val_refeeded_rmse: 0.2041\n",
            "Epoch 166/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2995 - output_loss: 0.2002 - refeeded_loss: 0.0852 - output_masked_rmse: 0.4229 - refeeded_rmse: 0.2886 - val_loss: 0.7324 - val_output_loss: 0.7539 - val_refeeded_loss: 0.0338 - val_output_masked_rmse: 0.7930 - val_refeeded_rmse: 0.1789\n",
            "Epoch 167/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2999 - output_loss: 0.2009 - refeeded_loss: 0.0839 - output_masked_rmse: 0.4240 - refeeded_rmse: 0.2865 - val_loss: 0.7307 - val_output_loss: 0.7468 - val_refeeded_loss: 0.0534 - val_output_masked_rmse: 0.7880 - val_refeeded_rmse: 0.2296\n",
            "Epoch 168/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2997 - output_loss: 0.1998 - refeeded_loss: 0.0876 - output_masked_rmse: 0.4228 - refeeded_rmse: 0.2929 - val_loss: 0.7311 - val_output_loss: 0.7515 - val_refeeded_loss: 0.0371 - val_output_masked_rmse: 0.7908 - val_refeeded_rmse: 0.1895\n",
            "Epoch 169/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2986 - output_loss: 0.1994 - refeeded_loss: 0.0836 - output_masked_rmse: 0.4222 - refeeded_rmse: 0.2859 - val_loss: 0.7326 - val_output_loss: 0.7519 - val_refeeded_loss: 0.0419 - val_output_masked_rmse: 0.7905 - val_refeeded_rmse: 0.2025\n",
            "Epoch 170/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2986 - output_loss: 0.1991 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4215 - refeeded_rmse: 0.2878 - val_loss: 0.7351 - val_output_loss: 0.7568 - val_refeeded_loss: 0.0359 - val_output_masked_rmse: 0.7954 - val_refeeded_rmse: 0.1842\n",
            "Epoch 171/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.3000 - output_loss: 0.2003 - refeeded_loss: 0.0869 - output_masked_rmse: 0.4226 - refeeded_rmse: 0.2914 - val_loss: 0.7337 - val_output_loss: 0.7529 - val_refeeded_loss: 0.0435 - val_output_masked_rmse: 0.7926 - val_refeeded_rmse: 0.2023\n",
            "Epoch 172/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3002 - output_loss: 0.2002 - refeeded_loss: 0.0885 - output_masked_rmse: 0.4231 - refeeded_rmse: 0.2940 - val_loss: 0.7359 - val_output_loss: 0.7579 - val_refeeded_loss: 0.0353 - val_output_masked_rmse: 0.7927 - val_refeeded_rmse: 0.1832\n",
            "Epoch 173/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2994 - output_loss: 0.2002 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4231 - refeeded_rmse: 0.2871 - val_loss: 0.7140 - val_output_loss: 0.7310 - val_refeeded_loss: 0.0334 - val_output_masked_rmse: 0.7815 - val_refeeded_rmse: 0.1780\n",
            "Epoch 174/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2973 - output_loss: 0.1978 - refeeded_loss: 0.0840 - output_masked_rmse: 0.4202 - refeeded_rmse: 0.2866 - val_loss: 0.7416 - val_output_loss: 0.7614 - val_refeeded_loss: 0.0504 - val_output_masked_rmse: 0.7966 - val_refeeded_rmse: 0.2233\n",
            "Epoch 175/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2973 - output_loss: 0.1976 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4200 - refeeded_rmse: 0.2878 - val_loss: 0.7213 - val_output_loss: 0.7391 - val_refeeded_loss: 0.0375 - val_output_masked_rmse: 0.7873 - val_refeeded_rmse: 0.1905\n",
            "Epoch 176/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2964 - output_loss: 0.1968 - refeeded_loss: 0.0836 - output_masked_rmse: 0.4193 - refeeded_rmse: 0.2860 - val_loss: 0.7373 - val_output_loss: 0.7595 - val_refeeded_loss: 0.0369 - val_output_masked_rmse: 0.7943 - val_refeeded_rmse: 0.1885\n",
            "Epoch 177/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2984 - output_loss: 0.1986 - refeeded_loss: 0.0863 - output_masked_rmse: 0.4213 - refeeded_rmse: 0.2905 - val_loss: 0.7259 - val_output_loss: 0.7448 - val_refeeded_loss: 0.0385 - val_output_masked_rmse: 0.7897 - val_refeeded_rmse: 0.1929\n",
            "Epoch 178/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2991 - output_loss: 0.1996 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4222 - refeeded_rmse: 0.2898 - val_loss: 0.7408 - val_output_loss: 0.7618 - val_refeeded_loss: 0.0443 - val_output_masked_rmse: 0.7962 - val_refeeded_rmse: 0.2081\n",
            "Epoch 179/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2978 - output_loss: 0.1982 - refeeded_loss: 0.0852 - output_masked_rmse: 0.4204 - refeeded_rmse: 0.2887 - val_loss: 0.7304 - val_output_loss: 0.7516 - val_refeeded_loss: 0.0335 - val_output_masked_rmse: 0.7908 - val_refeeded_rmse: 0.1772\n",
            "Epoch 180/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2987 - output_loss: 0.1993 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4220 - refeeded_rmse: 0.2897 - val_loss: 0.7328 - val_output_loss: 0.7549 - val_refeeded_loss: 0.0330 - val_output_masked_rmse: 0.7927 - val_refeeded_rmse: 0.1752\n",
            "Epoch 181/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2983 - output_loss: 0.1988 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4213 - refeeded_rmse: 0.2896 - val_loss: 0.7347 - val_output_loss: 0.7574 - val_refeeded_loss: 0.0321 - val_output_masked_rmse: 0.7950 - val_refeeded_rmse: 0.1740\n",
            "Epoch 182/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2983 - output_loss: 0.1991 - refeeded_loss: 0.0837 - output_masked_rmse: 0.4216 - refeeded_rmse: 0.2861 - val_loss: 0.7251 - val_output_loss: 0.7445 - val_refeeded_loss: 0.0358 - val_output_masked_rmse: 0.7879 - val_refeeded_rmse: 0.1856\n",
            "Epoch 183/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2973 - output_loss: 0.1978 - refeeded_loss: 0.0844 - output_masked_rmse: 0.4203 - refeeded_rmse: 0.2874 - val_loss: 0.7295 - val_output_loss: 0.7506 - val_refeeded_loss: 0.0332 - val_output_masked_rmse: 0.7911 - val_refeeded_rmse: 0.1772\n",
            "Epoch 184/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2967 - output_loss: 0.1972 - refeeded_loss: 0.0840 - output_masked_rmse: 0.4198 - refeeded_rmse: 0.2865 - val_loss: 0.7290 - val_output_loss: 0.7502 - val_refeeded_loss: 0.0334 - val_output_masked_rmse: 0.7921 - val_refeeded_rmse: 0.1780\n",
            "Epoch 185/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2969 - output_loss: 0.1973 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4200 - refeeded_rmse: 0.2878 - val_loss: 0.7228 - val_output_loss: 0.7401 - val_refeeded_loss: 0.0418 - val_output_masked_rmse: 0.7852 - val_refeeded_rmse: 0.2017\n",
            "Epoch 186/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2958 - output_loss: 0.1957 - refeeded_loss: 0.0855 - output_masked_rmse: 0.4183 - refeeded_rmse: 0.2891 - val_loss: 0.7389 - val_output_loss: 0.7624 - val_refeeded_loss: 0.0338 - val_output_masked_rmse: 0.7963 - val_refeeded_rmse: 0.1786\n",
            "Epoch 187/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2978 - output_loss: 0.1985 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4212 - refeeded_rmse: 0.2871 - val_loss: 0.7193 - val_output_loss: 0.7378 - val_refeeded_loss: 0.0339 - val_output_masked_rmse: 0.7849 - val_refeeded_rmse: 0.1795\n",
            "Epoch 188/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2963 - output_loss: 0.1962 - refeeded_loss: 0.0869 - output_masked_rmse: 0.4189 - refeeded_rmse: 0.2917 - val_loss: 0.7320 - val_output_loss: 0.7526 - val_refeeded_loss: 0.0385 - val_output_masked_rmse: 0.7888 - val_refeeded_rmse: 0.1928\n",
            "Epoch 189/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2959 - output_loss: 0.1958 - refeeded_loss: 0.0859 - output_masked_rmse: 0.4178 - refeeded_rmse: 0.2900 - val_loss: 0.7276 - val_output_loss: 0.7467 - val_refeeded_loss: 0.0397 - val_output_masked_rmse: 0.7886 - val_refeeded_rmse: 0.1960\n",
            "Epoch 190/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2945 - output_loss: 0.1947 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4171 - refeeded_rmse: 0.2868 - val_loss: 0.7238 - val_output_loss: 0.7420 - val_refeeded_loss: 0.0411 - val_output_masked_rmse: 0.7872 - val_refeeded_rmse: 0.1999\n",
            "Epoch 191/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2941 - output_loss: 0.1937 - refeeded_loss: 0.0866 - output_masked_rmse: 0.4158 - refeeded_rmse: 0.2912 - val_loss: 0.7435 - val_output_loss: 0.7685 - val_refeeded_loss: 0.0336 - val_output_masked_rmse: 0.7976 - val_refeeded_rmse: 0.1780\n",
            "Epoch 192/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2931 - output_loss: 0.1932 - refeeded_loss: 0.0832 - output_masked_rmse: 0.4156 - refeeded_rmse: 0.2852 - val_loss: 0.7300 - val_output_loss: 0.7517 - val_refeeded_loss: 0.0337 - val_output_masked_rmse: 0.7918 - val_refeeded_rmse: 0.1779\n",
            "Epoch 193/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2933 - output_loss: 0.1936 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4159 - refeeded_rmse: 0.2858 - val_loss: 0.7262 - val_output_loss: 0.7473 - val_refeeded_loss: 0.0325 - val_output_masked_rmse: 0.7914 - val_refeeded_rmse: 0.1737\n",
            "Epoch 194/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2957 - output_loss: 0.1957 - refeeded_loss: 0.0866 - output_masked_rmse: 0.4178 - refeeded_rmse: 0.2912 - val_loss: 0.7279 - val_output_loss: 0.7475 - val_refeeded_loss: 0.0400 - val_output_masked_rmse: 0.7885 - val_refeeded_rmse: 0.1966\n",
            "Epoch 195/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2953 - output_loss: 0.1957 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4184 - refeeded_rmse: 0.2868 - val_loss: 0.7273 - val_output_loss: 0.7482 - val_refeeded_loss: 0.0327 - val_output_masked_rmse: 0.7894 - val_refeeded_rmse: 0.1751\n",
            "Epoch 196/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2939 - output_loss: 0.1939 - refeeded_loss: 0.0848 - output_masked_rmse: 0.4161 - refeeded_rmse: 0.2881 - val_loss: 0.7251 - val_output_loss: 0.7440 - val_refeeded_loss: 0.0401 - val_output_masked_rmse: 0.7880 - val_refeeded_rmse: 0.1963\n",
            "Epoch 197/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2924 - output_loss: 0.1922 - refeeded_loss: 0.0849 - output_masked_rmse: 0.4144 - refeeded_rmse: 0.2883 - val_loss: 0.7373 - val_output_loss: 0.7603 - val_refeeded_loss: 0.0364 - val_output_masked_rmse: 0.7957 - val_refeeded_rmse: 0.1865\n",
            "Epoch 198/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2929 - output_loss: 0.1926 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4149 - refeeded_rmse: 0.2889 - val_loss: 0.7252 - val_output_loss: 0.7452 - val_refeeded_loss: 0.0352 - val_output_masked_rmse: 0.7881 - val_refeeded_rmse: 0.1835\n",
            "Epoch 199/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2927 - output_loss: 0.1931 - refeeded_loss: 0.0828 - output_masked_rmse: 0.4155 - refeeded_rmse: 0.2845 - val_loss: 0.7165 - val_output_loss: 0.7349 - val_refeeded_loss: 0.0349 - val_output_masked_rmse: 0.7829 - val_refeeded_rmse: 0.1800\n",
            "Epoch 200/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2950 - output_loss: 0.1954 - refeeded_loss: 0.0854 - output_masked_rmse: 0.4175 - refeeded_rmse: 0.2890 - val_loss: 0.7384 - val_output_loss: 0.7627 - val_refeeded_loss: 0.0325 - val_output_masked_rmse: 0.7969 - val_refeeded_rmse: 0.1745\n",
            "Epoch 201/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2948 - output_loss: 0.1957 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4180 - refeeded_rmse: 0.2858 - val_loss: 0.7182 - val_output_loss: 0.7359 - val_refeeded_loss: 0.0390 - val_output_masked_rmse: 0.7828 - val_refeeded_rmse: 0.1931\n",
            "Epoch 202/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2949 - output_loss: 0.1953 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4176 - refeeded_rmse: 0.2889 - val_loss: 0.7365 - val_output_loss: 0.7572 - val_refeeded_loss: 0.0451 - val_output_masked_rmse: 0.7894 - val_refeeded_rmse: 0.2097\n",
            "Epoch 203/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2925 - output_loss: 0.1924 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4147 - refeeded_rmse: 0.2889 - val_loss: 0.7177 - val_output_loss: 0.7365 - val_refeeded_loss: 0.0338 - val_output_masked_rmse: 0.7848 - val_refeeded_rmse: 0.1788\n",
            "Epoch 204/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2919 - output_loss: 0.1923 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4145 - refeeded_rmse: 0.2858 - val_loss: 0.7309 - val_output_loss: 0.7532 - val_refeeded_loss: 0.0336 - val_output_masked_rmse: 0.7930 - val_refeeded_rmse: 0.1784\n",
            "Epoch 205/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2920 - output_loss: 0.1921 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4146 - refeeded_rmse: 0.2879 - val_loss: 0.7241 - val_output_loss: 0.7437 - val_refeeded_loss: 0.0386 - val_output_masked_rmse: 0.7891 - val_refeeded_rmse: 0.1923\n",
            "Epoch 206/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2948 - output_loss: 0.1934 - refeeded_loss: 0.0938 - output_masked_rmse: 0.4156 - refeeded_rmse: 0.3032 - val_loss: 0.7209 - val_output_loss: 0.7390 - val_refeeded_loss: 0.0413 - val_output_masked_rmse: 0.7835 - val_refeeded_rmse: 0.1993\n",
            "Epoch 207/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2913 - output_loss: 0.1914 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4137 - refeeded_rmse: 0.2869 - val_loss: 0.7334 - val_output_loss: 0.7562 - val_refeeded_loss: 0.0345 - val_output_masked_rmse: 0.7949 - val_refeeded_rmse: 0.1810\n",
            "Epoch 208/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2913 - output_loss: 0.1920 - refeeded_loss: 0.0826 - output_masked_rmse: 0.4141 - refeeded_rmse: 0.2843 - val_loss: 0.7257 - val_output_loss: 0.7472 - val_refeeded_loss: 0.0332 - val_output_masked_rmse: 0.7897 - val_refeeded_rmse: 0.1769\n",
            "Epoch 209/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2909 - output_loss: 0.1914 - refeeded_loss: 0.0827 - output_masked_rmse: 0.4137 - refeeded_rmse: 0.2844 - val_loss: 0.7263 - val_output_loss: 0.7477 - val_refeeded_loss: 0.0338 - val_output_masked_rmse: 0.7885 - val_refeeded_rmse: 0.1785\n",
            "Epoch 210/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.2931 - output_loss: 0.1932 - refeeded_loss: 0.0855 - output_masked_rmse: 0.4153 - refeeded_rmse: 0.2893 - val_loss: 0.7133 - val_output_loss: 0.7313 - val_refeeded_loss: 0.0326 - val_output_masked_rmse: 0.7808 - val_refeeded_rmse: 0.1751\n",
            "Epoch 211/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2923 - output_loss: 0.1924 - refeeded_loss: 0.0856 - output_masked_rmse: 0.4149 - refeeded_rmse: 0.2895 - val_loss: 0.7335 - val_output_loss: 0.7568 - val_refeeded_loss: 0.0333 - val_output_masked_rmse: 0.7930 - val_refeeded_rmse: 0.1768\n",
            "Epoch 212/500\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.2912 - output_loss: 0.1913 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4133 - refeeded_rmse: 0.2869 - val_loss: 0.7075 - val_output_loss: 0.7250 - val_refeeded_loss: 0.0312 - val_output_masked_rmse: 0.7798 - val_refeeded_rmse: 0.1705\n",
            "Epoch 213/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2914 - output_loss: 0.1916 - refeeded_loss: 0.0849 - output_masked_rmse: 0.4139 - refeeded_rmse: 0.2884 - val_loss: 0.7282 - val_output_loss: 0.7502 - val_refeeded_loss: 0.0335 - val_output_masked_rmse: 0.7900 - val_refeeded_rmse: 0.1776\n",
            "Epoch 214/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2918 - output_loss: 0.1920 - refeeded_loss: 0.0848 - output_masked_rmse: 0.4139 - refeeded_rmse: 0.2880 - val_loss: 0.7214 - val_output_loss: 0.7414 - val_refeeded_loss: 0.0344 - val_output_masked_rmse: 0.7878 - val_refeeded_rmse: 0.1800\n",
            "Epoch 215/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2932 - output_loss: 0.1936 - refeeded_loss: 0.0845 - output_masked_rmse: 0.4150 - refeeded_rmse: 0.2875 - val_loss: 0.7151 - val_output_loss: 0.7322 - val_refeeded_loss: 0.0384 - val_output_masked_rmse: 0.7797 - val_refeeded_rmse: 0.1915\n",
            "Epoch 216/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2916 - output_loss: 0.1915 - refeeded_loss: 0.0851 - output_masked_rmse: 0.4138 - refeeded_rmse: 0.2887 - val_loss: 0.7243 - val_output_loss: 0.7456 - val_refeeded_loss: 0.0315 - val_output_masked_rmse: 0.7878 - val_refeeded_rmse: 0.1705\n",
            "Epoch 217/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2911 - output_loss: 0.1908 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4127 - refeeded_rmse: 0.2888 - val_loss: 0.7235 - val_output_loss: 0.7440 - val_refeeded_loss: 0.0348 - val_output_masked_rmse: 0.7868 - val_refeeded_rmse: 0.1807\n",
            "Epoch 218/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2904 - output_loss: 0.1905 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4125 - refeeded_rmse: 0.2870 - val_loss: 0.7215 - val_output_loss: 0.7418 - val_refeeded_loss: 0.0335 - val_output_masked_rmse: 0.7864 - val_refeeded_rmse: 0.1773\n",
            "Epoch 219/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2894 - output_loss: 0.1895 - refeeded_loss: 0.0836 - output_masked_rmse: 0.4115 - refeeded_rmse: 0.2860 - val_loss: 0.7214 - val_output_loss: 0.7419 - val_refeeded_loss: 0.0325 - val_output_masked_rmse: 0.7870 - val_refeeded_rmse: 0.1740\n",
            "Epoch 220/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2935 - output_loss: 0.1939 - refeeded_loss: 0.0848 - output_masked_rmse: 0.4157 - refeeded_rmse: 0.2881 - val_loss: 0.7210 - val_output_loss: 0.7403 - val_refeeded_loss: 0.0359 - val_output_masked_rmse: 0.7827 - val_refeeded_rmse: 0.1847\n",
            "Epoch 221/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2912 - output_loss: 0.1918 - refeeded_loss: 0.0823 - output_masked_rmse: 0.4136 - refeeded_rmse: 0.2837 - val_loss: 0.7263 - val_output_loss: 0.7456 - val_refeeded_loss: 0.0415 - val_output_masked_rmse: 0.7893 - val_refeeded_rmse: 0.1997\n",
            "Epoch 222/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2907 - output_loss: 0.1896 - refeeded_loss: 0.0882 - output_masked_rmse: 0.4116 - refeeded_rmse: 0.2940 - val_loss: 0.7178 - val_output_loss: 0.7363 - val_refeeded_loss: 0.0369 - val_output_masked_rmse: 0.7826 - val_refeeded_rmse: 0.1870\n",
            "Epoch 223/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2907 - output_loss: 0.1907 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4129 - refeeded_rmse: 0.2879 - val_loss: 0.7190 - val_output_loss: 0.7377 - val_refeeded_loss: 0.0371 - val_output_masked_rmse: 0.7837 - val_refeeded_rmse: 0.1876\n",
            "Epoch 224/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2903 - output_loss: 0.1902 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4121 - refeeded_rmse: 0.2879 - val_loss: 0.7230 - val_output_loss: 0.7425 - val_refeeded_loss: 0.0390 - val_output_masked_rmse: 0.7863 - val_refeeded_rmse: 0.1935\n",
            "Epoch 225/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2884 - output_loss: 0.1882 - refeeded_loss: 0.0840 - output_masked_rmse: 0.4099 - refeeded_rmse: 0.2867 - val_loss: 0.7234 - val_output_loss: 0.7452 - val_refeeded_loss: 0.0299 - val_output_masked_rmse: 0.7876 - val_refeeded_rmse: 0.1663\n",
            "Epoch 226/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2888 - output_loss: 0.1883 - refeeded_loss: 0.0858 - output_masked_rmse: 0.4101 - refeeded_rmse: 0.2898 - val_loss: 0.7216 - val_output_loss: 0.7393 - val_refeeded_loss: 0.0452 - val_output_masked_rmse: 0.7844 - val_refeeded_rmse: 0.2096\n",
            "Epoch 227/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2888 - output_loss: 0.1884 - refeeded_loss: 0.0857 - output_masked_rmse: 0.4102 - refeeded_rmse: 0.2897 - val_loss: 0.7357 - val_output_loss: 0.7604 - val_refeeded_loss: 0.0309 - val_output_masked_rmse: 0.7965 - val_refeeded_rmse: 0.1696\n",
            "Epoch 228/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2880 - output_loss: 0.1880 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4100 - refeeded_rmse: 0.2858 - val_loss: 0.7166 - val_output_loss: 0.7354 - val_refeeded_loss: 0.0361 - val_output_masked_rmse: 0.7819 - val_refeeded_rmse: 0.1848\n",
            "Epoch 229/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2885 - output_loss: 0.1886 - refeeded_loss: 0.0838 - output_masked_rmse: 0.4109 - refeeded_rmse: 0.2863 - val_loss: 0.7242 - val_output_loss: 0.7448 - val_refeeded_loss: 0.0361 - val_output_masked_rmse: 0.7897 - val_refeeded_rmse: 0.1857\n",
            "Epoch 230/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2900 - output_loss: 0.1903 - refeeded_loss: 0.0843 - output_masked_rmse: 0.4127 - refeeded_rmse: 0.2873 - val_loss: 0.7257 - val_output_loss: 0.7482 - val_refeeded_loss: 0.0307 - val_output_masked_rmse: 0.7902 - val_refeeded_rmse: 0.1689\n",
            "Epoch 231/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2892 - output_loss: 0.1898 - refeeded_loss: 0.0828 - output_masked_rmse: 0.4122 - refeeded_rmse: 0.2846 - val_loss: 0.7252 - val_output_loss: 0.7461 - val_refeeded_loss: 0.0362 - val_output_masked_rmse: 0.7877 - val_refeeded_rmse: 0.1852\n",
            "Epoch 232/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2901 - output_loss: 0.1905 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4128 - refeeded_rmse: 0.2868 - val_loss: 0.7090 - val_output_loss: 0.7254 - val_refeeded_loss: 0.0375 - val_output_masked_rmse: 0.7770 - val_refeeded_rmse: 0.1891\n",
            "Epoch 233/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2882 - output_loss: 0.1884 - refeeded_loss: 0.0831 - output_masked_rmse: 0.4103 - refeeded_rmse: 0.2850 - val_loss: 0.7324 - val_output_loss: 0.7564 - val_refeeded_loss: 0.0316 - val_output_masked_rmse: 0.7957 - val_refeeded_rmse: 0.1715\n",
            "Epoch 234/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2884 - output_loss: 0.1879 - refeeded_loss: 0.0863 - output_masked_rmse: 0.4098 - refeeded_rmse: 0.2907 - val_loss: 0.7191 - val_output_loss: 0.7392 - val_refeeded_loss: 0.0330 - val_output_masked_rmse: 0.7854 - val_refeeded_rmse: 0.1759\n",
            "Epoch 235/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2882 - output_loss: 0.1882 - refeeded_loss: 0.0839 - output_masked_rmse: 0.4099 - refeeded_rmse: 0.2865 - val_loss: 0.7216 - val_output_loss: 0.7427 - val_refeeded_loss: 0.0315 - val_output_masked_rmse: 0.7866 - val_refeeded_rmse: 0.1708\n",
            "Epoch 236/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2888 - output_loss: 0.1887 - refeeded_loss: 0.0844 - output_masked_rmse: 0.4110 - refeeded_rmse: 0.2873 - val_loss: 0.7255 - val_output_loss: 0.7449 - val_refeeded_loss: 0.0422 - val_output_masked_rmse: 0.7866 - val_refeeded_rmse: 0.2016\n",
            "Epoch 237/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2888 - output_loss: 0.1887 - refeeded_loss: 0.0848 - output_masked_rmse: 0.4107 - refeeded_rmse: 0.2880 - val_loss: 0.7217 - val_output_loss: 0.7425 - val_refeeded_loss: 0.0337 - val_output_masked_rmse: 0.7863 - val_refeeded_rmse: 0.1778\n",
            "Epoch 238/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2905 - output_loss: 0.1903 - refeeded_loss: 0.0862 - output_masked_rmse: 0.4125 - refeeded_rmse: 0.2904 - val_loss: 0.7051 - val_output_loss: 0.7220 - val_refeeded_loss: 0.0307 - val_output_masked_rmse: 0.7752 - val_refeeded_rmse: 0.1685\n",
            "Epoch 239/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2885 - output_loss: 0.1886 - refeeded_loss: 0.0831 - output_masked_rmse: 0.4105 - refeeded_rmse: 0.2851 - val_loss: 0.7231 - val_output_loss: 0.7449 - val_refeeded_loss: 0.0304 - val_output_masked_rmse: 0.7887 - val_refeeded_rmse: 0.1675\n",
            "Epoch 240/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2873 - output_loss: 0.1872 - refeeded_loss: 0.0837 - output_masked_rmse: 0.4093 - refeeded_rmse: 0.2862 - val_loss: 0.7157 - val_output_loss: 0.7352 - val_refeeded_loss: 0.0332 - val_output_masked_rmse: 0.7824 - val_refeeded_rmse: 0.1769\n",
            "Epoch 241/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2869 - output_loss: 0.1868 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4089 - refeeded_rmse: 0.2858 - val_loss: 0.7241 - val_output_loss: 0.7444 - val_refeeded_loss: 0.0380 - val_output_masked_rmse: 0.7872 - val_refeeded_rmse: 0.1898\n",
            "Epoch 242/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2888 - output_loss: 0.1886 - refeeded_loss: 0.0853 - output_masked_rmse: 0.4104 - refeeded_rmse: 0.2890 - val_loss: 0.7199 - val_output_loss: 0.7373 - val_refeeded_loss: 0.0451 - val_output_masked_rmse: 0.7840 - val_refeeded_rmse: 0.2088\n",
            "Epoch 243/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2882 - output_loss: 0.1881 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4102 - refeeded_rmse: 0.2877 - val_loss: 0.7314 - val_output_loss: 0.7553 - val_refeeded_loss: 0.0310 - val_output_masked_rmse: 0.7887 - val_refeeded_rmse: 0.1691\n",
            "Epoch 244/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2882 - output_loss: 0.1886 - refeeded_loss: 0.0833 - output_masked_rmse: 0.4105 - refeeded_rmse: 0.2854 - val_loss: 0.7113 - val_output_loss: 0.7298 - val_refeeded_loss: 0.0333 - val_output_masked_rmse: 0.7822 - val_refeeded_rmse: 0.1765\n",
            "Epoch 245/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2889 - output_loss: 0.1894 - refeeded_loss: 0.0833 - output_masked_rmse: 0.4121 - refeeded_rmse: 0.2854 - val_loss: 0.7234 - val_output_loss: 0.7452 - val_refeeded_loss: 0.0313 - val_output_masked_rmse: 0.7883 - val_refeeded_rmse: 0.1707\n",
            "Epoch 246/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2871 - output_loss: 0.1873 - refeeded_loss: 0.0829 - output_masked_rmse: 0.4094 - refeeded_rmse: 0.2848 - val_loss: 0.7263 - val_output_loss: 0.7487 - val_refeeded_loss: 0.0328 - val_output_masked_rmse: 0.7871 - val_refeeded_rmse: 0.1754\n",
            "Epoch 247/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2861 - output_loss: 0.1858 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4074 - refeeded_rmse: 0.2867 - val_loss: 0.7102 - val_output_loss: 0.7284 - val_refeeded_loss: 0.0338 - val_output_masked_rmse: 0.7797 - val_refeeded_rmse: 0.1784\n",
            "Epoch 248/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2863 - output_loss: 0.1859 - refeeded_loss: 0.0852 - output_masked_rmse: 0.4076 - refeeded_rmse: 0.2887 - val_loss: 0.7173 - val_output_loss: 0.7381 - val_refeeded_loss: 0.0304 - val_output_masked_rmse: 0.7844 - val_refeeded_rmse: 0.1676\n",
            "Epoch 249/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2869 - output_loss: 0.1869 - refeeded_loss: 0.0833 - output_masked_rmse: 0.4088 - refeeded_rmse: 0.2854 - val_loss: 0.7211 - val_output_loss: 0.7423 - val_refeeded_loss: 0.0326 - val_output_masked_rmse: 0.7838 - val_refeeded_rmse: 0.1746\n",
            "Epoch 250/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2859 - output_loss: 0.1860 - refeeded_loss: 0.0828 - output_masked_rmse: 0.4077 - refeeded_rmse: 0.2847 - val_loss: 0.7183 - val_output_loss: 0.7389 - val_refeeded_loss: 0.0324 - val_output_masked_rmse: 0.7868 - val_refeeded_rmse: 0.1740\n",
            "Epoch 251/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2877 - output_loss: 0.1879 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4095 - refeeded_rmse: 0.2877 - val_loss: 0.7282 - val_output_loss: 0.7504 - val_refeeded_loss: 0.0359 - val_output_masked_rmse: 0.7889 - val_refeeded_rmse: 0.1845\n",
            "Epoch 252/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2880 - output_loss: 0.1880 - refeeded_loss: 0.0847 - output_masked_rmse: 0.4096 - refeeded_rmse: 0.2879 - val_loss: 0.7114 - val_output_loss: 0.7303 - val_refeeded_loss: 0.0318 - val_output_masked_rmse: 0.7802 - val_refeeded_rmse: 0.1721\n",
            "Epoch 253/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2878 - output_loss: 0.1882 - refeeded_loss: 0.0837 - output_masked_rmse: 0.4103 - refeeded_rmse: 0.2863 - val_loss: 0.7241 - val_output_loss: 0.7455 - val_refeeded_loss: 0.0353 - val_output_masked_rmse: 0.7903 - val_refeeded_rmse: 0.1826\n",
            "Epoch 254/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2860 - output_loss: 0.1853 - refeeded_loss: 0.0867 - output_masked_rmse: 0.4072 - refeeded_rmse: 0.2915 - val_loss: 0.7171 - val_output_loss: 0.7378 - val_refeeded_loss: 0.0314 - val_output_masked_rmse: 0.7845 - val_refeeded_rmse: 0.1710\n",
            "Epoch 255/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2844 - output_loss: 0.1844 - refeeded_loss: 0.0826 - output_masked_rmse: 0.4062 - refeeded_rmse: 0.2842 - val_loss: 0.7331 - val_output_loss: 0.7580 - val_refeeded_loss: 0.0312 - val_output_masked_rmse: 0.7926 - val_refeeded_rmse: 0.1699\n",
            "Epoch 256/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2847 - output_loss: 0.1846 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4062 - refeeded_rmse: 0.2868 - val_loss: 0.7178 - val_output_loss: 0.7388 - val_refeeded_loss: 0.0318 - val_output_masked_rmse: 0.7866 - val_refeeded_rmse: 0.1724\n",
            "Epoch 257/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2863 - output_loss: 0.1867 - refeeded_loss: 0.0835 - output_masked_rmse: 0.4082 - refeeded_rmse: 0.2859 - val_loss: 0.7148 - val_output_loss: 0.7353 - val_refeeded_loss: 0.0310 - val_output_masked_rmse: 0.7792 - val_refeeded_rmse: 0.1702\n",
            "Epoch 258/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2859 - output_loss: 0.1862 - refeeded_loss: 0.0834 - output_masked_rmse: 0.4084 - refeeded_rmse: 0.2856 - val_loss: 0.7237 - val_output_loss: 0.7459 - val_refeeded_loss: 0.0331 - val_output_masked_rmse: 0.7889 - val_refeeded_rmse: 0.1761\n",
            "Epoch 259/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2870 - output_loss: 0.1871 - refeeded_loss: 0.0848 - output_masked_rmse: 0.4091 - refeeded_rmse: 0.2881 - val_loss: 0.7157 - val_output_loss: 0.7361 - val_refeeded_loss: 0.0311 - val_output_masked_rmse: 0.7832 - val_refeeded_rmse: 0.1705\n",
            "Epoch 260/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2843 - output_loss: 0.1844 - refeeded_loss: 0.0823 - output_masked_rmse: 0.4061 - refeeded_rmse: 0.2837 - val_loss: 0.7215 - val_output_loss: 0.7437 - val_refeeded_loss: 0.0305 - val_output_masked_rmse: 0.7876 - val_refeeded_rmse: 0.1685\n",
            "Epoch 261/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2852 - output_loss: 0.1857 - refeeded_loss: 0.0824 - output_masked_rmse: 0.4072 - refeeded_rmse: 0.2840 - val_loss: 0.7088 - val_output_loss: 0.7269 - val_refeeded_loss: 0.0345 - val_output_masked_rmse: 0.7765 - val_refeeded_rmse: 0.1802\n",
            "Epoch 262/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2888 - output_loss: 0.1890 - refeeded_loss: 0.0856 - output_masked_rmse: 0.4103 - refeeded_rmse: 0.2895 - val_loss: 0.7184 - val_output_loss: 0.7383 - val_refeeded_loss: 0.0355 - val_output_masked_rmse: 0.7863 - val_refeeded_rmse: 0.1833\n",
            "Epoch 263/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2865 - output_loss: 0.1869 - refeeded_loss: 0.0826 - output_masked_rmse: 0.4087 - refeeded_rmse: 0.2843 - val_loss: 0.7176 - val_output_loss: 0.7383 - val_refeeded_loss: 0.0317 - val_output_masked_rmse: 0.7829 - val_refeeded_rmse: 0.1716\n",
            "Epoch 264/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2854 - output_loss: 0.1853 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4078 - refeeded_rmse: 0.2869 - val_loss: 0.7018 - val_output_loss: 0.7194 - val_refeeded_loss: 0.0287 - val_output_masked_rmse: 0.7760 - val_refeeded_rmse: 0.1621\n",
            "Epoch 265/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2851 - output_loss: 0.1849 - refeeded_loss: 0.0845 - output_masked_rmse: 0.4066 - refeeded_rmse: 0.2876 - val_loss: 0.7270 - val_output_loss: 0.7502 - val_refeeded_loss: 0.0317 - val_output_masked_rmse: 0.7893 - val_refeeded_rmse: 0.1716\n",
            "Epoch 266/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2843 - output_loss: 0.1838 - refeeded_loss: 0.0845 - output_masked_rmse: 0.4052 - refeeded_rmse: 0.2876 - val_loss: 0.7237 - val_output_loss: 0.7408 - val_refeeded_loss: 0.0535 - val_output_masked_rmse: 0.7851 - val_refeeded_rmse: 0.2281\n",
            "Epoch 267/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2846 - output_loss: 0.1840 - refeeded_loss: 0.0863 - output_masked_rmse: 0.4058 - refeeded_rmse: 0.2907 - val_loss: 0.7183 - val_output_loss: 0.7396 - val_refeeded_loss: 0.0306 - val_output_masked_rmse: 0.7851 - val_refeeded_rmse: 0.1692\n",
            "Epoch 268/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2854 - output_loss: 0.1852 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4067 - refeeded_rmse: 0.2870 - val_loss: 0.7113 - val_output_loss: 0.7299 - val_refeeded_loss: 0.0347 - val_output_masked_rmse: 0.7800 - val_refeeded_rmse: 0.1816\n",
            "Epoch 269/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2836 - output_loss: 0.1835 - refeeded_loss: 0.0831 - output_masked_rmse: 0.4049 - refeeded_rmse: 0.2852 - val_loss: 0.7084 - val_output_loss: 0.7268 - val_refeeded_loss: 0.0332 - val_output_masked_rmse: 0.7775 - val_refeeded_rmse: 0.1766\n",
            "Epoch 270/500\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.2835 - output_loss: 0.1837 - refeeded_loss: 0.0823 - output_masked_rmse: 0.4053 - refeeded_rmse: 0.2838 - val_loss: 0.7191 - val_output_loss: 0.7408 - val_refeeded_loss: 0.0310 - val_output_masked_rmse: 0.7840 - val_refeeded_rmse: 0.1698\n",
            "Epoch 271/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2837 - output_loss: 0.1841 - refeeded_loss: 0.0812 - output_masked_rmse: 0.4058 - refeeded_rmse: 0.2819 - val_loss: 0.7163 - val_output_loss: 0.7372 - val_refeeded_loss: 0.0309 - val_output_masked_rmse: 0.7833 - val_refeeded_rmse: 0.1693\n",
            "Epoch 272/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2834 - output_loss: 0.1831 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4043 - refeeded_rmse: 0.2869 - val_loss: 0.7218 - val_output_loss: 0.7437 - val_refeeded_loss: 0.0330 - val_output_masked_rmse: 0.7858 - val_refeeded_rmse: 0.1760\n",
            "Epoch 273/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2830 - output_loss: 0.1830 - refeeded_loss: 0.0827 - output_masked_rmse: 0.4043 - refeeded_rmse: 0.2845 - val_loss: 0.7161 - val_output_loss: 0.7372 - val_refeeded_loss: 0.0309 - val_output_masked_rmse: 0.7843 - val_refeeded_rmse: 0.1691\n",
            "Epoch 274/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2840 - output_loss: 0.1842 - refeeded_loss: 0.0827 - output_masked_rmse: 0.4057 - refeeded_rmse: 0.2845 - val_loss: 0.7189 - val_output_loss: 0.7408 - val_refeeded_loss: 0.0301 - val_output_masked_rmse: 0.7851 - val_refeeded_rmse: 0.1670\n",
            "Epoch 275/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2853 - output_loss: 0.1855 - refeeded_loss: 0.0839 - output_masked_rmse: 0.4072 - refeeded_rmse: 0.2864 - val_loss: 0.7180 - val_output_loss: 0.7382 - val_refeeded_loss: 0.0357 - val_output_masked_rmse: 0.7844 - val_refeeded_rmse: 0.1834\n",
            "Epoch 276/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2838 - output_loss: 0.1836 - refeeded_loss: 0.0838 - output_masked_rmse: 0.4052 - refeeded_rmse: 0.2864 - val_loss: 0.7187 - val_output_loss: 0.7397 - val_refeeded_loss: 0.0331 - val_output_masked_rmse: 0.7840 - val_refeeded_rmse: 0.1758\n",
            "Epoch 277/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2829 - output_loss: 0.1832 - refeeded_loss: 0.0817 - output_masked_rmse: 0.4040 - refeeded_rmse: 0.2827 - val_loss: 0.7118 - val_output_loss: 0.7313 - val_refeeded_loss: 0.0332 - val_output_masked_rmse: 0.7834 - val_refeeded_rmse: 0.1767\n",
            "Epoch 278/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2831 - output_loss: 0.1829 - refeeded_loss: 0.0841 - output_masked_rmse: 0.4044 - refeeded_rmse: 0.2870 - val_loss: 0.7185 - val_output_loss: 0.7405 - val_refeeded_loss: 0.0301 - val_output_masked_rmse: 0.7856 - val_refeeded_rmse: 0.1673\n",
            "Epoch 279/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2834 - output_loss: 0.1835 - refeeded_loss: 0.0825 - output_masked_rmse: 0.4052 - refeeded_rmse: 0.2842 - val_loss: 0.7138 - val_output_loss: 0.7344 - val_refeeded_loss: 0.0308 - val_output_masked_rmse: 0.7818 - val_refeeded_rmse: 0.1699\n",
            "Epoch 280/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2832 - output_loss: 0.1835 - refeeded_loss: 0.0826 - output_masked_rmse: 0.4046 - refeeded_rmse: 0.2843 - val_loss: 0.7153 - val_output_loss: 0.7365 - val_refeeded_loss: 0.0303 - val_output_masked_rmse: 0.7845 - val_refeeded_rmse: 0.1681\n",
            "Epoch 281/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2813 - output_loss: 0.1815 - refeeded_loss: 0.0816 - output_masked_rmse: 0.4026 - refeeded_rmse: 0.2825 - val_loss: 0.7161 - val_output_loss: 0.7369 - val_refeeded_loss: 0.0339 - val_output_masked_rmse: 0.7850 - val_refeeded_rmse: 0.1793\n",
            "Epoch 282/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2829 - output_loss: 0.1827 - refeeded_loss: 0.0846 - output_masked_rmse: 0.4038 - refeeded_rmse: 0.2877 - val_loss: 0.7104 - val_output_loss: 0.7293 - val_refeeded_loss: 0.0343 - val_output_masked_rmse: 0.7770 - val_refeeded_rmse: 0.1802\n",
            "Epoch 283/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2813 - output_loss: 0.1814 - refeeded_loss: 0.0820 - output_masked_rmse: 0.4026 - refeeded_rmse: 0.2832 - val_loss: 0.7159 - val_output_loss: 0.7364 - val_refeeded_loss: 0.0345 - val_output_masked_rmse: 0.7831 - val_refeeded_rmse: 0.1807\n",
            "Epoch 284/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2813 - output_loss: 0.1813 - refeeded_loss: 0.0824 - output_masked_rmse: 0.4025 - refeeded_rmse: 0.2839 - val_loss: 0.7176 - val_output_loss: 0.7394 - val_refeeded_loss: 0.0308 - val_output_masked_rmse: 0.7838 - val_refeeded_rmse: 0.1696\n",
            "Epoch 285/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2809 - output_loss: 0.1808 - refeeded_loss: 0.0827 - output_masked_rmse: 0.4022 - refeeded_rmse: 0.2845 - val_loss: 0.7149 - val_output_loss: 0.7346 - val_refeeded_loss: 0.0369 - val_output_masked_rmse: 0.7834 - val_refeeded_rmse: 0.1878\n",
            "Epoch 286/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2825 - output_loss: 0.1826 - refeeded_loss: 0.0832 - output_masked_rmse: 0.4039 - refeeded_rmse: 0.2853 - val_loss: 0.7176 - val_output_loss: 0.7334 - val_refeeded_loss: 0.0540 - val_output_masked_rmse: 0.7796 - val_refeeded_rmse: 0.2303\n",
            "Epoch 287/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2836 - output_loss: 0.1832 - refeeded_loss: 0.0855 - output_masked_rmse: 0.4048 - refeeded_rmse: 0.2893 - val_loss: 0.7314 - val_output_loss: 0.7563 - val_refeeded_loss: 0.0316 - val_output_masked_rmse: 0.7937 - val_refeeded_rmse: 0.1719\n",
            "Epoch 288/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2814 - output_loss: 0.1813 - refeeded_loss: 0.0822 - output_masked_rmse: 0.4028 - refeeded_rmse: 0.2837 - val_loss: 0.7125 - val_output_loss: 0.7325 - val_refeeded_loss: 0.0322 - val_output_masked_rmse: 0.7807 - val_refeeded_rmse: 0.1745\n",
            "Epoch 289/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2808 - output_loss: 0.1811 - refeeded_loss: 0.0804 - output_masked_rmse: 0.4026 - refeeded_rmse: 0.2805 - val_loss: 0.7136 - val_output_loss: 0.7349 - val_refeeded_loss: 0.0289 - val_output_masked_rmse: 0.7810 - val_refeeded_rmse: 0.1634\n",
            "Epoch 290/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2823 - output_loss: 0.1827 - refeeded_loss: 0.0820 - output_masked_rmse: 0.4041 - refeeded_rmse: 0.2832 - val_loss: 0.7253 - val_output_loss: 0.7485 - val_refeeded_loss: 0.0319 - val_output_masked_rmse: 0.7885 - val_refeeded_rmse: 0.1731\n",
            "Epoch 291/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2821 - output_loss: 0.1821 - refeeded_loss: 0.0829 - output_masked_rmse: 0.4037 - refeeded_rmse: 0.2849 - val_loss: 0.7123 - val_output_loss: 0.7326 - val_refeeded_loss: 0.0317 - val_output_masked_rmse: 0.7820 - val_refeeded_rmse: 0.1728\n",
            "Epoch 292/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2829 - output_loss: 0.1828 - refeeded_loss: 0.0842 - output_masked_rmse: 0.4044 - refeeded_rmse: 0.2872 - val_loss: 0.7108 - val_output_loss: 0.7312 - val_refeeded_loss: 0.0294 - val_output_masked_rmse: 0.7810 - val_refeeded_rmse: 0.1652\n",
            "Epoch 293/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2833 - output_loss: 0.1836 - refeeded_loss: 0.0822 - output_masked_rmse: 0.4054 - refeeded_rmse: 0.2837 - val_loss: 0.7211 - val_output_loss: 0.7432 - val_refeeded_loss: 0.0325 - val_output_masked_rmse: 0.7861 - val_refeeded_rmse: 0.1745\n",
            "Epoch 294/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2823 - output_loss: 0.1829 - refeeded_loss: 0.0808 - output_masked_rmse: 0.4047 - refeeded_rmse: 0.2811 - val_loss: 0.7175 - val_output_loss: 0.7397 - val_refeeded_loss: 0.0288 - val_output_masked_rmse: 0.7838 - val_refeeded_rmse: 0.1634\n",
            "Epoch 295/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2810 - output_loss: 0.1811 - refeeded_loss: 0.0821 - output_masked_rmse: 0.4024 - refeeded_rmse: 0.2834 - val_loss: 0.7099 - val_output_loss: 0.7302 - val_refeeded_loss: 0.0299 - val_output_masked_rmse: 0.7811 - val_refeeded_rmse: 0.1658\n",
            "Epoch 296/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2809 - output_loss: 0.1812 - refeeded_loss: 0.0809 - output_masked_rmse: 0.4024 - refeeded_rmse: 0.2813 - val_loss: 0.7174 - val_output_loss: 0.7385 - val_refeeded_loss: 0.0337 - val_output_masked_rmse: 0.7855 - val_refeeded_rmse: 0.1782\n",
            "Epoch 297/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2803 - output_loss: 0.1806 - refeeded_loss: 0.0809 - output_masked_rmse: 0.4018 - refeeded_rmse: 0.2814 - val_loss: 0.7199 - val_output_loss: 0.7426 - val_refeeded_loss: 0.0302 - val_output_masked_rmse: 0.7845 - val_refeeded_rmse: 0.1672\n",
            "Epoch 298/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2804 - output_loss: 0.1804 - refeeded_loss: 0.0822 - output_masked_rmse: 0.4013 - refeeded_rmse: 0.2836 - val_loss: 0.7067 - val_output_loss: 0.7244 - val_refeeded_loss: 0.0368 - val_output_masked_rmse: 0.7762 - val_refeeded_rmse: 0.1871\n",
            "Epoch 299/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2811 - output_loss: 0.1813 - refeeded_loss: 0.0821 - output_masked_rmse: 0.4027 - refeeded_rmse: 0.2834 - val_loss: 0.7226 - val_output_loss: 0.7452 - val_refeeded_loss: 0.0335 - val_output_masked_rmse: 0.7886 - val_refeeded_rmse: 0.1772\n",
            "Epoch 300/500\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2814 - output_loss: 0.1816 - refeeded_loss: 0.0828 - output_masked_rmse: 0.4030 - refeeded_rmse: 0.2847 - val_loss: 0.7139 - val_output_loss: 0.7350 - val_refeeded_loss: 0.0304 - val_output_masked_rmse: 0.7833 - val_refeeded_rmse: 0.1685\n",
            "Epoch 301/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2821 - output_loss: 0.1824 - refeeded_loss: 0.0827 - output_masked_rmse: 0.4040 - refeeded_rmse: 0.2846 - val_loss: 0.7194 - val_output_loss: 0.7411 - val_refeeded_loss: 0.0334 - val_output_masked_rmse: 0.7846 - val_refeeded_rmse: 0.1770\n",
            "Epoch 302/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2808 - output_loss: 0.1811 - refeeded_loss: 0.0814 - output_masked_rmse: 0.4024 - refeeded_rmse: 0.2822 - val_loss: 0.7144 - val_output_loss: 0.7351 - val_refeeded_loss: 0.0319 - val_output_masked_rmse: 0.7818 - val_refeeded_rmse: 0.1736\n",
            "Epoch 303/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2803 - output_loss: 0.1809 - refeeded_loss: 0.0797 - output_masked_rmse: 0.4024 - refeeded_rmse: 0.2793 - val_loss: 0.7191 - val_output_loss: 0.7410 - val_refeeded_loss: 0.0327 - val_output_masked_rmse: 0.7836 - val_refeeded_rmse: 0.1762\n",
            "Epoch 304/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2823 - output_loss: 0.1825 - refeeded_loss: 0.0825 - output_masked_rmse: 0.4042 - refeeded_rmse: 0.2842 - val_loss: 0.7121 - val_output_loss: 0.7323 - val_refeeded_loss: 0.0312 - val_output_masked_rmse: 0.7835 - val_refeeded_rmse: 0.1712\n",
            "Epoch 305/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2816 - output_loss: 0.1821 - refeeded_loss: 0.0809 - output_masked_rmse: 0.4034 - refeeded_rmse: 0.2813 - val_loss: 0.7246 - val_output_loss: 0.7485 - val_refeeded_loss: 0.0305 - val_output_masked_rmse: 0.7867 - val_refeeded_rmse: 0.1686\n",
            "Epoch 306/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2819 - output_loss: 0.1822 - refeeded_loss: 0.0829 - output_masked_rmse: 0.4036 - refeeded_rmse: 0.2849 - val_loss: 0.7163 - val_output_loss: 0.7374 - val_refeeded_loss: 0.0322 - val_output_masked_rmse: 0.7842 - val_refeeded_rmse: 0.1740\n",
            "Epoch 307/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2803 - output_loss: 0.1804 - refeeded_loss: 0.0811 - output_masked_rmse: 0.4017 - refeeded_rmse: 0.2817 - val_loss: 0.7110 - val_output_loss: 0.7303 - val_refeeded_loss: 0.0350 - val_output_masked_rmse: 0.7814 - val_refeeded_rmse: 0.1825\n",
            "Epoch 308/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2809 - output_loss: 0.1813 - refeeded_loss: 0.0813 - output_masked_rmse: 0.4024 - refeeded_rmse: 0.2821 - val_loss: 0.7150 - val_output_loss: 0.7362 - val_refeeded_loss: 0.0314 - val_output_masked_rmse: 0.7836 - val_refeeded_rmse: 0.1720\n",
            "Epoch 309/500\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2795 - output_loss: 0.1799 - refeeded_loss: 0.0804 - output_masked_rmse: 0.4011 - refeeded_rmse: 0.2804 - val_loss: 0.7125 - val_output_loss: 0.7337 - val_refeeded_loss: 0.0298 - val_output_masked_rmse: 0.7809 - val_refeeded_rmse: 0.1664\n",
            "Epoch 310/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2794 - output_loss: 0.1799 - refeeded_loss: 0.0800 - output_masked_rmse: 0.4010 - refeeded_rmse: 0.2798 - val_loss: 0.7225 - val_output_loss: 0.7458 - val_refeeded_loss: 0.0311 - val_output_masked_rmse: 0.7881 - val_refeeded_rmse: 0.1708\n",
            "Epoch 311/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2805 - output_loss: 0.1810 - refeeded_loss: 0.0806 - output_masked_rmse: 0.4021 - refeeded_rmse: 0.2808 - val_loss: 0.7170 - val_output_loss: 0.7377 - val_refeeded_loss: 0.0359 - val_output_masked_rmse: 0.7830 - val_refeeded_rmse: 0.1856\n",
            "Epoch 312/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2809 - output_loss: 0.1816 - refeeded_loss: 0.0806 - output_masked_rmse: 0.4030 - refeeded_rmse: 0.2808 - val_loss: 0.7077 - val_output_loss: 0.7271 - val_refeeded_loss: 0.0317 - val_output_masked_rmse: 0.7785 - val_refeeded_rmse: 0.1727\n",
            "Epoch 313/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2814 - output_loss: 0.1823 - refeeded_loss: 0.0801 - output_masked_rmse: 0.4041 - refeeded_rmse: 0.2800 - val_loss: 0.7163 - val_output_loss: 0.7380 - val_refeeded_loss: 0.0314 - val_output_masked_rmse: 0.7849 - val_refeeded_rmse: 0.1715\n",
            "Epoch 314/500\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2792 - output_loss: 0.1791 - refeeded_loss: 0.0820 - output_masked_rmse: 0.4004 - refeeded_rmse: 0.2833 - val_loss: 0.7176 - val_output_loss: 0.7385 - val_refeeded_loss: 0.0353 - val_output_masked_rmse: 0.7831 - val_refeeded_rmse: 0.1837\n",
            "Epoch 00314: early stopping\n",
            "CPU times: user 10min 1s, sys: 58.3 s, total: 11min\n",
            "Wall time: 8min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMf7nt5kX8MU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7546d233-2719-4ab8-d16d-799e8fb6857a"
      },
      "source": [
        "show_history(hist, 'output_loss', 'output_masked_rmse')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ply0yBs4YCIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b62d5a0e-6d08-4d7e-e0d8-ce331a564d06"
      },
      "source": [
        "test_pred = make_predictor(test, model, n_item, batch_size)\n",
        "print(f'Mean of masked RMSE: {test_pred:.4f}')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of masked RMSE: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}