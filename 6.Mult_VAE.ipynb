{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mult-VAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viikY8IQdVTY"
      },
      "source": [
        "# Mult-VAE\n",
        "\n",
        "- [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/pdf/1802.05814.pdf)\n",
        "- [참고](https://jrzaurin.github.io/infinitoml/2020/05/15/mult-vae.html)\n",
        "\n",
        "## Experiment\n",
        "\n",
        "- sampling vs training all\n",
        "     - sampling이 일반적으로 성능이 좋음\n",
        "- alternative learning\n",
        "    - alternative learning으로 성능 상승이 존재\n",
        "- multinomial vs logistic\n",
        "    - alternative learning을 적용하지 않으면 logistic의 성능이 더 좋았음\n",
        "    - alternative learning을 적용하게 되면 multinomial의 성능이 매우 상승함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8FDcw4rVboe"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Callable, Tuple, List\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('bmh')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Dropout, Embedding, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.initializers import TruncatedNormal, RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.utils import get_file\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdjqodyYVf9I"
      },
      "source": [
        "def load_data(data_size : str) -> pd.DataFrame:\n",
        "    ''' load Movie Lens data '''\n",
        "\n",
        "    if data_size == '100k':\n",
        "        file = get_file('ml-100k.zip', 'http://files.grouplens.org/datasets/movielens/ml-100k.zip')\n",
        "        file_name = 'ml-100k/*'\n",
        "    elif data_size == '1m':\n",
        "        file = get_file('ml-1m.zip', 'http://files.grouplens.org/datasets/movielens/ml-1m.zip')\n",
        "        file_name = 'ml-1m/ratings.dat'\n",
        "    elif data_size == '10m':\n",
        "        file = get_file('ml-10m.zip', 'http://files.grouplens.org/datasets/movielens/ml-10m.zip')\n",
        "        file_name = 'ml-10M100K/ratings.dat'\n",
        "    elif data_size == '20m':\n",
        "        file = get_file('ml-20m.zip', 'http://files.grouplens.org/datasets/movielens/ml-20m.zip')\n",
        "        file_name = 'ml-20m/ratings.csv'\n",
        "    elif data_size == '25m':\n",
        "        file = get_file('ml-25m.zip', 'http://files.grouplens.org/datasets/movielens/ml-25m.zip')\n",
        "        file_name = 'ml-25m/ratings.csv'\n",
        "    zip_ref = zipfile.ZipFile(file, 'r')\n",
        "    zip_ref.extractall()\n",
        "\n",
        "    col_names = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "    if data_size in ['20m', '25m']:\n",
        "        ratings = pd.read_csv(file_name, engine = 'python')\n",
        "    else:\n",
        "        ratings = pd.read_csv(file_name, sep = '|', delimiter = '::', names = col_names, engine = 'python')\n",
        "    print(ratings.shape)\n",
        "    return ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZf8Gzf0VhYV",
        "outputId": "7781780e-cb46-4ce9-b11f-fdd621a1c9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "ratings = load_data('1m')\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000209, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1     1193       5  978300760\n",
              "1       1      661       3  978302109\n",
              "2       1      914       3  978301968\n",
              "3       1     3408       4  978300275\n",
              "4       1     2355       5  978824291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGuhgUB67uKF"
      },
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU_B2Cc6MYyt"
      },
      "source": [
        "def preprocessing(df: pd.DataFrame, threshold = 4) -> pd.DataFrame:\n",
        "    df = df[df.rating >= threshold]\n",
        "    positive = df.groupby('userId')['movieId'].nunique()\n",
        "    positive = positive.index[positive >= 5]\n",
        "    df = df[df.userId.isin(positive)]\n",
        "    return df.reset_index(drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q61otQWA3tFe",
        "outputId": "490d72c5-4712-4506-9595-8256727d82ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "idx_user_map = ratings.userId.unique()\n",
        "user_idx_map = {e: i for i, e in enumerate(idx_user_map)}\n",
        "n_user = idx_user_map.shape[0]\n",
        "print(f'# of user = {n_user}')\n",
        "\n",
        "idx_item_map = ratings.movieId.unique()\n",
        "item_idx_map = {e: i for i, e in enumerate(idx_item_map)}\n",
        "n_item = idx_item_map.shape[0]\n",
        "print(f'# of item = {n_item}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of user = 6040\n",
            "# of item = 3706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJvVnvKX3uNv"
      },
      "source": [
        "def Id2idx(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.assign(userId = lambda x: x.userId.map(user_idx_map), \n",
        "                     movieId = lambda x: x.movieId.map(item_idx_map))\n",
        "\n",
        "def idx2Id(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.assign(userId = lambda x: x.userId.apply(lambda x: idx_user_map[x]), \n",
        "                     movieId = lambda x: x.movieId.apply(lambda x: idx_item_map[x]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS1B1fPw3whx",
        "outputId": "99882d0f-baa7-43fd-bf9f-d3b32c4601bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "ratings = preprocessing(ratings)\n",
        "ratings = Id2idx(ratings)\n",
        "\n",
        "print(ratings.shape)\n",
        "ratings.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(575272, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>978302039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>978300719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       0        0       5  978300760\n",
              "1       0        3       4  978300275\n",
              "2       0        4       5  978824291\n",
              "3       0        6       5  978302039\n",
              "4       0        7       5  978300719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td2PONcp5LGq"
      },
      "source": [
        "def train_valid_test_split(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    train_user, test_user = train_test_split(df.userId.unique(), test_size = 0.2, random_state = 7777)\n",
        "    valid_user, test_user = train_test_split(test_user, test_size = 0.5, random_state = 7777)\n",
        "\n",
        "    train, valid, test = map(lambda x: df[df.userId.isin(x)], (train_user, valid_user, test_user))\n",
        "    train, valid, test = map(lambda df: df.reset_index(drop = True), (train, valid, test))\n",
        "    return train, valid, test\n",
        "\n",
        "def query_answer_split(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    query, answer = train_test_split(df, test_size = 0.2, stratify = df.userId, random_state = 7777)\n",
        "    query, answer = map(lambda df: df.sort_values(['userId', 'timestamp']), (query, answer))\n",
        "    query, answer = map(lambda df: df.reset_index(drop = True), (query, answer))\n",
        "    return query, answer\n",
        "\n",
        "def list_aggregation(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.groupby('userId', as_index = False)[['movieId', 'rating']].agg(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLAac2E-Bv1u"
      },
      "source": [
        "def train_generator(df: pd.DataFrame,\n",
        "                    n_item: int,\n",
        "                    batch_size: int,\n",
        "                    implicit = True,\n",
        "                    threshold = 4,\n",
        "                    corruption = 0.5,\n",
        "                    sampling = True,\n",
        "                    NS = 5) -> Tuple[np.array, np.array]:\n",
        "\n",
        "    n_row = df.index.size\n",
        "    n_col = n_item\n",
        "\n",
        "    Ids = np.arange(n_row)\n",
        "    profile = df['movieId']\n",
        "    rating = df['rating'] if not implicit else df['rating'].apply(lambda x: [1 if r >= threshold else 0 for r in x])\n",
        "\n",
        "    n_batch = int(np.ceil(n_row / batch_size))\n",
        "    if sampling:\n",
        "        while True:\n",
        "            batch_Id = np.random.choice(Ids, size = batch_size)\n",
        "            batch = np.zeros(shape = (batch_size, n_col))\n",
        "            \n",
        "            for i, idx in enumerate(batch_Id):\n",
        "                pos = np.array(profile[idx])\n",
        "                batch[i, pos] = rating[idx]\n",
        "\n",
        "            yield batch, batch\n",
        "    else:\n",
        "        while True:\n",
        "            np.random.shuffle(Ids)\n",
        "        \n",
        "            for batch_step in range(n_batch):\n",
        "                lower = batch_step * batch_size\n",
        "                upper = lower + batch_size\n",
        "                \n",
        "                batch_Id = Ids[lower: upper]\n",
        "                batch = np.zeros(shape = (batch_Id.size, n_col))\n",
        "                for i, idx in enumerate(batch_Id):\n",
        "                    pos = np.array(profile[idx])\n",
        "                    batch[i, pos] = rating[idx]              \n",
        "                yield batch, batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3RMzY9oFh3x"
      },
      "source": [
        "def valid_generator(query: pd.DataFrame,\n",
        "                    answer: pd.DataFrame,\n",
        "                    n_item: int,\n",
        "                    batch_size: int,\n",
        "                    implicit = True,\n",
        "                    threshold = 4) -> Tuple[np.array, np.array]:\n",
        "\n",
        "    n_row = query.index.size\n",
        "    n_col = n_item\n",
        "\n",
        "    Ids = np.arange(n_row)\n",
        "    profile_q = query['movieId']\n",
        "    profile_a = answer['movieId']\n",
        "    if implicit:\n",
        "        rating_q = query['rating'].apply(lambda x: [1 if r >= threshold else 0 for r in x])\n",
        "        rating_a = answer['rating'].apply(lambda x: [1 if r >= threshold else 0 for r in x])\n",
        "    else:\n",
        "        rating_q = query['rating']\n",
        "        rating_a = answer['rating']\n",
        "\n",
        "    n_batch = int(np.ceil(n_row / batch_size))\n",
        "    while True:\n",
        "        for batch_step in range(n_batch):\n",
        "            lower = batch_step * batch_size\n",
        "            upper = lower + batch_size\n",
        "            \n",
        "            batch_Id = Ids[lower: upper]\n",
        "            batch_q = np.zeros(shape = (batch_Id.size, n_col))\n",
        "            batch_a = np.zeros(shape = (batch_Id.size, n_col))\n",
        "\n",
        "            for i, idx in enumerate(batch_Id):\n",
        "                obs = np.array(profile_q[idx]) # observed\n",
        "                ubs = np.array(profile_a[idx]) # unobserved\n",
        "\n",
        "                batch_q[i, obs] = rating_q[idx]\n",
        "                batch_a[i, ubs] = rating_a[idx]\n",
        "\n",
        "            yield batch_q, batch_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNPv41eMBv1v"
      },
      "source": [
        "def mae(y_true: np.array, y_pred: np.array) -> tf.Tensor:\n",
        "    ae = K.abs(y_true - y_pred)\n",
        "    return K.mean(ae, axis = -1)\n",
        "\n",
        "def rmse(y_true: np.array, y_pred: np.array) -> tf.Tensor:\n",
        "    se = K.square(mask_true * (y_true - y_pred))\n",
        "    return K.sqrt(K.mean(masked_se, axis = -1))\n",
        "\n",
        "def cross_entropy(y_true: np.array, y_pred: np.array) -> tf.Tensor:\n",
        "    ce = y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred)\n",
        "    return -K.sum(ce, axis = -1)\n",
        "\n",
        "def log_loss(y_true: np.array, y_pred: np.array) -> tf.Tensor:\n",
        "    return -K.sum(y_true * K.log(y_pred), axis = -1)\n",
        "\n",
        "def batch_ndcg(y_true, y_pred, k = 100):\n",
        "    rec = tf.argsort(y_pred, axis = -1, direction = 'DESCENDING')[:, :k]\n",
        "\n",
        "    row = tf.repeat(tf.range(tf.shape(y_true)[0]), k)\n",
        "    row = tf.expand_dims(row, axis = 1)\n",
        "    col = tf.reshape(rec, shape = [-1])\n",
        "    col = tf.expand_dims(col, axis = 1)\n",
        "    loc = tf.concat([row, col], axis = 1)\n",
        "\n",
        "    top_k = tf.reshape(tf.gather_nd(y_true, loc), shape = tf.shape(rec))\n",
        "    ideal = tf.sort(top_k, axis = 1, direction = 'DESCENDING')\n",
        "\n",
        "    weight = tf.range(2, 102, dtype = 'float32')\n",
        "    weight = tf.math.log(weight)\n",
        "    weight = tf.math.reciprocal(weight)\n",
        "    \n",
        "    dcg = tf.reduce_sum(top_k * weight, axis = 1)    \n",
        "    idcg = tf.reduce_sum(ideal * weight, axis = 1)\n",
        "    return dcg / tf.where(idcg == 0, 1.0, idcg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8nTDPrt5-qb"
      },
      "source": [
        "class Sampling(Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * K.random_normal(shape = (batch, dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmXd5rxsDPdr"
      },
      "source": [
        "def VAE(n_user: int,\n",
        "        n_item: int,\n",
        "        latent_dim = 200,\n",
        "        activation = 'tanh',\n",
        "        optimizer = 'adam',\n",
        "        dropout_rate = 0.5,\n",
        "        kernel_initializer = None,\n",
        "        kernel_regularizer = None,\n",
        "        likelihood = 'logistic',\n",
        "        beta = 0.2) -> Callable:\n",
        "\n",
        "    if not kernel_initializer:\n",
        "        kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.1, seed = None)\n",
        "\n",
        "    if likelihood == 'multinomial':\n",
        "        loss = log_loss\n",
        "        last_activation = 'softmax'\n",
        "    elif likelihood == 'logistic':\n",
        "        loss = cross_entropy\n",
        "        last_activation = 'sigmoid'\n",
        "    elif likelihood == 'gaussian':\n",
        "        loss = rmse\n",
        "        last_activation = 'sigmoid'\n",
        "    \n",
        "    inputs = Input(shape = (n_item, ), name = 'input')\n",
        "    z_mean_weight = Dense(latent_dim,\n",
        "                          activation = activation,\n",
        "                          kernel_initializer = kernel_initializer,\n",
        "                          kernel_regularizer = kernel_regularizer, \n",
        "                          name = 'mean')\n",
        "    z_log_var_weight = Dense(latent_dim, \n",
        "                             activation = activation,\n",
        "                             kernel_initializer = kernel_initializer,\n",
        "                             kernel_regularizer = kernel_regularizer, \n",
        "                             name = 'log_var')\n",
        "    outputs_weight = Dense(n_item,\n",
        "                           activation = last_activation, \n",
        "                           kernel_initializer = kernel_initializer,\n",
        "                           name = 'output')\n",
        "\n",
        "    x = Dropout(dropout_rate)(inputs)\n",
        "    enc_z_mean = z_mean_weight(x)\n",
        "    enc_z_log_var = z_log_var_weight(x)\n",
        "    enc_z = Sampling()([enc_z_mean, enc_z_log_var])\n",
        "    enc_kl_loss = -0.5 * K.sum(1 + enc_z_log_var - K.exp(enc_z_log_var) - K.square(enc_z_mean), axis = -1)\n",
        "\n",
        "    encoder = Model(inputs = inputs, outputs = [enc_z_mean, enc_z_log_var, enc_z], name = 'encoder')\n",
        "    encoder.add_loss(enc_kl_loss)\n",
        "    encoder.compile(optimizer = 'adam')\n",
        "\n",
        "    z_mean = z_mean_weight(inputs)\n",
        "    z_log_var = z_log_var_weight(inputs)\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    outputs = outputs_weight(z)\n",
        "\n",
        "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.exp(z_log_var) - K.square(z_mean), axis = -1)\n",
        "    lh_loss = loss(inputs, outputs)\n",
        "    vae_loss = K.mean(lh_loss + beta * kl_loss)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = outputs, name = 'VAE')\n",
        "    model.add_loss(vae_loss)\n",
        "    model.compile(optimizer = optimizer, metrics = [mae, batch_ndcg])\n",
        "    return encoder, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU9gLOL-LVKT"
      },
      "source": [
        "def test_predictor(df: pd.DataFrame, \n",
        "                   model: Callable, \n",
        "                   n_item: int, \n",
        "                   batch_size: int, \n",
        "                   implicit = True,\n",
        "                   threshold = 4,\n",
        "                   top_N = 20) -> float:\n",
        "\n",
        "    n_row = df.index.size\n",
        "    n_col = n_item\n",
        "\n",
        "    Ids = np.arange(n_row)\n",
        "    profile = df['movieId']\n",
        "    rating = df['rating'] if not implicit else df['rating'].apply(lambda x: [1 if r >= threshold else 0 for r in x])\n",
        "\n",
        "    res = []\n",
        "    steps = int(np.ceil(n_row / batch_size))\n",
        "    for batch_step in range(steps):\n",
        "        lower = batch_step * batch_size\n",
        "        upper = lower + batch_size\n",
        "\n",
        "        batch_Id = Ids[lower: upper]\n",
        "        y_true = np.zeros(shape = (batch_Id.size, n_col))\n",
        "        for i, idx in enumerate(batch_Id):\n",
        "            y_true[i, profile[idx]] = rating[idx]\n",
        "\n",
        "        y_pred = model.predict(y_true, verbose = 0)\n",
        "        \n",
        "        rec = np.argsort(np.where(y_true == 1, -1, y_pred), axis = -1)[:, :-top_N-1:-1]\n",
        "        res.append(rec)\n",
        "    return np.concatenate(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2quTiHQJlpg"
      },
      "source": [
        "def show_history(history, loss: str, metric: str) -> None:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 4))\n",
        "\n",
        "    ax1.plot(history[f'{loss}'])\n",
        "    ax1.plot(history[f'val_{loss}'])\n",
        "    ax1.set_title('Loss', fontsize = 20)\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_xlabel('epoch')\n",
        "    ax1.legend(['loss', 'val_loss'], loc = 'upper right')\n",
        "\n",
        "    ax2.plot(history[f'{metric}'])\n",
        "    ax2.plot(history[f'val_{metric}'])\n",
        "    ax2.set_title('Metric', fontsize = 20)\n",
        "    ax2.set_ylabel('metric')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['metric', 'metric'], loc = 'upper right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lziheZmDL6fQ"
      },
      "source": [
        "def ndcg(gt, rec):\n",
        "    dcg, idcg = 0.0, 0.0\n",
        "    k = 0\n",
        "    for i, r in enumerate(rec):\n",
        "        if r in gt:\n",
        "            dcg += 1.0 / np.log(i + 2)\n",
        "            idcg += 1.0 / np.log(k + 2)\n",
        "            k += 1\n",
        "    return dcg / np.max([1, idcg])\n",
        "\n",
        "def recall(gt, rec):\n",
        "    res = [r for r in rec if r in gt]\n",
        "    return len(res) / len(gt)\n",
        "\n",
        "def precision(gt, rec):\n",
        "    res = [r for r in rec if r in gt]\n",
        "    return len(res) / len(rec)\n",
        "\n",
        "def precision_k(gt, rec, k):\n",
        "    rec_k = rec[:k+1]\n",
        "    res = [r for r in rec_k if r in gt]\n",
        "    return len(res) / k\n",
        "\n",
        "def AP_k(gt, rec, k = 20):\n",
        "    res = 0\n",
        "    for i in range(k):\n",
        "        if rec[i] in gt:\n",
        "            res += precision_k(gt, rec, i+1)\n",
        "    return res / min(k, len(gt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNWM3LYgSBGa"
      },
      "source": [
        "def evaluation(true: pd.DataFrame, pred):\n",
        "    m_ndcg = 0\n",
        "    m_recall = 0\n",
        "    m_precision = 0\n",
        "    map_k = 0\n",
        "    for i in range(len(pred)):\n",
        "        rec = pred[i]\n",
        "        gt = true.at[i, 'movieId']\n",
        "        m_ndcg += ndcg(gt, rec)\n",
        "        m_recall += recall(gt, rec)\n",
        "        m_precision += precision(gt, rec)\n",
        "        map_k += AP_k(gt, rec)\n",
        "    m_ndcg /= len(pred)\n",
        "    m_recall /= len(pred)\n",
        "    m_precision /= len(pred)\n",
        "    map_k /= len(pred)\n",
        "    return m_ndcg, m_recall, m_precision, map_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZc_fV0DmRA"
      },
      "source": [
        "### 1. Mult-DAE(Multinomial Likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyAUW6XGO0p"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train, valid, test = train_valid_test_split(ratings)\n",
        "(valid_q, valid_a), (test_q, test_a) = map(query_answer_split, (valid, test))\n",
        "train, valid_q, valid_a, test_q, test_a = map(list_aggregation, (train, valid_q, valid_a, test_q, test_a))\n",
        "\n",
        "train_gen = train_generator(train, n_item, batch_size)\n",
        "valid_gen = valid_generator(valid_q, valid_a, n_item, batch_size)\n",
        "\n",
        "steps_per_epoch = train.index.size // batch_size + 1\n",
        "validation_steps = valid_q.index.size // batch_size + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11q6-rSGPGCs",
        "outputId": "85a5fa9c-7a45-411e-bf20-e240888949b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        }
      },
      "source": [
        "optimizer = Adam(learning_rate = 0.001) #, decay = 1e-5)\n",
        "encoder, model = VAE(n_user, n_item, latent_dim = 200, optimizer = optimizer, likelihood = 'multinomial')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"VAE\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 3706)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mean (Dense)                    (None, 200)          741400      input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "log_var (Dense)                 (None, 200)          741400      input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sampling_5 (Sampling)           (None, 200)          0           mean[1][0]                       \n",
            "                                                                 log_var[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 3706)         744906      sampling_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_8 (TensorFlow [(None, 200)]        0           log_var[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_5 (TensorFlowOp [(None, 200)]        0           log_var[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_12 (TensorFlowO [(None, 200)]        0           tf_op_layer_AddV2_8[0][0]        \n",
            "                                                                 tf_op_layer_Exp_5[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_5 (TensorFlo [(None, 200)]        0           mean[1][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log_3 (TensorFlowOp [(None, 3706)]       0           output[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_13 (TensorFlowO [(None, 200)]        0           tf_op_layer_Sub_12[0][0]         \n",
            "                                                                 tf_op_layer_Square_5[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_11 (TensorFlowO [(None, 3706)]       0           input[0][0]                      \n",
            "                                                                 tf_op_layer_Log_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_7 (TensorFlowOp [(None,)]            0           tf_op_layer_Sub_13[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_8 (TensorFlowOp [(None,)]            0           tf_op_layer_Mul_11[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_10 (TensorFlowO [(None,)]            0           tf_op_layer_Sum_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Neg_2 (TensorFlowOp [(None,)]            0           tf_op_layer_Sum_8[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_12 (TensorFlowO [(None,)]            0           tf_op_layer_Mul_10[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_9 (TensorFlow [(None,)]            0           tf_op_layer_Neg_2[0][0]          \n",
            "                                                                 tf_op_layer_Mul_12[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_2 (TensorFlowO [()]                 0           tf_op_layer_AddV2_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_loss_5 (AddLoss)            ()                   0           tf_op_layer_Mean_2[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 2,227,706\n",
            "Trainable params: 2,227,706\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7lQYKnyXb3X",
        "outputId": "7bc22261-87bb-4f3f-cc9c-6fbf60cb1c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "total_hist = {}\n",
        "for _ in range(epochs):\n",
        "    anneal_size, epoch_size = 20, 10\n",
        "    encoder.fit(x = train_gen, epochs = anneal_size, steps_per_epoch = steps_per_epoch, verbose = 1)\n",
        "    hist = model.fit(x = train_gen, validation_data = valid_gen, epochs = epoch_size, verbose = 1,\n",
        "                     steps_per_epoch = steps_per_epoch, validation_steps = validation_steps)\n",
        "    for key in hist.history.keys():\n",
        "        total_hist[key] = total_hist.get(key, []) + hist.history[key]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 60.5986\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 55.6241\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 52.0151\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 47.9673\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 43.9438\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 39.5249\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 35.9779\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 31.8244\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 27.7132\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 23.9059\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 20.5344\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 17.7500\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 15.1924\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 12.5141\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 10.5531\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 9.0876\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.7422\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 6.3981\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.3829\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.5295\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 761.0030 - mae: 0.0252 - batch_ndcg: 0.4041 - val_loss: 568.7947 - val_mae: 0.0052 - val_batch_ndcg: 0.2331\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 719.9869 - mae: 0.0258 - batch_ndcg: 0.5752 - val_loss: 550.8669 - val_mae: 0.0052 - val_batch_ndcg: 0.2692\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 701.1501 - mae: 0.0258 - batch_ndcg: 0.6467 - val_loss: 538.8304 - val_mae: 0.0052 - val_batch_ndcg: 0.2951\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 690.1562 - mae: 0.0259 - batch_ndcg: 0.6881 - val_loss: 529.5970 - val_mae: 0.0052 - val_batch_ndcg: 0.3080\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 679.6807 - mae: 0.0259 - batch_ndcg: 0.7223 - val_loss: 523.8365 - val_mae: 0.0052 - val_batch_ndcg: 0.3217\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 677.1282 - mae: 0.0261 - batch_ndcg: 0.7430 - val_loss: 519.2070 - val_mae: 0.0052 - val_batch_ndcg: 0.3288\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 656.3029 - mae: 0.0256 - batch_ndcg: 0.7672 - val_loss: 514.7963 - val_mae: 0.0052 - val_batch_ndcg: 0.3334\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 659.7672 - mae: 0.0258 - batch_ndcg: 0.7813 - val_loss: 511.9138 - val_mae: 0.0052 - val_batch_ndcg: 0.3395\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 667.3015 - mae: 0.0263 - batch_ndcg: 0.7988 - val_loss: 509.5378 - val_mae: 0.0052 - val_batch_ndcg: 0.3375\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 663.4443 - mae: 0.0263 - batch_ndcg: 0.8131 - val_loss: 507.2283 - val_mae: 0.0052 - val_batch_ndcg: 0.3447\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 46.6238\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 15.9494\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.2251\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.7904\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.4552\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.7100\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.2629\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.0221\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.6113\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3854\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.2232\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0646\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9867\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8873\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7861\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7583\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6413\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6377\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5329\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5146\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 721.8268 - mae: 0.0262 - batch_ndcg: 0.5695 - val_loss: 524.8068 - val_mae: 0.0052 - val_batch_ndcg: 0.3188\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 683.6065 - mae: 0.0263 - batch_ndcg: 0.7027 - val_loss: 516.8342 - val_mae: 0.0052 - val_batch_ndcg: 0.3404\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 681.8757 - mae: 0.0265 - batch_ndcg: 0.7270 - val_loss: 513.2121 - val_mae: 0.0052 - val_batch_ndcg: 0.3547\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 655.6334 - mae: 0.0258 - batch_ndcg: 0.7550 - val_loss: 510.1417 - val_mae: 0.0052 - val_batch_ndcg: 0.3561\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 664.5730 - mae: 0.0262 - batch_ndcg: 0.7687 - val_loss: 508.5459 - val_mae: 0.0052 - val_batch_ndcg: 0.3622\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 645.6068 - mae: 0.0257 - batch_ndcg: 0.7797 - val_loss: 506.8378 - val_mae: 0.0052 - val_batch_ndcg: 0.3621\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 639.6770 - mae: 0.0256 - batch_ndcg: 0.7926 - val_loss: 504.5767 - val_mae: 0.0052 - val_batch_ndcg: 0.3623\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 628.9748 - mae: 0.0253 - batch_ndcg: 0.7993 - val_loss: 503.1974 - val_mae: 0.0052 - val_batch_ndcg: 0.3668\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 638.3755 - mae: 0.0257 - batch_ndcg: 0.8064 - val_loss: 501.8818 - val_mae: 0.0052 - val_batch_ndcg: 0.3683\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 647.3615 - mae: 0.0261 - batch_ndcg: 0.8175 - val_loss: 501.0953 - val_mae: 0.0052 - val_batch_ndcg: 0.3730\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 40.4602\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 9.0005\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.1614\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.7027\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0873\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7485\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5920\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4974\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4513\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3723\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3257\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2810\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2681\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2574\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2832\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2673\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2224\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1972\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1771\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1884\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 700.2452 - mae: 0.0259 - batch_ndcg: 0.5814 - val_loss: 516.0685 - val_mae: 0.0052 - val_batch_ndcg: 0.3331\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 660.0674 - mae: 0.0260 - batch_ndcg: 0.7301 - val_loss: 508.6195 - val_mae: 0.0052 - val_batch_ndcg: 0.3612\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 644.5471 - mae: 0.0256 - batch_ndcg: 0.7593 - val_loss: 505.9864 - val_mae: 0.0052 - val_batch_ndcg: 0.3616\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 633.7645 - mae: 0.0254 - batch_ndcg: 0.7808 - val_loss: 503.8814 - val_mae: 0.0052 - val_batch_ndcg: 0.3709\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 639.5190 - mae: 0.0257 - batch_ndcg: 0.7907 - val_loss: 502.6252 - val_mae: 0.0052 - val_batch_ndcg: 0.3705\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 646.4188 - mae: 0.0261 - batch_ndcg: 0.8005 - val_loss: 500.8318 - val_mae: 0.0052 - val_batch_ndcg: 0.3796\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 653.8347 - mae: 0.0264 - batch_ndcg: 0.8111 - val_loss: 500.6314 - val_mae: 0.0052 - val_batch_ndcg: 0.3784\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 618.6711 - mae: 0.0252 - batch_ndcg: 0.8134 - val_loss: 499.0815 - val_mae: 0.0052 - val_batch_ndcg: 0.3747\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 638.8734 - mae: 0.0260 - batch_ndcg: 0.8192 - val_loss: 498.8575 - val_mae: 0.0052 - val_batch_ndcg: 0.3762\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 630.5266 - mae: 0.0258 - batch_ndcg: 0.8241 - val_loss: 498.3008 - val_mae: 0.0052 - val_batch_ndcg: 0.3773\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.3664\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.1827\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.7781\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4312\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8009\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5520\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4210\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3131\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2682\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2487\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2423\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2323\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1568\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1787\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1642\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1429\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1494\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2067\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1454\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1667\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 694.2948 - mae: 0.0260 - batch_ndcg: 0.6089 - val_loss: 511.8653 - val_mae: 0.0052 - val_batch_ndcg: 0.3520\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 637.0405 - mae: 0.0253 - batch_ndcg: 0.7533 - val_loss: 505.5792 - val_mae: 0.0052 - val_batch_ndcg: 0.3629\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 667.4128 - mae: 0.0266 - batch_ndcg: 0.7763 - val_loss: 503.5124 - val_mae: 0.0052 - val_batch_ndcg: 0.3729\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 647.0981 - mae: 0.0261 - batch_ndcg: 0.7914 - val_loss: 501.1734 - val_mae: 0.0052 - val_batch_ndcg: 0.3735\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 656.1593 - mae: 0.0265 - batch_ndcg: 0.8015 - val_loss: 500.2562 - val_mae: 0.0052 - val_batch_ndcg: 0.3721\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 641.4219 - mae: 0.0260 - batch_ndcg: 0.8096 - val_loss: 499.0762 - val_mae: 0.0052 - val_batch_ndcg: 0.3777\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 664.1240 - mae: 0.0270 - batch_ndcg: 0.8209 - val_loss: 498.4142 - val_mae: 0.0052 - val_batch_ndcg: 0.3813\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 623.6780 - mae: 0.0255 - batch_ndcg: 0.8212 - val_loss: 497.5612 - val_mae: 0.0052 - val_batch_ndcg: 0.3820\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 620.6554 - mae: 0.0255 - batch_ndcg: 0.8241 - val_loss: 497.3528 - val_mae: 0.0052 - val_batch_ndcg: 0.3804\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 615.3638 - mae: 0.0253 - batch_ndcg: 0.8303 - val_loss: 496.7483 - val_mae: 0.0052 - val_batch_ndcg: 0.3828\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 35.7808\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.8958\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.6611\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3799\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8308\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5894\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3984\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3341\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2966\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2520\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2577\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2226\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2080\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1740\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1853\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1648\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1520\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1432\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1421\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1307\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 695.6539 - mae: 0.0263 - batch_ndcg: 0.6263 - val_loss: 509.8000 - val_mae: 0.0052 - val_batch_ndcg: 0.3568\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 666.3373 - mae: 0.0265 - batch_ndcg: 0.7617 - val_loss: 504.4112 - val_mae: 0.0052 - val_batch_ndcg: 0.3726\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 641.9702 - mae: 0.0258 - batch_ndcg: 0.7817 - val_loss: 501.8408 - val_mae: 0.0052 - val_batch_ndcg: 0.3744\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 640.5868 - mae: 0.0260 - batch_ndcg: 0.8005 - val_loss: 499.6092 - val_mae: 0.0052 - val_batch_ndcg: 0.3763\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 641.6085 - mae: 0.0261 - batch_ndcg: 0.8108 - val_loss: 499.2213 - val_mae: 0.0052 - val_batch_ndcg: 0.3839\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 634.9100 - mae: 0.0259 - batch_ndcg: 0.8165 - val_loss: 498.0343 - val_mae: 0.0052 - val_batch_ndcg: 0.3739\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 632.4541 - mae: 0.0259 - batch_ndcg: 0.8223 - val_loss: 497.8174 - val_mae: 0.0052 - val_batch_ndcg: 0.3838\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 618.6618 - mae: 0.0254 - batch_ndcg: 0.8262 - val_loss: 496.9523 - val_mae: 0.0052 - val_batch_ndcg: 0.3806\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 641.4973 - mae: 0.0264 - batch_ndcg: 0.8340 - val_loss: 496.2492 - val_mae: 0.0052 - val_batch_ndcg: 0.3773\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 622.6210 - mae: 0.0257 - batch_ndcg: 0.8351 - val_loss: 496.1855 - val_mae: 0.0052 - val_batch_ndcg: 0.3824\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.0818\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.9605\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.7351\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3246\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8032\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5390\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4571\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3081\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2613\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2529\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2163\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2365\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2198\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2354\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1837\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1589\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1578\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1703\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1413\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1401\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 684.5810 - mae: 0.0259 - batch_ndcg: 0.6286 - val_loss: 509.2619 - val_mae: 0.0052 - val_batch_ndcg: 0.3614\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 625.7851 - mae: 0.0251 - batch_ndcg: 0.7633 - val_loss: 503.1632 - val_mae: 0.0052 - val_batch_ndcg: 0.3743\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 639.6163 - mae: 0.0259 - batch_ndcg: 0.7959 - val_loss: 500.7262 - val_mae: 0.0052 - val_batch_ndcg: 0.3728\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 638.3466 - mae: 0.0260 - batch_ndcg: 0.8065 - val_loss: 499.2001 - val_mae: 0.0052 - val_batch_ndcg: 0.3745\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 641.2037 - mae: 0.0262 - batch_ndcg: 0.8151 - val_loss: 498.2433 - val_mae: 0.0052 - val_batch_ndcg: 0.3795\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 625.0712 - mae: 0.0256 - batch_ndcg: 0.8172 - val_loss: 497.7246 - val_mae: 0.0052 - val_batch_ndcg: 0.3790\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 621.5108 - mae: 0.0255 - batch_ndcg: 0.8251 - val_loss: 497.0182 - val_mae: 0.0052 - val_batch_ndcg: 0.3824\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 635.6504 - mae: 0.0262 - batch_ndcg: 0.8332 - val_loss: 496.4416 - val_mae: 0.0052 - val_batch_ndcg: 0.3873\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 617.1049 - mae: 0.0255 - batch_ndcg: 0.8314 - val_loss: 495.4169 - val_mae: 0.0052 - val_batch_ndcg: 0.3779\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 618.4596 - mae: 0.0256 - batch_ndcg: 0.8394 - val_loss: 496.1247 - val_mae: 0.0052 - val_batch_ndcg: 0.3776\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.0897\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.1250\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.8401\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3313\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8945\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5532\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4028\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3117\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2833\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2438\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1903\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2034\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1735\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1805\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1562\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1193\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1104\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1063\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1027\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0932\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 684.8409 - mae: 0.0259 - batch_ndcg: 0.6309 - val_loss: 508.1351 - val_mae: 0.0052 - val_batch_ndcg: 0.3629\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 628.4366 - mae: 0.0252 - batch_ndcg: 0.7687 - val_loss: 502.2154 - val_mae: 0.0052 - val_batch_ndcg: 0.3849\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 649.4315 - mae: 0.0263 - batch_ndcg: 0.7967 - val_loss: 500.1165 - val_mae: 0.0052 - val_batch_ndcg: 0.3737\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 622.6031 - mae: 0.0254 - batch_ndcg: 0.8093 - val_loss: 498.7084 - val_mae: 0.0052 - val_batch_ndcg: 0.3777\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 613.4813 - mae: 0.0252 - batch_ndcg: 0.8141 - val_loss: 497.5377 - val_mae: 0.0052 - val_batch_ndcg: 0.3728\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 651.2056 - mae: 0.0267 - batch_ndcg: 0.8234 - val_loss: 496.4527 - val_mae: 0.0052 - val_batch_ndcg: 0.3757\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 645.3763 - mae: 0.0265 - batch_ndcg: 0.8287 - val_loss: 496.3752 - val_mae: 0.0052 - val_batch_ndcg: 0.3771\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 621.6262 - mae: 0.0257 - batch_ndcg: 0.8311 - val_loss: 496.3086 - val_mae: 0.0052 - val_batch_ndcg: 0.3807\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 627.9497 - mae: 0.0259 - batch_ndcg: 0.8329 - val_loss: 495.9600 - val_mae: 0.0052 - val_batch_ndcg: 0.3793\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 630.6408 - mae: 0.0261 - batch_ndcg: 0.8375 - val_loss: 495.0416 - val_mae: 0.0052 - val_batch_ndcg: 0.3765\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.5373\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.0394\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.6863\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3842\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8291\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5477\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3796\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3049\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2687\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2419\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2479\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2102\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1715\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1699\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1897\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1456\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1450\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1774\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1837\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1277\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 680.6721 - mae: 0.0259 - batch_ndcg: 0.6458 - val_loss: 507.2647 - val_mae: 0.0052 - val_batch_ndcg: 0.3594\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 649.1824 - mae: 0.0261 - batch_ndcg: 0.7778 - val_loss: 501.8710 - val_mae: 0.0052 - val_batch_ndcg: 0.3747\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 608.5634 - mae: 0.0249 - batch_ndcg: 0.7964 - val_loss: 500.1600 - val_mae: 0.0052 - val_batch_ndcg: 0.3773\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 619.2617 - mae: 0.0255 - batch_ndcg: 0.8117 - val_loss: 498.9546 - val_mae: 0.0052 - val_batch_ndcg: 0.3808\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 636.5096 - mae: 0.0261 - batch_ndcg: 0.8163 - val_loss: 497.4820 - val_mae: 0.0052 - val_batch_ndcg: 0.3768\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 598.7029 - mae: 0.0247 - batch_ndcg: 0.8217 - val_loss: 496.0853 - val_mae: 0.0052 - val_batch_ndcg: 0.3871\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 620.2183 - mae: 0.0257 - batch_ndcg: 0.8314 - val_loss: 496.3734 - val_mae: 0.0052 - val_batch_ndcg: 0.3776\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 613.6115 - mae: 0.0254 - batch_ndcg: 0.8333 - val_loss: 495.7026 - val_mae: 0.0052 - val_batch_ndcg: 0.3836\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 622.0303 - mae: 0.0258 - batch_ndcg: 0.8413 - val_loss: 495.2433 - val_mae: 0.0052 - val_batch_ndcg: 0.3796\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 611.2048 - mae: 0.0254 - batch_ndcg: 0.8392 - val_loss: 495.3587 - val_mae: 0.0052 - val_batch_ndcg: 0.3737\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.0221\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.7572\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.0550\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4322\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8432\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5658\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3822\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3110\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2812\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2838\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2162\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2100\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1914\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1810\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2044\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1702\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1422\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1159\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1261\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1410\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 691.2884 - mae: 0.0264 - batch_ndcg: 0.6498 - val_loss: 507.1195 - val_mae: 0.0052 - val_batch_ndcg: 0.3690\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 634.7715 - mae: 0.0256 - batch_ndcg: 0.7801 - val_loss: 501.1829 - val_mae: 0.0052 - val_batch_ndcg: 0.3764\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 621.2533 - mae: 0.0254 - batch_ndcg: 0.8015 - val_loss: 499.4958 - val_mae: 0.0052 - val_batch_ndcg: 0.3768\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 628.0336 - mae: 0.0258 - batch_ndcg: 0.8128 - val_loss: 497.9045 - val_mae: 0.0052 - val_batch_ndcg: 0.3816\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 631.1643 - mae: 0.0259 - batch_ndcg: 0.8174 - val_loss: 497.1580 - val_mae: 0.0052 - val_batch_ndcg: 0.3833\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 611.1041 - mae: 0.0253 - batch_ndcg: 0.8275 - val_loss: 496.4166 - val_mae: 0.0052 - val_batch_ndcg: 0.3743\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 618.1460 - mae: 0.0256 - batch_ndcg: 0.8349 - val_loss: 496.0111 - val_mae: 0.0052 - val_batch_ndcg: 0.3780\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 583.5281 - mae: 0.0243 - batch_ndcg: 0.8314 - val_loss: 495.6935 - val_mae: 0.0052 - val_batch_ndcg: 0.3784\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 640.0640 - mae: 0.0265 - batch_ndcg: 0.8425 - val_loss: 494.9883 - val_mae: 0.0052 - val_batch_ndcg: 0.3737\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 617.2495 - mae: 0.0257 - batch_ndcg: 0.8432 - val_loss: 495.0650 - val_mae: 0.0052 - val_batch_ndcg: 0.3821\n",
            "Epoch 1/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 37.0731\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.8618\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.0833\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4951\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9712\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6174\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4686\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3166\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3123\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2413\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1738\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1643\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1463\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1778\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1460\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1167\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1483\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2273\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1987\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2107\n",
            "Epoch 1/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 679.1473 - mae: 0.0259 - batch_ndcg: 0.6590 - val_loss: 506.9664 - val_mae: 0.0052 - val_batch_ndcg: 0.3623\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 646.4832 - mae: 0.0261 - batch_ndcg: 0.7831 - val_loss: 501.7194 - val_mae: 0.0052 - val_batch_ndcg: 0.3723\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 660.8464 - mae: 0.0269 - batch_ndcg: 0.8048 - val_loss: 499.3952 - val_mae: 0.0052 - val_batch_ndcg: 0.3779\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 634.2240 - mae: 0.0260 - batch_ndcg: 0.8156 - val_loss: 498.0250 - val_mae: 0.0052 - val_batch_ndcg: 0.3730\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 616.0331 - mae: 0.0254 - batch_ndcg: 0.8232 - val_loss: 496.7787 - val_mae: 0.0052 - val_batch_ndcg: 0.3823\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 636.1321 - mae: 0.0263 - batch_ndcg: 0.8298 - val_loss: 496.2597 - val_mae: 0.0052 - val_batch_ndcg: 0.3792\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 631.7429 - mae: 0.0262 - batch_ndcg: 0.8362 - val_loss: 495.6053 - val_mae: 0.0052 - val_batch_ndcg: 0.3837\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 631.5682 - mae: 0.0261 - batch_ndcg: 0.8366 - val_loss: 495.9061 - val_mae: 0.0052 - val_batch_ndcg: 0.3818\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 622.6578 - mae: 0.0259 - batch_ndcg: 0.8434 - val_loss: 495.2213 - val_mae: 0.0052 - val_batch_ndcg: 0.3790\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 639.5372 - mae: 0.0266 - batch_ndcg: 0.8492 - val_loss: 494.8250 - val_mae: 0.0052 - val_batch_ndcg: 0.3764\n",
            "CPU times: user 2min 28s, sys: 14.3 s, total: 2min 43s\n",
            "Wall time: 2min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTyPlYN6Fbl0",
        "outputId": "7a7282c2-e609-401d-efff-42cbbd609009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "show_history(total_hist, 'loss', 'batch_ndcg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1D4m0ZRwo4K",
        "outputId": "efc83e02-fd70-471c-ad66-3a3dc5c7578b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "pred = test_predictor(test_q, model, n_item, batch_size)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 726, 2041,   88, ...,   34,    9,  187],\n",
              "       [1767, 1509, 1631, ...,  662,  733, 1644],\n",
              "       [ 128,  167,  246, ...,   27,  704,   97],\n",
              "       ...,\n",
              "       [ 872,  945, 2450, ...,  184,  167,  246],\n",
              "       [ 217,  726,  748, ...,  277,  338,  127],\n",
              "       [ 711,  960,  217, ...,  392,  714,  170]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88-eqqC6gU7U",
        "outputId": "c3098a72-12f7-4df7-882d-d7f2b428f767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "m_ndcg, m_recall, m_precision, map_k = evaluation(test_a, pred)\n",
        "print(f'nDCG: {m_ndcg:.5f}',\n",
        "      f'\\nRecall: {m_recall:.5f}',\n",
        "      f'\\nPrecision: {m_precision:.5f}',\n",
        "      f'\\nMAP: {map_k:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nDCG: 0.53160 \n",
            "Recall: 0.22548 \n",
            "Precision: 0.17293 \n",
            "MAP: 0.13357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGSWMi2K3_8s"
      },
      "source": [
        "### 2. Mult-DAE(Logistic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdfTxrY1UQvk",
        "outputId": "6f2a742e-6278-454b-8452-547fa4b28ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "optimizer = Adam(learning_rate = 0.001, decay = 1e-5)\n",
        "encoder, model = VAE(n_user, n_item, latent_dim = 200, optimizer = optimizer, likelihood = 'logistic')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"VAE\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 3706)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mean (Dense)                    (None, 200)          741400      input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "log_var (Dense)                 (None, 200)          741400      input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sampling_7 (Sampling)           (None, 200)          0           mean[1][0]                       \n",
            "                                                                 log_var[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 3706)         744906      sampling_7[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_19 (TensorFlowO [(None, 3706)]       0           output[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_11 (TensorFlo [(None, 200)]        0           log_var[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_7 (TensorFlowOp [(None, 200)]        0           log_var[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log_4 (TensorFlowOp [(None, 3706)]       0           output[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_18 (TensorFlowO [(None, 3706)]       0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log_5 (TensorFlowOp [(None, 3706)]       0           tf_op_layer_Sub_19[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_16 (TensorFlowO [(None, 200)]        0           tf_op_layer_AddV2_11[0][0]       \n",
            "                                                                 tf_op_layer_Exp_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_7 (TensorFlo [(None, 200)]        0           mean[1][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_15 (TensorFlowO [(None, 3706)]       0           input[0][0]                      \n",
            "                                                                 tf_op_layer_Log_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_16 (TensorFlowO [(None, 3706)]       0           tf_op_layer_Sub_18[0][0]         \n",
            "                                                                 tf_op_layer_Log_5[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_17 (TensorFlowO [(None, 200)]        0           tf_op_layer_Sub_16[0][0]         \n",
            "                                                                 tf_op_layer_Square_7[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_12 (TensorFlo [(None, 3706)]       0           tf_op_layer_Mul_15[0][0]         \n",
            "                                                                 tf_op_layer_Mul_16[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_10 (TensorFlowO [(None,)]            0           tf_op_layer_Sub_17[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_11 (TensorFlowO [(None,)]            0           tf_op_layer_AddV2_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_14 (TensorFlowO [(None,)]            0           tf_op_layer_Sum_10[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Neg_3 (TensorFlowOp [(None,)]            0           tf_op_layer_Sum_11[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_17 (TensorFlowO [(None,)]            0           tf_op_layer_Mul_14[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_13 (TensorFlo [(None,)]            0           tf_op_layer_Neg_3[0][0]          \n",
            "                                                                 tf_op_layer_Mul_17[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_3 (TensorFlowO [()]                 0           tf_op_layer_AddV2_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_loss_7 (AddLoss)            ()                   0           tf_op_layer_Mean_3[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 2,227,706\n",
            "Trainable params: 2,227,706\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2gbiOYlUd3Y",
        "outputId": "642835e0-012e-4a85-ddfe-b93fe70c1a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "epochs = 100\n",
        "total_hist = {}\n",
        "for _ in range(epochs):\n",
        "    anneal_size, epoch_size = 8, 4\n",
        "    encoder.fit(x = train_gen, epochs = anneal_size, steps_per_epoch = steps_per_epoch, verbose = 1)\n",
        "    hist = model.fit(x = train_gen, validation_data = valid_gen, epochs = epoch_size, verbose = 1,\n",
        "                     steps_per_epoch = steps_per_epoch, validation_steps = validation_steps)\n",
        "    for key in hist.history.keys():\n",
        "        total_hist[key] = total_hist.get(key, []) + hist.history[key]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 60.2815\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 55.2123\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 52.2020\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 48.3812\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 44.3531\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 39.5086\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 35.7355\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 31.9626\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 1662.4313 - mae: 0.2711 - batch_ndcg: 0.3610 - val_loss: 609.4084 - val_mae: 0.0826 - val_batch_ndcg: 0.2854\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 515.5509 - mae: 0.0633 - batch_ndcg: 0.5851 - val_loss: 452.2550 - val_mae: 0.0520 - val_batch_ndcg: 0.2873\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 453.1554 - mae: 0.0540 - batch_ndcg: 0.5907 - val_loss: 415.6838 - val_mae: 0.0461 - val_batch_ndcg: 0.2945\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 423.4128 - mae: 0.0510 - batch_ndcg: 0.5896 - val_loss: 383.4303 - val_mae: 0.0417 - val_batch_ndcg: 0.3036\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 96.6305\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 58.4812\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 29.8124\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 23.7776\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 19.9582\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 16.4900\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 13.6821\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 11.3077\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 832.5712 - mae: 0.1177 - batch_ndcg: 0.5168 - val_loss: 484.5328 - val_mae: 0.0574 - val_batch_ndcg: 0.2763\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 466.2327 - mae: 0.0559 - batch_ndcg: 0.5897 - val_loss: 439.8510 - val_mae: 0.0526 - val_batch_ndcg: 0.2963\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 445.1464 - mae: 0.0547 - batch_ndcg: 0.6010 - val_loss: 402.1821 - val_mae: 0.0465 - val_batch_ndcg: 0.3033\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 406.8020 - mae: 0.0503 - batch_ndcg: 0.6162 - val_loss: 379.3184 - val_mae: 0.0437 - val_batch_ndcg: 0.3117\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 79.1501\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 25.9189\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 11.5386\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.0679\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 6.4661\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.5159\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.4868\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.8067\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 773.2346 - mae: 0.1084 - batch_ndcg: 0.5190 - val_loss: 456.1480 - val_mae: 0.0531 - val_batch_ndcg: 0.2886\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 469.2244 - mae: 0.0568 - batch_ndcg: 0.5926 - val_loss: 424.4804 - val_mae: 0.0524 - val_batch_ndcg: 0.2946\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 431.5449 - mae: 0.0541 - batch_ndcg: 0.6037 - val_loss: 397.5548 - val_mae: 0.0470 - val_batch_ndcg: 0.3088\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 404.8290 - mae: 0.0500 - batch_ndcg: 0.6165 - val_loss: 386.0589 - val_mae: 0.0467 - val_batch_ndcg: 0.3141\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 68.6474\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 16.0547\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 6.1442\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.7044\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.5227\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.2068\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.8303\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.5191\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 743.0767 - mae: 0.1057 - batch_ndcg: 0.5311 - val_loss: 446.7047 - val_mae: 0.0530 - val_batch_ndcg: 0.2947\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 454.2413 - mae: 0.0560 - batch_ndcg: 0.6116 - val_loss: 418.7477 - val_mae: 0.0495 - val_batch_ndcg: 0.3058\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 431.4164 - mae: 0.0540 - batch_ndcg: 0.6153 - val_loss: 393.5395 - val_mae: 0.0464 - val_batch_ndcg: 0.3180\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 417.0678 - mae: 0.0523 - batch_ndcg: 0.6276 - val_loss: 380.9369 - val_mae: 0.0452 - val_batch_ndcg: 0.3266\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 55.6140\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 11.8877\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.8002\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.4513\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4689\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0744\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9103\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7757\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 707.0649 - mae: 0.1050 - batch_ndcg: 0.5369 - val_loss: 432.4100 - val_mae: 0.0525 - val_batch_ndcg: 0.3054\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 434.5694 - mae: 0.0548 - batch_ndcg: 0.6231 - val_loss: 393.8182 - val_mae: 0.0470 - val_batch_ndcg: 0.3172\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 412.8537 - mae: 0.0528 - batch_ndcg: 0.6326 - val_loss: 383.0929 - val_mae: 0.0464 - val_batch_ndcg: 0.3190\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 389.6471 - mae: 0.0502 - batch_ndcg: 0.6353 - val_loss: 355.8368 - val_mae: 0.0416 - val_batch_ndcg: 0.3271\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 47.7014\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 10.3150\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.6391\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4572\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8505\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6371\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5413\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4651\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 680.2167 - mae: 0.1016 - batch_ndcg: 0.5486 - val_loss: 401.8132 - val_mae: 0.0474 - val_batch_ndcg: 0.3189\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 406.6880 - mae: 0.0523 - batch_ndcg: 0.6438 - val_loss: 369.8075 - val_mae: 0.0448 - val_batch_ndcg: 0.3276\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 385.8463 - mae: 0.0499 - batch_ndcg: 0.6441 - val_loss: 358.8167 - val_mae: 0.0431 - val_batch_ndcg: 0.3311\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 365.1175 - mae: 0.0474 - batch_ndcg: 0.6498 - val_loss: 346.8760 - val_mae: 0.0404 - val_batch_ndcg: 0.3429\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 44.4474\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.6627\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.5639\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0019\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5878\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4985\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4011\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3823\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 659.3503 - mae: 0.0969 - batch_ndcg: 0.5633 - val_loss: 390.0398 - val_mae: 0.0484 - val_batch_ndcg: 0.3300\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 396.8576 - mae: 0.0511 - batch_ndcg: 0.6530 - val_loss: 354.1293 - val_mae: 0.0425 - val_batch_ndcg: 0.3391\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 378.9410 - mae: 0.0495 - batch_ndcg: 0.6580 - val_loss: 350.8412 - val_mae: 0.0419 - val_batch_ndcg: 0.3446\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 365.1715 - mae: 0.0472 - batch_ndcg: 0.6610 - val_loss: 335.4604 - val_mae: 0.0383 - val_batch_ndcg: 0.3459\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 42.3760\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.2050\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.5395\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7285\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5075\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4565\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3277\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2980\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 660.8917 - mae: 0.0947 - batch_ndcg: 0.5719 - val_loss: 388.7557 - val_mae: 0.0465 - val_batch_ndcg: 0.3337\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 399.6827 - mae: 0.0519 - batch_ndcg: 0.6578 - val_loss: 353.4900 - val_mae: 0.0412 - val_batch_ndcg: 0.3440\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 373.0634 - mae: 0.0486 - batch_ndcg: 0.6595 - val_loss: 341.2559 - val_mae: 0.0400 - val_batch_ndcg: 0.3398\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 369.0152 - mae: 0.0479 - batch_ndcg: 0.6653 - val_loss: 333.8944 - val_mae: 0.0393 - val_batch_ndcg: 0.3479\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 40.7803\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.7037\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.1944\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6559\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4275\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3454\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2910\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1968\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 649.3481 - mae: 0.0943 - batch_ndcg: 0.5809 - val_loss: 384.6444 - val_mae: 0.0468 - val_batch_ndcg: 0.3389\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 385.9000 - mae: 0.0505 - batch_ndcg: 0.6615 - val_loss: 355.5438 - val_mae: 0.0428 - val_batch_ndcg: 0.3416\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 376.2715 - mae: 0.0494 - batch_ndcg: 0.6611 - val_loss: 339.7353 - val_mae: 0.0408 - val_batch_ndcg: 0.3465\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 360.2880 - mae: 0.0472 - batch_ndcg: 0.6628 - val_loss: 332.3390 - val_mae: 0.0384 - val_batch_ndcg: 0.3496\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 37.7902\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 5.1613\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0661\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5924\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4163\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3072\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2555\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2615\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 620.0206 - mae: 0.0893 - batch_ndcg: 0.5797 - val_loss: 382.9485 - val_mae: 0.0451 - val_batch_ndcg: 0.3416\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 390.4188 - mae: 0.0510 - batch_ndcg: 0.6614 - val_loss: 347.0573 - val_mae: 0.0406 - val_batch_ndcg: 0.3499\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 369.6548 - mae: 0.0486 - batch_ndcg: 0.6664 - val_loss: 333.5839 - val_mae: 0.0387 - val_batch_ndcg: 0.3491\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 359.8222 - mae: 0.0473 - batch_ndcg: 0.6669 - val_loss: 325.6832 - val_mae: 0.0379 - val_batch_ndcg: 0.3545\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 39.1411\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.0490\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0701\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5544\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4126\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2720\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2073\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2203\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 626.2606 - mae: 0.0887 - batch_ndcg: 0.5912 - val_loss: 376.3326 - val_mae: 0.0456 - val_batch_ndcg: 0.3402\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 381.1635 - mae: 0.0502 - batch_ndcg: 0.6539 - val_loss: 340.6848 - val_mae: 0.0406 - val_batch_ndcg: 0.3467\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 368.7650 - mae: 0.0484 - batch_ndcg: 0.6619 - val_loss: 336.6010 - val_mae: 0.0397 - val_batch_ndcg: 0.3492\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 357.3523 - mae: 0.0472 - batch_ndcg: 0.6670 - val_loss: 319.2079 - val_mae: 0.0369 - val_batch_ndcg: 0.3523\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 40.0249\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.5439\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.1443\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6192\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4079\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3144\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2566\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1998\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 595.7703 - mae: 0.0875 - batch_ndcg: 0.5910 - val_loss: 362.5498 - val_mae: 0.0432 - val_batch_ndcg: 0.3467\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 382.9483 - mae: 0.0504 - batch_ndcg: 0.6675 - val_loss: 336.8283 - val_mae: 0.0399 - val_batch_ndcg: 0.3551\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 357.9901 - mae: 0.0480 - batch_ndcg: 0.6671 - val_loss: 324.0157 - val_mae: 0.0376 - val_batch_ndcg: 0.3541\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 351.9133 - mae: 0.0468 - batch_ndcg: 0.6785 - val_loss: 318.0361 - val_mae: 0.0366 - val_batch_ndcg: 0.3547\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 38.5178\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.9337\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0510\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6312\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4061\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3288\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2431\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 592.6165 - mae: 0.0870 - batch_ndcg: 0.5965 - val_loss: 369.8520 - val_mae: 0.0467 - val_batch_ndcg: 0.3501\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 377.0605 - mae: 0.0507 - batch_ndcg: 0.6717 - val_loss: 331.6063 - val_mae: 0.0404 - val_batch_ndcg: 0.3598\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 352.2478 - mae: 0.0475 - batch_ndcg: 0.6828 - val_loss: 325.2063 - val_mae: 0.0384 - val_batch_ndcg: 0.3605\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 338.5180 - mae: 0.0454 - batch_ndcg: 0.6839 - val_loss: 308.3467 - val_mae: 0.0353 - val_batch_ndcg: 0.3631\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 38.4937\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.4174\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.1033\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5816\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3414\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2658\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2308\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1870\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 578.5667 - mae: 0.0845 - batch_ndcg: 0.6003 - val_loss: 352.3871 - val_mae: 0.0416 - val_batch_ndcg: 0.3514\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 365.4919 - mae: 0.0490 - batch_ndcg: 0.6805 - val_loss: 325.4259 - val_mae: 0.0390 - val_batch_ndcg: 0.3540\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 350.5931 - mae: 0.0470 - batch_ndcg: 0.6866 - val_loss: 319.9354 - val_mae: 0.0379 - val_batch_ndcg: 0.3616\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 336.6729 - mae: 0.0451 - batch_ndcg: 0.6807 - val_loss: 310.8863 - val_mae: 0.0370 - val_batch_ndcg: 0.3593\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 38.7553\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 5.1422\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0442\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5515\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3997\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3257\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2504\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2219\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 569.4370 - mae: 0.0849 - batch_ndcg: 0.6059 - val_loss: 343.8493 - val_mae: 0.0406 - val_batch_ndcg: 0.3578\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 359.8948 - mae: 0.0488 - batch_ndcg: 0.6827 - val_loss: 317.2243 - val_mae: 0.0379 - val_batch_ndcg: 0.3565\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 353.1767 - mae: 0.0479 - batch_ndcg: 0.6935 - val_loss: 307.1337 - val_mae: 0.0354 - val_batch_ndcg: 0.3623\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 332.0345 - mae: 0.0451 - batch_ndcg: 0.6909 - val_loss: 303.9301 - val_mae: 0.0344 - val_batch_ndcg: 0.3671\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 37.5743\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.5420\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0224\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5186\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3473\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2727\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2212\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1718\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 556.3680 - mae: 0.0839 - batch_ndcg: 0.6134 - val_loss: 346.4958 - val_mae: 0.0433 - val_batch_ndcg: 0.3568\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 349.6996 - mae: 0.0476 - batch_ndcg: 0.6860 - val_loss: 327.9051 - val_mae: 0.0404 - val_batch_ndcg: 0.3602\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 343.1451 - mae: 0.0469 - batch_ndcg: 0.6862 - val_loss: 312.4567 - val_mae: 0.0376 - val_batch_ndcg: 0.3655\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 339.7776 - mae: 0.0461 - batch_ndcg: 0.7020 - val_loss: 305.2558 - val_mae: 0.0361 - val_batch_ndcg: 0.3680\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.6934\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.1737\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0837\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5595\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3996\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2738\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2370\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1807\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 568.7983 - mae: 0.0791 - batch_ndcg: 0.6119 - val_loss: 353.1431 - val_mae: 0.0438 - val_batch_ndcg: 0.3502\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 359.2596 - mae: 0.0492 - batch_ndcg: 0.6861 - val_loss: 324.4584 - val_mae: 0.0399 - val_batch_ndcg: 0.3591\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 345.3594 - mae: 0.0470 - batch_ndcg: 0.6933 - val_loss: 308.9902 - val_mae: 0.0352 - val_batch_ndcg: 0.3692\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 336.1665 - mae: 0.0454 - batch_ndcg: 0.6953 - val_loss: 306.4546 - val_mae: 0.0354 - val_batch_ndcg: 0.3638\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 38.9837\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.5161\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0009\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5838\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3596\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2524\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2349\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2123\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 561.1144 - mae: 0.0811 - batch_ndcg: 0.6159 - val_loss: 362.5593 - val_mae: 0.0458 - val_batch_ndcg: 0.3502\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 361.5951 - mae: 0.0496 - batch_ndcg: 0.6881 - val_loss: 320.0053 - val_mae: 0.0397 - val_batch_ndcg: 0.3629\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 353.0727 - mae: 0.0485 - batch_ndcg: 0.6912 - val_loss: 310.2960 - val_mae: 0.0361 - val_batch_ndcg: 0.3645\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 330.1283 - mae: 0.0450 - batch_ndcg: 0.6950 - val_loss: 305.6131 - val_mae: 0.0353 - val_batch_ndcg: 0.3683\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 36.4228\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.1216\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.0322\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5370\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3661\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2859\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2369\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2128\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 551.9103 - mae: 0.0836 - batch_ndcg: 0.6184 - val_loss: 342.5533 - val_mae: 0.0425 - val_batch_ndcg: 0.3534\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 350.2034 - mae: 0.0485 - batch_ndcg: 0.6849 - val_loss: 316.7135 - val_mae: 0.0388 - val_batch_ndcg: 0.3666\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 338.6292 - mae: 0.0462 - batch_ndcg: 0.6991 - val_loss: 303.6826 - val_mae: 0.0355 - val_batch_ndcg: 0.3675\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 335.1860 - mae: 0.0459 - batch_ndcg: 0.7032 - val_loss: 300.3201 - val_mae: 0.0357 - val_batch_ndcg: 0.3643\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 33.4079\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.6650\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9286\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5435\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3591\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2927\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2291\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2042\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 563.7450 - mae: 0.0805 - batch_ndcg: 0.6161 - val_loss: 356.2141 - val_mae: 0.0450 - val_batch_ndcg: 0.3455\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 357.0191 - mae: 0.0493 - batch_ndcg: 0.6846 - val_loss: 318.4500 - val_mae: 0.0383 - val_batch_ndcg: 0.3622\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 345.3132 - mae: 0.0476 - batch_ndcg: 0.6943 - val_loss: 311.9777 - val_mae: 0.0374 - val_batch_ndcg: 0.3651\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 337.3005 - mae: 0.0461 - batch_ndcg: 0.6957 - val_loss: 306.4839 - val_mae: 0.0364 - val_batch_ndcg: 0.3674\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 34.5003\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.0814\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.0177\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5064\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3859\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2791\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2284\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2138\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 550.7757 - mae: 0.0808 - batch_ndcg: 0.6048 - val_loss: 348.4578 - val_mae: 0.0433 - val_batch_ndcg: 0.3449\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 362.2423 - mae: 0.0496 - batch_ndcg: 0.6867 - val_loss: 312.5596 - val_mae: 0.0378 - val_batch_ndcg: 0.3630\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 341.4192 - mae: 0.0473 - batch_ndcg: 0.6913 - val_loss: 305.3076 - val_mae: 0.0368 - val_batch_ndcg: 0.3646\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 325.3179 - mae: 0.0444 - batch_ndcg: 0.6993 - val_loss: 298.8098 - val_mae: 0.0351 - val_batch_ndcg: 0.3656\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 33.5703\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.9646\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8999\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4998\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3241\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2199\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2175\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1603\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 548.4788 - mae: 0.0801 - batch_ndcg: 0.6065 - val_loss: 343.6817 - val_mae: 0.0411 - val_batch_ndcg: 0.3539\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 362.5315 - mae: 0.0498 - batch_ndcg: 0.6886 - val_loss: 325.0691 - val_mae: 0.0411 - val_batch_ndcg: 0.3637\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 343.6887 - mae: 0.0479 - batch_ndcg: 0.6956 - val_loss: 303.4520 - val_mae: 0.0357 - val_batch_ndcg: 0.3674\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 331.9925 - mae: 0.0459 - batch_ndcg: 0.6977 - val_loss: 294.7460 - val_mae: 0.0333 - val_batch_ndcg: 0.3675\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 32.3109\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 4.0728\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9307\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5023\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3283\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2443\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2008\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1776\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 529.0981 - mae: 0.0764 - batch_ndcg: 0.6071 - val_loss: 351.9824 - val_mae: 0.0437 - val_batch_ndcg: 0.3450\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 361.6685 - mae: 0.0497 - batch_ndcg: 0.6746 - val_loss: 317.5607 - val_mae: 0.0384 - val_batch_ndcg: 0.3584\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 332.0706 - mae: 0.0461 - batch_ndcg: 0.6937 - val_loss: 304.1268 - val_mae: 0.0357 - val_batch_ndcg: 0.3624\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 325.4448 - mae: 0.0451 - batch_ndcg: 0.6977 - val_loss: 295.4174 - val_mae: 0.0347 - val_batch_ndcg: 0.3708\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 30.8970\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.6938\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8679\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4850\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3304\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2391\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2165\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1867\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 532.8264 - mae: 0.0772 - batch_ndcg: 0.6000 - val_loss: 339.1509 - val_mae: 0.0403 - val_batch_ndcg: 0.3403\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 356.5742 - mae: 0.0489 - batch_ndcg: 0.6742 - val_loss: 314.5860 - val_mae: 0.0380 - val_batch_ndcg: 0.3548\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 343.0385 - mae: 0.0470 - batch_ndcg: 0.6888 - val_loss: 301.5416 - val_mae: 0.0357 - val_batch_ndcg: 0.3650\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 330.7944 - mae: 0.0458 - batch_ndcg: 0.7076 - val_loss: 295.3372 - val_mae: 0.0346 - val_batch_ndcg: 0.3688\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 29.3364\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.5471\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8662\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5123\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3158\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2382\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2501\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1810\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 527.5770 - mae: 0.0784 - batch_ndcg: 0.6040 - val_loss: 341.2955 - val_mae: 0.0430 - val_batch_ndcg: 0.3462\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 345.5191 - mae: 0.0487 - batch_ndcg: 0.6904 - val_loss: 315.2630 - val_mae: 0.0400 - val_batch_ndcg: 0.3622\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 323.2019 - mae: 0.0454 - batch_ndcg: 0.6998 - val_loss: 293.2905 - val_mae: 0.0355 - val_batch_ndcg: 0.3698\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 322.3474 - mae: 0.0451 - batch_ndcg: 0.7097 - val_loss: 288.8397 - val_mae: 0.0347 - val_batch_ndcg: 0.3698\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 28.1432\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 3.2811\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8584\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4884\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3548\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2593\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2029\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1655\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 528.1350 - mae: 0.0720 - batch_ndcg: 0.6089 - val_loss: 346.5261 - val_mae: 0.0437 - val_batch_ndcg: 0.3435\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 357.5616 - mae: 0.0491 - batch_ndcg: 0.6791 - val_loss: 312.9280 - val_mae: 0.0382 - val_batch_ndcg: 0.3647\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 336.9871 - mae: 0.0471 - batch_ndcg: 0.6959 - val_loss: 300.2553 - val_mae: 0.0362 - val_batch_ndcg: 0.3670\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 327.8984 - mae: 0.0456 - batch_ndcg: 0.7074 - val_loss: 288.6654 - val_mae: 0.0347 - val_batch_ndcg: 0.3690\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 29.1423\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.3974\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8787\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5208\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3191\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2390\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1918\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1434\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 513.5617 - mae: 0.0737 - batch_ndcg: 0.6118 - val_loss: 336.6285 - val_mae: 0.0407 - val_batch_ndcg: 0.3559\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 352.4129 - mae: 0.0489 - batch_ndcg: 0.6932 - val_loss: 312.6251 - val_mae: 0.0387 - val_batch_ndcg: 0.3673\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 331.8757 - mae: 0.0462 - batch_ndcg: 0.6966 - val_loss: 301.9635 - val_mae: 0.0362 - val_batch_ndcg: 0.3665\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 327.3461 - mae: 0.0455 - batch_ndcg: 0.7084 - val_loss: 290.5146 - val_mae: 0.0343 - val_batch_ndcg: 0.3629\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 29.4852\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.2676\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7776\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4950\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2764\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2167\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1785\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1694\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 503.7545 - mae: 0.0746 - batch_ndcg: 0.6148 - val_loss: 331.3912 - val_mae: 0.0418 - val_batch_ndcg: 0.3497\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 337.0958 - mae: 0.0473 - batch_ndcg: 0.6911 - val_loss: 307.1007 - val_mae: 0.0377 - val_batch_ndcg: 0.3692\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 322.7268 - mae: 0.0451 - batch_ndcg: 0.7048 - val_loss: 293.2552 - val_mae: 0.0354 - val_batch_ndcg: 0.3648\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 321.3235 - mae: 0.0445 - batch_ndcg: 0.7157 - val_loss: 285.0592 - val_mae: 0.0340 - val_batch_ndcg: 0.3713\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 29.8020\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.4820\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8995\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5472\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3597\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2591\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2192\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1997\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 489.5409 - mae: 0.0748 - batch_ndcg: 0.6238 - val_loss: 320.5372 - val_mae: 0.0401 - val_batch_ndcg: 0.3523\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 335.8204 - mae: 0.0472 - batch_ndcg: 0.6933 - val_loss: 296.3219 - val_mae: 0.0360 - val_batch_ndcg: 0.3628\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 321.0063 - mae: 0.0451 - batch_ndcg: 0.7044 - val_loss: 288.4910 - val_mae: 0.0349 - val_batch_ndcg: 0.3652\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 320.0150 - mae: 0.0447 - batch_ndcg: 0.7136 - val_loss: 284.8803 - val_mae: 0.0336 - val_batch_ndcg: 0.3764\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 29.0060\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 3.6308\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8949\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5180\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3932\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2930\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2289\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2075\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 497.8316 - mae: 0.0720 - batch_ndcg: 0.6319 - val_loss: 322.4779 - val_mae: 0.0405 - val_batch_ndcg: 0.3610\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 338.7504 - mae: 0.0476 - batch_ndcg: 0.7011 - val_loss: 297.6425 - val_mae: 0.0364 - val_batch_ndcg: 0.3638\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 318.3886 - mae: 0.0446 - batch_ndcg: 0.7111 - val_loss: 292.1767 - val_mae: 0.0359 - val_batch_ndcg: 0.3736\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 318.4766 - mae: 0.0446 - batch_ndcg: 0.7175 - val_loss: 290.6057 - val_mae: 0.0350 - val_batch_ndcg: 0.3783\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 27.7679\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 3.3229\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8629\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5088\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3342\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2516\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2041\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1751\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 487.7470 - mae: 0.0726 - batch_ndcg: 0.6206 - val_loss: 315.9612 - val_mae: 0.0375 - val_batch_ndcg: 0.3567\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 330.0650 - mae: 0.0467 - batch_ndcg: 0.6985 - val_loss: 299.5608 - val_mae: 0.0373 - val_batch_ndcg: 0.3629\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 317.5640 - mae: 0.0446 - batch_ndcg: 0.7111 - val_loss: 287.8315 - val_mae: 0.0341 - val_batch_ndcg: 0.3765\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 310.7509 - mae: 0.0435 - batch_ndcg: 0.7125 - val_loss: 282.3460 - val_mae: 0.0341 - val_batch_ndcg: 0.3713\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 28.3710\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 3.2733\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8648\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4731\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3850\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2584\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2030\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1818\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 477.2616 - mae: 0.0692 - batch_ndcg: 0.6255 - val_loss: 324.2156 - val_mae: 0.0407 - val_batch_ndcg: 0.3567\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 334.9314 - mae: 0.0479 - batch_ndcg: 0.7008 - val_loss: 299.9769 - val_mae: 0.0379 - val_batch_ndcg: 0.3660\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 326.4579 - mae: 0.0461 - batch_ndcg: 0.7143 - val_loss: 286.6954 - val_mae: 0.0345 - val_batch_ndcg: 0.3702\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 310.5386 - mae: 0.0436 - batch_ndcg: 0.7164 - val_loss: 280.6813 - val_mae: 0.0332 - val_batch_ndcg: 0.3667\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 26.4479\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 3.0043\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8123\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4867\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3364\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2611\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1881\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1597\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 492.4738 - mae: 0.0698 - batch_ndcg: 0.6248 - val_loss: 324.7409 - val_mae: 0.0403 - val_batch_ndcg: 0.3517\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 338.3067 - mae: 0.0474 - batch_ndcg: 0.6976 - val_loss: 294.3243 - val_mae: 0.0363 - val_batch_ndcg: 0.3686\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 323.9138 - mae: 0.0459 - batch_ndcg: 0.7111 - val_loss: 290.7376 - val_mae: 0.0355 - val_batch_ndcg: 0.3736\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 313.6924 - mae: 0.0442 - batch_ndcg: 0.7180 - val_loss: 280.9410 - val_mae: 0.0329 - val_batch_ndcg: 0.3728\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 26.4005\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.7329\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7994\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4522\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2969\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2132\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1672\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1424\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 485.7823 - mae: 0.0719 - batch_ndcg: 0.6204 - val_loss: 313.4258 - val_mae: 0.0393 - val_batch_ndcg: 0.3538\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 329.0224 - mae: 0.0470 - batch_ndcg: 0.7008 - val_loss: 296.4276 - val_mae: 0.0367 - val_batch_ndcg: 0.3652\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 315.5214 - mae: 0.0447 - batch_ndcg: 0.7105 - val_loss: 287.0460 - val_mae: 0.0351 - val_batch_ndcg: 0.3712\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 307.4602 - mae: 0.0434 - batch_ndcg: 0.7179 - val_loss: 279.7407 - val_mae: 0.0335 - val_batch_ndcg: 0.3820\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 25.0596\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.7278\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7657\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4552\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3195\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2270\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2035\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1574\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 479.2021 - mae: 0.0705 - batch_ndcg: 0.6203 - val_loss: 314.7153 - val_mae: 0.0382 - val_batch_ndcg: 0.3606\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 331.8069 - mae: 0.0466 - batch_ndcg: 0.7032 - val_loss: 289.9364 - val_mae: 0.0351 - val_batch_ndcg: 0.3682\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 316.3512 - mae: 0.0447 - batch_ndcg: 0.7150 - val_loss: 284.3385 - val_mae: 0.0344 - val_batch_ndcg: 0.3773\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 303.4092 - mae: 0.0429 - batch_ndcg: 0.7146 - val_loss: 274.0346 - val_mae: 0.0320 - val_batch_ndcg: 0.3667\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 26.0550\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.9959\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8515\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5231\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3484\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2626\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2046\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1883\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 476.9797 - mae: 0.0663 - batch_ndcg: 0.6168 - val_loss: 322.2242 - val_mae: 0.0380 - val_batch_ndcg: 0.3514\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 340.8145 - mae: 0.0471 - batch_ndcg: 0.6913 - val_loss: 294.7903 - val_mae: 0.0349 - val_batch_ndcg: 0.3603\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 323.5692 - mae: 0.0452 - batch_ndcg: 0.7091 - val_loss: 286.2831 - val_mae: 0.0342 - val_batch_ndcg: 0.3685\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 315.3539 - mae: 0.0444 - batch_ndcg: 0.7138 - val_loss: 284.1658 - val_mae: 0.0336 - val_batch_ndcg: 0.3729\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 27.3969\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.9261\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8533\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4890\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2915\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2218\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1842\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1592\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 457.9491 - mae: 0.0699 - batch_ndcg: 0.6133 - val_loss: 307.1447 - val_mae: 0.0357 - val_batch_ndcg: 0.3545\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 331.9748 - mae: 0.0468 - batch_ndcg: 0.6969 - val_loss: 291.3720 - val_mae: 0.0355 - val_batch_ndcg: 0.3667\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 316.4104 - mae: 0.0446 - batch_ndcg: 0.7089 - val_loss: 283.1063 - val_mae: 0.0338 - val_batch_ndcg: 0.3749\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 305.3271 - mae: 0.0430 - batch_ndcg: 0.7139 - val_loss: 278.3175 - val_mae: 0.0331 - val_batch_ndcg: 0.3840\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 25.7251\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.6706\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8275\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4322\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3409\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2515\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2246\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1798\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 475.1306 - mae: 0.0696 - batch_ndcg: 0.6252 - val_loss: 312.7083 - val_mae: 0.0385 - val_batch_ndcg: 0.3583\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 328.8289 - mae: 0.0470 - batch_ndcg: 0.7003 - val_loss: 293.3123 - val_mae: 0.0361 - val_batch_ndcg: 0.3701\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 309.0116 - mae: 0.0440 - batch_ndcg: 0.7029 - val_loss: 282.2218 - val_mae: 0.0334 - val_batch_ndcg: 0.3684\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 306.5045 - mae: 0.0432 - batch_ndcg: 0.7136 - val_loss: 271.6205 - val_mae: 0.0304 - val_batch_ndcg: 0.3737\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 24.9171\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.4179\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8159\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4675\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3011\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2308\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2149\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1713\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 472.8025 - mae: 0.0651 - batch_ndcg: 0.6230 - val_loss: 324.1700 - val_mae: 0.0401 - val_batch_ndcg: 0.3502\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 335.6259 - mae: 0.0472 - batch_ndcg: 0.6842 - val_loss: 294.9048 - val_mae: 0.0359 - val_batch_ndcg: 0.3661\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 315.3371 - mae: 0.0448 - batch_ndcg: 0.6990 - val_loss: 281.6782 - val_mae: 0.0335 - val_batch_ndcg: 0.3733\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 313.9149 - mae: 0.0443 - batch_ndcg: 0.7165 - val_loss: 276.3683 - val_mae: 0.0323 - val_batch_ndcg: 0.3756\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 24.3129\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.2140\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7594\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4668\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2901\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2169\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2113\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1729\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 446.3305 - mae: 0.0675 - batch_ndcg: 0.6134 - val_loss: 306.9835 - val_mae: 0.0358 - val_batch_ndcg: 0.3536\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 321.7942 - mae: 0.0456 - batch_ndcg: 0.6885 - val_loss: 288.5833 - val_mae: 0.0345 - val_batch_ndcg: 0.3661\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 314.4691 - mae: 0.0443 - batch_ndcg: 0.7113 - val_loss: 276.8983 - val_mae: 0.0331 - val_batch_ndcg: 0.3781\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 309.8049 - mae: 0.0437 - batch_ndcg: 0.7182 - val_loss: 272.3479 - val_mae: 0.0322 - val_batch_ndcg: 0.3706\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 24.0809\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2304\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7425\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5184\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3770\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2516\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1852\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1590\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 462.3820 - mae: 0.0673 - batch_ndcg: 0.6240 - val_loss: 306.0526 - val_mae: 0.0371 - val_batch_ndcg: 0.3515\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 328.3416 - mae: 0.0464 - batch_ndcg: 0.6971 - val_loss: 289.6392 - val_mae: 0.0359 - val_batch_ndcg: 0.3631\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 320.0700 - mae: 0.0453 - batch_ndcg: 0.7106 - val_loss: 278.7065 - val_mae: 0.0330 - val_batch_ndcg: 0.3705\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 306.8854 - mae: 0.0434 - batch_ndcg: 0.7197 - val_loss: 273.2157 - val_mae: 0.0315 - val_batch_ndcg: 0.3724\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 24.4714\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.3180\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8543\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4642\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3085\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2837\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2056\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2115\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 454.1019 - mae: 0.0650 - batch_ndcg: 0.6266 - val_loss: 305.3362 - val_mae: 0.0360 - val_batch_ndcg: 0.3479\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 331.9974 - mae: 0.0467 - batch_ndcg: 0.6987 - val_loss: 289.3328 - val_mae: 0.0353 - val_batch_ndcg: 0.3642\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 316.4097 - mae: 0.0446 - batch_ndcg: 0.7121 - val_loss: 278.7498 - val_mae: 0.0327 - val_batch_ndcg: 0.3728\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 312.8523 - mae: 0.0442 - batch_ndcg: 0.7151 - val_loss: 272.3351 - val_mae: 0.0323 - val_batch_ndcg: 0.3713\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 25.5267\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.5240\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7954\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4590\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3257\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2477\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2016\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1997\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 443.6208 - mae: 0.0663 - batch_ndcg: 0.6326 - val_loss: 299.8757 - val_mae: 0.0365 - val_batch_ndcg: 0.3647\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 321.5676 - mae: 0.0460 - batch_ndcg: 0.7046 - val_loss: 282.9207 - val_mae: 0.0350 - val_batch_ndcg: 0.3741\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 308.5603 - mae: 0.0441 - batch_ndcg: 0.7080 - val_loss: 280.6420 - val_mae: 0.0341 - val_batch_ndcg: 0.3689\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 301.9514 - mae: 0.0427 - batch_ndcg: 0.7174 - val_loss: 273.0123 - val_mae: 0.0323 - val_batch_ndcg: 0.3747\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 24.0521\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2745\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7573\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4532\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3137\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2254\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1976\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2073\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 422.3448 - mae: 0.0624 - batch_ndcg: 0.6229 - val_loss: 300.6856 - val_mae: 0.0351 - val_batch_ndcg: 0.3583\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 327.5981 - mae: 0.0463 - batch_ndcg: 0.7029 - val_loss: 282.4017 - val_mae: 0.0336 - val_batch_ndcg: 0.3698\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 311.5841 - mae: 0.0441 - batch_ndcg: 0.7164 - val_loss: 272.5409 - val_mae: 0.0323 - val_batch_ndcg: 0.3747\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 303.3724 - mae: 0.0430 - batch_ndcg: 0.7224 - val_loss: 270.3932 - val_mae: 0.0321 - val_batch_ndcg: 0.3758\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 24.4443\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.5281\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8301\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4422\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3387\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2515\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2104\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1649\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 435.5667 - mae: 0.0633 - batch_ndcg: 0.6303 - val_loss: 302.9785 - val_mae: 0.0368 - val_batch_ndcg: 0.3539\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 319.9684 - mae: 0.0454 - batch_ndcg: 0.7062 - val_loss: 280.8893 - val_mae: 0.0338 - val_batch_ndcg: 0.3770\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 310.2796 - mae: 0.0440 - batch_ndcg: 0.7145 - val_loss: 273.0911 - val_mae: 0.0324 - val_batch_ndcg: 0.3743\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 307.7256 - mae: 0.0435 - batch_ndcg: 0.7246 - val_loss: 270.9075 - val_mae: 0.0313 - val_batch_ndcg: 0.3801\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 23.7297\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.4065\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7443\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4181\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2829\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2287\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1873\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1731\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 431.8039 - mae: 0.0620 - batch_ndcg: 0.6309 - val_loss: 297.8383 - val_mae: 0.0337 - val_batch_ndcg: 0.3654\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 323.0903 - mae: 0.0457 - batch_ndcg: 0.7015 - val_loss: 279.0784 - val_mae: 0.0328 - val_batch_ndcg: 0.3793\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 306.5048 - mae: 0.0434 - batch_ndcg: 0.7166 - val_loss: 276.7563 - val_mae: 0.0327 - val_batch_ndcg: 0.3671\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 301.3798 - mae: 0.0427 - batch_ndcg: 0.7219 - val_loss: 265.3934 - val_mae: 0.0305 - val_batch_ndcg: 0.3813\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 24.5067\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.4552\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7792\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4569\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2817\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2328\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2133\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1922\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - ETA: 0s - loss: 417.7968 - mae: 0.0629 - batch_ndcg: 0.6374WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 417.7968 - mae: 0.0629 - batch_ndcg: 0.6374 - val_loss: 291.1156 - val_mae: 0.0338 - val_batch_ndcg: 0.3643\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 319.3368 - mae: 0.0454 - batch_ndcg: 0.7037 - val_loss: 278.5132 - val_mae: 0.0331 - val_batch_ndcg: 0.3664\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 302.6404 - mae: 0.0433 - batch_ndcg: 0.7162 - val_loss: 269.5761 - val_mae: 0.0320 - val_batch_ndcg: 0.3729\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 295.5621 - mae: 0.0421 - batch_ndcg: 0.7255 - val_loss: 266.1379 - val_mae: 0.0304 - val_batch_ndcg: 0.3740\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 22.5721\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.2388\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6901\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4169\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2702\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2270\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1919\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1606\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 416.0243 - mae: 0.0618 - batch_ndcg: 0.6408 - val_loss: 289.5018 - val_mae: 0.0328 - val_batch_ndcg: 0.3589\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 312.5252 - mae: 0.0444 - batch_ndcg: 0.7093 - val_loss: 277.5968 - val_mae: 0.0321 - val_batch_ndcg: 0.3718\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 304.6010 - mae: 0.0431 - batch_ndcg: 0.7166 - val_loss: 272.3069 - val_mae: 0.0332 - val_batch_ndcg: 0.3717\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 298.2741 - mae: 0.0424 - batch_ndcg: 0.7247 - val_loss: 267.0953 - val_mae: 0.0307 - val_batch_ndcg: 0.3761\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 23.2771\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.3093\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7918\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4542\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3125\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2138\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1562\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1433\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 414.3673 - mae: 0.0606 - batch_ndcg: 0.6393 - val_loss: 291.4300 - val_mae: 0.0348 - val_batch_ndcg: 0.3555\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 308.1202 - mae: 0.0441 - batch_ndcg: 0.7115 - val_loss: 273.6563 - val_mae: 0.0319 - val_batch_ndcg: 0.3667\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 302.4669 - mae: 0.0431 - batch_ndcg: 0.7201 - val_loss: 267.7441 - val_mae: 0.0303 - val_batch_ndcg: 0.3789\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 294.6414 - mae: 0.0419 - batch_ndcg: 0.7295 - val_loss: 264.1146 - val_mae: 0.0310 - val_batch_ndcg: 0.3792\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.3892\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 2.0712\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7395\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4196\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3240\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2366\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1877\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1678\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 402.8775 - mae: 0.0599 - batch_ndcg: 0.6430 - val_loss: 287.7116 - val_mae: 0.0347 - val_batch_ndcg: 0.3661\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 313.6505 - mae: 0.0447 - batch_ndcg: 0.7204 - val_loss: 279.2215 - val_mae: 0.0338 - val_batch_ndcg: 0.3752\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 303.7215 - mae: 0.0436 - batch_ndcg: 0.7271 - val_loss: 266.0529 - val_mae: 0.0311 - val_batch_ndcg: 0.3758\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 293.7661 - mae: 0.0419 - batch_ndcg: 0.7276 - val_loss: 260.8254 - val_mae: 0.0296 - val_batch_ndcg: 0.3828\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 21.6603\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.0885\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8178\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4330\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3307\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2506\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2061\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1681\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 406.5669 - mae: 0.0578 - batch_ndcg: 0.6423 - val_loss: 291.3927 - val_mae: 0.0333 - val_batch_ndcg: 0.3659\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 314.4926 - mae: 0.0444 - batch_ndcg: 0.7141 - val_loss: 269.2195 - val_mae: 0.0315 - val_batch_ndcg: 0.3726\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 306.7067 - mae: 0.0433 - batch_ndcg: 0.7208 - val_loss: 266.6929 - val_mae: 0.0313 - val_batch_ndcg: 0.3763\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 296.7833 - mae: 0.0421 - batch_ndcg: 0.7317 - val_loss: 265.4391 - val_mae: 0.0312 - val_batch_ndcg: 0.3744\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 24.1346\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.3675\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7310\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4625\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2820\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2070\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1999\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1855\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 405.1852 - mae: 0.0592 - batch_ndcg: 0.6392 - val_loss: 294.2399 - val_mae: 0.0353 - val_batch_ndcg: 0.3597\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 317.6809 - mae: 0.0451 - batch_ndcg: 0.7147 - val_loss: 269.0047 - val_mae: 0.0317 - val_batch_ndcg: 0.3782\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 299.5468 - mae: 0.0426 - batch_ndcg: 0.7194 - val_loss: 265.5351 - val_mae: 0.0315 - val_batch_ndcg: 0.3766\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 294.0451 - mae: 0.0419 - batch_ndcg: 0.7310 - val_loss: 260.4549 - val_mae: 0.0299 - val_batch_ndcg: 0.3786\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.8915\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2156\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7794\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4440\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3073\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2359\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2057\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1690\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 397.1484 - mae: 0.0591 - batch_ndcg: 0.6426 - val_loss: 282.0410 - val_mae: 0.0329 - val_batch_ndcg: 0.3631\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 312.4337 - mae: 0.0444 - batch_ndcg: 0.7211 - val_loss: 270.2792 - val_mae: 0.0318 - val_batch_ndcg: 0.3749\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 301.3964 - mae: 0.0429 - batch_ndcg: 0.7243 - val_loss: 265.9979 - val_mae: 0.0320 - val_batch_ndcg: 0.3770\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 287.4737 - mae: 0.0408 - batch_ndcg: 0.7312 - val_loss: 260.4043 - val_mae: 0.0303 - val_batch_ndcg: 0.3833\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.7382\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 2.2440\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8223\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4678\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3575\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2618\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2378\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2312\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 395.5921 - mae: 0.0572 - batch_ndcg: 0.6449 - val_loss: 281.9701 - val_mae: 0.0337 - val_batch_ndcg: 0.3636\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 314.0618 - mae: 0.0440 - batch_ndcg: 0.7135 - val_loss: 271.9557 - val_mae: 0.0322 - val_batch_ndcg: 0.3704\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 298.3030 - mae: 0.0425 - batch_ndcg: 0.7270 - val_loss: 265.8836 - val_mae: 0.0307 - val_batch_ndcg: 0.3744\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.7532 - mae: 0.0408 - batch_ndcg: 0.7293 - val_loss: 259.7210 - val_mae: 0.0302 - val_batch_ndcg: 0.3781\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 25.0477\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.3766\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7698\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5105\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3467\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2470\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1973\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1678\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 392.9507 - mae: 0.0595 - batch_ndcg: 0.6445 - val_loss: 279.0604 - val_mae: 0.0322 - val_batch_ndcg: 0.3684\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 309.0966 - mae: 0.0440 - batch_ndcg: 0.7179 - val_loss: 270.3629 - val_mae: 0.0327 - val_batch_ndcg: 0.3747\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 295.9364 - mae: 0.0422 - batch_ndcg: 0.7279 - val_loss: 264.7238 - val_mae: 0.0313 - val_batch_ndcg: 0.3749\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 294.7118 - mae: 0.0420 - batch_ndcg: 0.7380 - val_loss: 260.2331 - val_mae: 0.0296 - val_batch_ndcg: 0.3840\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.9042\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2213\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7699\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4480\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3341\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2622\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2094\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1721\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 387.7621 - mae: 0.0567 - batch_ndcg: 0.6540 - val_loss: 279.5846 - val_mae: 0.0316 - val_batch_ndcg: 0.3642\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 303.1962 - mae: 0.0432 - batch_ndcg: 0.7174 - val_loss: 266.3145 - val_mae: 0.0313 - val_batch_ndcg: 0.3679\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 296.7659 - mae: 0.0424 - batch_ndcg: 0.7310 - val_loss: 262.0710 - val_mae: 0.0311 - val_batch_ndcg: 0.3759\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.7060 - mae: 0.0414 - batch_ndcg: 0.7352 - val_loss: 255.9895 - val_mae: 0.0299 - val_batch_ndcg: 0.3837\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 23.5351\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.3039\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7643\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4605\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3103\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2441\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1982\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1668\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 395.0283 - mae: 0.0557 - batch_ndcg: 0.6450 - val_loss: 285.4664 - val_mae: 0.0338 - val_batch_ndcg: 0.3577\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 300.7516 - mae: 0.0428 - batch_ndcg: 0.7147 - val_loss: 267.3010 - val_mae: 0.0306 - val_batch_ndcg: 0.3687\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 296.4117 - mae: 0.0423 - batch_ndcg: 0.7290 - val_loss: 259.4296 - val_mae: 0.0298 - val_batch_ndcg: 0.3767\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 288.7873 - mae: 0.0410 - batch_ndcg: 0.7332 - val_loss: 256.1676 - val_mae: 0.0289 - val_batch_ndcg: 0.3822\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.7459\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2718\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7256\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4311\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3060\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2290\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1710\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1603\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 382.1758 - mae: 0.0560 - batch_ndcg: 0.6466 - val_loss: 276.0324 - val_mae: 0.0315 - val_batch_ndcg: 0.3667\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 303.7693 - mae: 0.0435 - batch_ndcg: 0.7188 - val_loss: 266.1029 - val_mae: 0.0303 - val_batch_ndcg: 0.3697\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 298.7387 - mae: 0.0424 - batch_ndcg: 0.7337 - val_loss: 257.7654 - val_mae: 0.0295 - val_batch_ndcg: 0.3736\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 283.6015 - mae: 0.0404 - batch_ndcg: 0.7324 - val_loss: 254.4630 - val_mae: 0.0295 - val_batch_ndcg: 0.3852\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.6348\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2929\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7740\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4148\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3043\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2386\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1630\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1363\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 378.6302 - mae: 0.0554 - batch_ndcg: 0.6520 - val_loss: 277.6453 - val_mae: 0.0327 - val_batch_ndcg: 0.3677\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 301.1052 - mae: 0.0430 - batch_ndcg: 0.7205 - val_loss: 265.3087 - val_mae: 0.0314 - val_batch_ndcg: 0.3846\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 297.9135 - mae: 0.0424 - batch_ndcg: 0.7296 - val_loss: 258.8260 - val_mae: 0.0298 - val_batch_ndcg: 0.3785\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 283.3626 - mae: 0.0403 - batch_ndcg: 0.7333 - val_loss: 255.9999 - val_mae: 0.0290 - val_batch_ndcg: 0.3847\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.4295\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.2725\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7294\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4786\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3131\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2676\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2057\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1733\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 372.5755 - mae: 0.0554 - batch_ndcg: 0.6531 - val_loss: 275.6400 - val_mae: 0.0316 - val_batch_ndcg: 0.3621\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 295.3775 - mae: 0.0422 - batch_ndcg: 0.7188 - val_loss: 265.1323 - val_mae: 0.0320 - val_batch_ndcg: 0.3766\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 291.3785 - mae: 0.0417 - batch_ndcg: 0.7327 - val_loss: 257.2704 - val_mae: 0.0304 - val_batch_ndcg: 0.3786\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 289.7437 - mae: 0.0413 - batch_ndcg: 0.7414 - val_loss: 252.9471 - val_mae: 0.0296 - val_batch_ndcg: 0.3853\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 21.7076\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.0799\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7418\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4498\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3019\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2379\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1757\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1492\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 366.8138 - mae: 0.0535 - batch_ndcg: 0.6445 - val_loss: 271.4840 - val_mae: 0.0302 - val_batch_ndcg: 0.3667\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 303.2854 - mae: 0.0431 - batch_ndcg: 0.7192 - val_loss: 261.2585 - val_mae: 0.0301 - val_batch_ndcg: 0.3763\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 293.1016 - mae: 0.0415 - batch_ndcg: 0.7340 - val_loss: 255.6013 - val_mae: 0.0295 - val_batch_ndcg: 0.3777\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 282.0792 - mae: 0.0401 - batch_ndcg: 0.7378 - val_loss: 254.0258 - val_mae: 0.0291 - val_batch_ndcg: 0.3813\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 22.8174\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.1480\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7224\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4854\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3114\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2230\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1906\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1560\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 374.1613 - mae: 0.0554 - batch_ndcg: 0.6555 - val_loss: 269.8929 - val_mae: 0.0308 - val_batch_ndcg: 0.3639\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 296.9240 - mae: 0.0427 - batch_ndcg: 0.7261 - val_loss: 260.3384 - val_mae: 0.0309 - val_batch_ndcg: 0.3757\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 293.7050 - mae: 0.0422 - batch_ndcg: 0.7354 - val_loss: 256.9779 - val_mae: 0.0301 - val_batch_ndcg: 0.3877\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 287.4263 - mae: 0.0411 - batch_ndcg: 0.7387 - val_loss: 253.1091 - val_mae: 0.0290 - val_batch_ndcg: 0.3804\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 21.7512\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.0530\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7305\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4357\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3307\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2788\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1969\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1552\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 370.1973 - mae: 0.0549 - batch_ndcg: 0.6543 - val_loss: 268.1584 - val_mae: 0.0311 - val_batch_ndcg: 0.3614\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 293.7992 - mae: 0.0422 - batch_ndcg: 0.7249 - val_loss: 259.2065 - val_mae: 0.0304 - val_batch_ndcg: 0.3825\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 292.6767 - mae: 0.0420 - batch_ndcg: 0.7346 - val_loss: 253.7569 - val_mae: 0.0296 - val_batch_ndcg: 0.3792\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 283.9393 - mae: 0.0408 - batch_ndcg: 0.7416 - val_loss: 250.5144 - val_mae: 0.0291 - val_batch_ndcg: 0.3814\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 21.3784\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.1289\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.8469\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5172\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3274\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2756\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2059\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1926\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 363.7425 - mae: 0.0532 - batch_ndcg: 0.6553 - val_loss: 273.5034 - val_mae: 0.0322 - val_batch_ndcg: 0.3627\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 291.9009 - mae: 0.0419 - batch_ndcg: 0.7262 - val_loss: 259.9671 - val_mae: 0.0306 - val_batch_ndcg: 0.3749\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 287.8830 - mae: 0.0414 - batch_ndcg: 0.7362 - val_loss: 253.5614 - val_mae: 0.0291 - val_batch_ndcg: 0.3809\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 288.5229 - mae: 0.0414 - batch_ndcg: 0.7479 - val_loss: 251.9970 - val_mae: 0.0293 - val_batch_ndcg: 0.3850\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 20.2307\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.0035\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7422\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4689\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3292\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2460\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2014\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1922\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 371.1961 - mae: 0.0533 - batch_ndcg: 0.6554 - val_loss: 269.2569 - val_mae: 0.0311 - val_batch_ndcg: 0.3617\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 293.0354 - mae: 0.0418 - batch_ndcg: 0.7217 - val_loss: 259.8125 - val_mae: 0.0305 - val_batch_ndcg: 0.3797\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 286.2573 - mae: 0.0408 - batch_ndcg: 0.7375 - val_loss: 251.3711 - val_mae: 0.0288 - val_batch_ndcg: 0.3784\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 282.1478 - mae: 0.0405 - batch_ndcg: 0.7415 - val_loss: 249.9662 - val_mae: 0.0289 - val_batch_ndcg: 0.3873\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 21.2091\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.1335\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7801\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4879\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3321\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2854\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2300\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1625\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 367.8435 - mae: 0.0534 - batch_ndcg: 0.6589 - val_loss: 270.6530 - val_mae: 0.0316 - val_batch_ndcg: 0.3634\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 286.7557 - mae: 0.0413 - batch_ndcg: 0.7188 - val_loss: 259.1898 - val_mae: 0.0314 - val_batch_ndcg: 0.3811\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 292.1151 - mae: 0.0421 - batch_ndcg: 0.7399 - val_loss: 253.3783 - val_mae: 0.0295 - val_batch_ndcg: 0.3793\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 278.0593 - mae: 0.0400 - batch_ndcg: 0.7390 - val_loss: 249.4435 - val_mae: 0.0283 - val_batch_ndcg: 0.3823\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 20.4192\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.9202\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6988\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4493\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3442\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2574\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1986\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1548\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 365.7707 - mae: 0.0539 - batch_ndcg: 0.6583 - val_loss: 267.8094 - val_mae: 0.0316 - val_batch_ndcg: 0.3638\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.5406 - mae: 0.0418 - batch_ndcg: 0.7211 - val_loss: 257.8040 - val_mae: 0.0305 - val_batch_ndcg: 0.3735\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 281.5734 - mae: 0.0404 - batch_ndcg: 0.7357 - val_loss: 254.1395 - val_mae: 0.0301 - val_batch_ndcg: 0.3813\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 280.5424 - mae: 0.0404 - batch_ndcg: 0.7484 - val_loss: 246.7716 - val_mae: 0.0291 - val_batch_ndcg: 0.3882\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.3906\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8627\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7611\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5078\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3104\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2353\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1828\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1913\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 363.4504 - mae: 0.0528 - batch_ndcg: 0.6587 - val_loss: 266.2236 - val_mae: 0.0306 - val_batch_ndcg: 0.3590\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.8335 - mae: 0.0416 - batch_ndcg: 0.7238 - val_loss: 255.0632 - val_mae: 0.0301 - val_batch_ndcg: 0.3749\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 283.0765 - mae: 0.0407 - batch_ndcg: 0.7350 - val_loss: 249.9437 - val_mae: 0.0290 - val_batch_ndcg: 0.3772\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 283.9191 - mae: 0.0405 - batch_ndcg: 0.7444 - val_loss: 247.1977 - val_mae: 0.0280 - val_batch_ndcg: 0.3884\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 20.4292\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8742\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7339\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4540\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3265\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2573\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1953\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1656\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 364.3748 - mae: 0.0512 - batch_ndcg: 0.6499 - val_loss: 268.7708 - val_mae: 0.0292 - val_batch_ndcg: 0.3648\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 292.6368 - mae: 0.0412 - batch_ndcg: 0.7248 - val_loss: 257.9640 - val_mae: 0.0291 - val_batch_ndcg: 0.3801\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 286.0316 - mae: 0.0408 - batch_ndcg: 0.7382 - val_loss: 252.2336 - val_mae: 0.0293 - val_batch_ndcg: 0.3773\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 282.9282 - mae: 0.0403 - batch_ndcg: 0.7459 - val_loss: 249.0907 - val_mae: 0.0290 - val_batch_ndcg: 0.3842\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 21.2832\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.9982\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7484\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4480\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2915\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2195\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1678\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1670\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 356.3347 - mae: 0.0525 - batch_ndcg: 0.6567 - val_loss: 262.8592 - val_mae: 0.0306 - val_batch_ndcg: 0.3726\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 292.1829 - mae: 0.0423 - batch_ndcg: 0.7293 - val_loss: 253.4691 - val_mae: 0.0299 - val_batch_ndcg: 0.3886\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 286.0280 - mae: 0.0410 - batch_ndcg: 0.7423 - val_loss: 251.6193 - val_mae: 0.0298 - val_batch_ndcg: 0.3829\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 275.6504 - mae: 0.0396 - batch_ndcg: 0.7410 - val_loss: 246.5387 - val_mae: 0.0281 - val_batch_ndcg: 0.3859\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 20.2588\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.9462\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7201\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4444\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3405\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2135\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1846\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1346\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 352.8719 - mae: 0.0513 - batch_ndcg: 0.6507 - val_loss: 267.2100 - val_mae: 0.0316 - val_batch_ndcg: 0.3689\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 293.0277 - mae: 0.0422 - batch_ndcg: 0.7272 - val_loss: 252.9518 - val_mae: 0.0295 - val_batch_ndcg: 0.3794\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.8026 - mae: 0.0404 - batch_ndcg: 0.7380 - val_loss: 250.7099 - val_mae: 0.0293 - val_batch_ndcg: 0.3818\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 276.1355 - mae: 0.0396 - batch_ndcg: 0.7464 - val_loss: 245.8079 - val_mae: 0.0285 - val_batch_ndcg: 0.3874\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.4425\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8156\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7120\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4322\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2892\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2037\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1899\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1536\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 351.7218 - mae: 0.0510 - batch_ndcg: 0.6624 - val_loss: 260.0713 - val_mae: 0.0309 - val_batch_ndcg: 0.3670\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.6447 - mae: 0.0417 - batch_ndcg: 0.7234 - val_loss: 253.1114 - val_mae: 0.0299 - val_batch_ndcg: 0.3788\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 277.7489 - mae: 0.0399 - batch_ndcg: 0.7370 - val_loss: 248.5285 - val_mae: 0.0291 - val_batch_ndcg: 0.3814\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.3689 - mae: 0.0403 - batch_ndcg: 0.7509 - val_loss: 245.5783 - val_mae: 0.0283 - val_batch_ndcg: 0.3897\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.4483\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.9060\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7336\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4280\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3025\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2434\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2062\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1605\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 349.8901 - mae: 0.0504 - batch_ndcg: 0.6551 - val_loss: 262.2181 - val_mae: 0.0301 - val_batch_ndcg: 0.3710\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.2596 - mae: 0.0414 - batch_ndcg: 0.7340 - val_loss: 252.6388 - val_mae: 0.0291 - val_batch_ndcg: 0.3791\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 282.6387 - mae: 0.0406 - batch_ndcg: 0.7426 - val_loss: 249.0107 - val_mae: 0.0289 - val_batch_ndcg: 0.3890\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 282.1657 - mae: 0.0406 - batch_ndcg: 0.7492 - val_loss: 245.4940 - val_mae: 0.0276 - val_batch_ndcg: 0.3890\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.4530\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8736\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7178\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4344\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2972\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2200\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1791\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1512\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 350.5353 - mae: 0.0511 - batch_ndcg: 0.6581 - val_loss: 261.3602 - val_mae: 0.0316 - val_batch_ndcg: 0.3766\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.1431 - mae: 0.0418 - batch_ndcg: 0.7341 - val_loss: 253.8797 - val_mae: 0.0304 - val_batch_ndcg: 0.3827\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.8827 - mae: 0.0402 - batch_ndcg: 0.7400 - val_loss: 246.2776 - val_mae: 0.0280 - val_batch_ndcg: 0.3817\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 277.4561 - mae: 0.0397 - batch_ndcg: 0.7507 - val_loss: 244.6964 - val_mae: 0.0288 - val_batch_ndcg: 0.3949\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.8333\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8507\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6836\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3977\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2862\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2197\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2170\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2248\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 351.6572 - mae: 0.0503 - batch_ndcg: 0.6613 - val_loss: 260.5964 - val_mae: 0.0297 - val_batch_ndcg: 0.3627\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 284.9988 - mae: 0.0409 - batch_ndcg: 0.7299 - val_loss: 250.1727 - val_mae: 0.0286 - val_batch_ndcg: 0.3821\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.6792 - mae: 0.0400 - batch_ndcg: 0.7421 - val_loss: 249.7582 - val_mae: 0.0295 - val_batch_ndcg: 0.3843\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 276.8609 - mae: 0.0399 - batch_ndcg: 0.7507 - val_loss: 245.4233 - val_mae: 0.0286 - val_batch_ndcg: 0.3872\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.8504\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7959\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7244\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4375\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3202\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2557\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2076\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1544\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 348.1356 - mae: 0.0505 - batch_ndcg: 0.6616 - val_loss: 258.7306 - val_mae: 0.0306 - val_batch_ndcg: 0.3724\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 281.2642 - mae: 0.0406 - batch_ndcg: 0.7357 - val_loss: 249.7813 - val_mae: 0.0292 - val_batch_ndcg: 0.3794\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 277.4615 - mae: 0.0399 - batch_ndcg: 0.7419 - val_loss: 245.6126 - val_mae: 0.0283 - val_batch_ndcg: 0.3884\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 269.9176 - mae: 0.0388 - batch_ndcg: 0.7500 - val_loss: 243.7257 - val_mae: 0.0276 - val_batch_ndcg: 0.3869\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 19.5712\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.0500\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7602\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4834\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3792\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2488\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2259\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1805\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 336.2071 - mae: 0.0480 - batch_ndcg: 0.6658 - val_loss: 259.0646 - val_mae: 0.0296 - val_batch_ndcg: 0.3678\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 289.7122 - mae: 0.0416 - batch_ndcg: 0.7425 - val_loss: 249.0976 - val_mae: 0.0292 - val_batch_ndcg: 0.3901\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 281.0755 - mae: 0.0406 - batch_ndcg: 0.7481 - val_loss: 246.6630 - val_mae: 0.0285 - val_batch_ndcg: 0.3835\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 269.4547 - mae: 0.0385 - batch_ndcg: 0.7526 - val_loss: 243.6602 - val_mae: 0.0281 - val_batch_ndcg: 0.3842\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 19.4850\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7755\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7811\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4889\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3297\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2291\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2366\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1679\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 346.2209 - mae: 0.0493 - batch_ndcg: 0.6638 - val_loss: 258.2446 - val_mae: 0.0296 - val_batch_ndcg: 0.3719\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 285.4244 - mae: 0.0409 - batch_ndcg: 0.7354 - val_loss: 248.7852 - val_mae: 0.0285 - val_batch_ndcg: 0.3773\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.2167 - mae: 0.0401 - batch_ndcg: 0.7439 - val_loss: 243.8573 - val_mae: 0.0282 - val_batch_ndcg: 0.3874\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 275.2469 - mae: 0.0397 - batch_ndcg: 0.7537 - val_loss: 242.0196 - val_mae: 0.0273 - val_batch_ndcg: 0.3886\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.3390\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.9259\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7938\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4714\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3426\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2549\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2433\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1897\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 333.2605 - mae: 0.0485 - batch_ndcg: 0.6638 - val_loss: 254.7953 - val_mae: 0.0302 - val_batch_ndcg: 0.3719\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 277.7692 - mae: 0.0402 - batch_ndcg: 0.7349 - val_loss: 246.5821 - val_mae: 0.0293 - val_batch_ndcg: 0.3853\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 275.3855 - mae: 0.0397 - batch_ndcg: 0.7473 - val_loss: 242.8313 - val_mae: 0.0280 - val_batch_ndcg: 0.3863\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.2419 - mae: 0.0385 - batch_ndcg: 0.7542 - val_loss: 240.3616 - val_mae: 0.0278 - val_batch_ndcg: 0.3911\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 18.6464\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7840\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7715\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4375\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3377\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2266\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1893\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1731\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 337.8571 - mae: 0.0486 - batch_ndcg: 0.6624 - val_loss: 256.5905 - val_mae: 0.0305 - val_batch_ndcg: 0.3727\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.3577 - mae: 0.0405 - batch_ndcg: 0.7338 - val_loss: 247.7887 - val_mae: 0.0290 - val_batch_ndcg: 0.3816\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 271.9441 - mae: 0.0391 - batch_ndcg: 0.7485 - val_loss: 241.5278 - val_mae: 0.0275 - val_batch_ndcg: 0.3874\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.7384 - mae: 0.0385 - batch_ndcg: 0.7525 - val_loss: 239.2466 - val_mae: 0.0274 - val_batch_ndcg: 0.3929\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.1368\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8343\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7412\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4615\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3566\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2584\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2061\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1441\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 336.8826 - mae: 0.0494 - batch_ndcg: 0.6707 - val_loss: 255.5216 - val_mae: 0.0309 - val_batch_ndcg: 0.3723\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 277.5524 - mae: 0.0402 - batch_ndcg: 0.7332 - val_loss: 246.9476 - val_mae: 0.0291 - val_batch_ndcg: 0.3836\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 275.5072 - mae: 0.0398 - batch_ndcg: 0.7484 - val_loss: 242.6781 - val_mae: 0.0284 - val_batch_ndcg: 0.3890\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 273.7218 - mae: 0.0394 - batch_ndcg: 0.7585 - val_loss: 240.6261 - val_mae: 0.0278 - val_batch_ndcg: 0.3891\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 20.0748\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 2.0520\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7904\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5036\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3271\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2726\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2624\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2227\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 331.0436 - mae: 0.0480 - batch_ndcg: 0.6710 - val_loss: 254.8392 - val_mae: 0.0304 - val_batch_ndcg: 0.3778\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 279.4491 - mae: 0.0404 - batch_ndcg: 0.7400 - val_loss: 246.5872 - val_mae: 0.0288 - val_batch_ndcg: 0.3780\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 276.9637 - mae: 0.0400 - batch_ndcg: 0.7571 - val_loss: 240.0091 - val_mae: 0.0275 - val_batch_ndcg: 0.3889\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 270.0102 - mae: 0.0390 - batch_ndcg: 0.7591 - val_loss: 237.8541 - val_mae: 0.0267 - val_batch_ndcg: 0.3933\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.9573\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7839\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6772\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4095\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2827\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2334\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1877\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1479\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 332.0835 - mae: 0.0481 - batch_ndcg: 0.6727 - val_loss: 252.0647 - val_mae: 0.0289 - val_batch_ndcg: 0.3777\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 275.5014 - mae: 0.0398 - batch_ndcg: 0.7376 - val_loss: 243.4123 - val_mae: 0.0279 - val_batch_ndcg: 0.3854\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 268.1902 - mae: 0.0386 - batch_ndcg: 0.7490 - val_loss: 240.7453 - val_mae: 0.0274 - val_batch_ndcg: 0.3943\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 265.6524 - mae: 0.0382 - batch_ndcg: 0.7542 - val_loss: 236.6379 - val_mae: 0.0267 - val_batch_ndcg: 0.3973\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 19.7691\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.9574\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7409\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4582\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3038\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2588\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1644\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1354\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 335.8333 - mae: 0.0481 - batch_ndcg: 0.6707 - val_loss: 252.0818 - val_mae: 0.0291 - val_batch_ndcg: 0.3761\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 278.6021 - mae: 0.0402 - batch_ndcg: 0.7420 - val_loss: 241.4456 - val_mae: 0.0273 - val_batch_ndcg: 0.3898\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 271.2417 - mae: 0.0389 - batch_ndcg: 0.7508 - val_loss: 240.2818 - val_mae: 0.0275 - val_batch_ndcg: 0.3880\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 268.9633 - mae: 0.0387 - batch_ndcg: 0.7589 - val_loss: 237.4471 - val_mae: 0.0272 - val_batch_ndcg: 0.3902\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.9017\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.8322\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7354\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3976\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3188\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2304\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2035\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2059\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 323.6253 - mae: 0.0463 - batch_ndcg: 0.6629 - val_loss: 250.6270 - val_mae: 0.0286 - val_batch_ndcg: 0.3738\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 278.3214 - mae: 0.0400 - batch_ndcg: 0.7417 - val_loss: 243.3038 - val_mae: 0.0275 - val_batch_ndcg: 0.3858\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 270.4373 - mae: 0.0390 - batch_ndcg: 0.7541 - val_loss: 239.0367 - val_mae: 0.0271 - val_batch_ndcg: 0.3904\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 260.0461 - mae: 0.0376 - batch_ndcg: 0.7551 - val_loss: 236.9805 - val_mae: 0.0265 - val_batch_ndcg: 0.3912\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.1916\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7249\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6995\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4476\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3299\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2401\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1855\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1725\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 327.3232 - mae: 0.0464 - batch_ndcg: 0.6644 - val_loss: 251.6134 - val_mae: 0.0289 - val_batch_ndcg: 0.3771\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 272.2756 - mae: 0.0391 - batch_ndcg: 0.7349 - val_loss: 242.3545 - val_mae: 0.0276 - val_batch_ndcg: 0.3843\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 271.9981 - mae: 0.0391 - batch_ndcg: 0.7544 - val_loss: 238.7389 - val_mae: 0.0270 - val_batch_ndcg: 0.3901\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 263.5850 - mae: 0.0380 - batch_ndcg: 0.7532 - val_loss: 236.5684 - val_mae: 0.0265 - val_batch_ndcg: 0.3952\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.0652\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.7793\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7781\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4570\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3470\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2523\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1988\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1660\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 328.6457 - mae: 0.0472 - batch_ndcg: 0.6697 - val_loss: 249.7542 - val_mae: 0.0286 - val_batch_ndcg: 0.3771\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 275.1303 - mae: 0.0396 - batch_ndcg: 0.7391 - val_loss: 241.8426 - val_mae: 0.0275 - val_batch_ndcg: 0.3817\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 271.2316 - mae: 0.0390 - batch_ndcg: 0.7534 - val_loss: 238.0209 - val_mae: 0.0265 - val_batch_ndcg: 0.3872\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 268.9773 - mae: 0.0388 - batch_ndcg: 0.7633 - val_loss: 235.8327 - val_mae: 0.0267 - val_batch_ndcg: 0.4011\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 18.7122\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.7963\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6887\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4244\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2773\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2097\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1811\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1336\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 324.5215 - mae: 0.0469 - batch_ndcg: 0.6700 - val_loss: 248.2650 - val_mae: 0.0280 - val_batch_ndcg: 0.3762\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 279.4111 - mae: 0.0403 - batch_ndcg: 0.7468 - val_loss: 241.5497 - val_mae: 0.0277 - val_batch_ndcg: 0.3863\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 267.8647 - mae: 0.0386 - batch_ndcg: 0.7545 - val_loss: 237.7623 - val_mae: 0.0272 - val_batch_ndcg: 0.3838\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 258.0676 - mae: 0.0371 - batch_ndcg: 0.7638 - val_loss: 235.0988 - val_mae: 0.0265 - val_batch_ndcg: 0.4011\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.4199\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.9293\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7717\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4657\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3091\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2054\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1896\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2105\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 320.6979 - mae: 0.0463 - batch_ndcg: 0.6742 - val_loss: 248.0489 - val_mae: 0.0286 - val_batch_ndcg: 0.3752\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 274.7527 - mae: 0.0396 - batch_ndcg: 0.7440 - val_loss: 239.6554 - val_mae: 0.0270 - val_batch_ndcg: 0.3835\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 262.9171 - mae: 0.0380 - batch_ndcg: 0.7532 - val_loss: 236.7923 - val_mae: 0.0274 - val_batch_ndcg: 0.3889\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 266.0740 - mae: 0.0383 - batch_ndcg: 0.7643 - val_loss: 234.7413 - val_mae: 0.0272 - val_batch_ndcg: 0.3910\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.3706\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.6760\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6805\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3833\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2796\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2087\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1596\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1306\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 321.8081 - mae: 0.0462 - batch_ndcg: 0.6713 - val_loss: 246.8353 - val_mae: 0.0286 - val_batch_ndcg: 0.3724\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 279.6707 - mae: 0.0403 - batch_ndcg: 0.7482 - val_loss: 239.9574 - val_mae: 0.0281 - val_batch_ndcg: 0.3893\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 264.7537 - mae: 0.0381 - batch_ndcg: 0.7568 - val_loss: 235.7882 - val_mae: 0.0266 - val_batch_ndcg: 0.3909\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 258.9305 - mae: 0.0373 - batch_ndcg: 0.7633 - val_loss: 233.7310 - val_mae: 0.0266 - val_batch_ndcg: 0.3976\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 19.2639\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8778\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7344\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4209\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3084\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2133\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1995\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1674\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 318.8770 - mae: 0.0460 - batch_ndcg: 0.6724 - val_loss: 245.5602 - val_mae: 0.0269 - val_batch_ndcg: 0.3854\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 270.0470 - mae: 0.0387 - batch_ndcg: 0.7418 - val_loss: 238.0227 - val_mae: 0.0270 - val_batch_ndcg: 0.3861\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.4828 - mae: 0.0386 - batch_ndcg: 0.7606 - val_loss: 236.4849 - val_mae: 0.0269 - val_batch_ndcg: 0.3918\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 261.0266 - mae: 0.0377 - batch_ndcg: 0.7673 - val_loss: 233.2998 - val_mae: 0.0265 - val_batch_ndcg: 0.3978\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 17.9717\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7549\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7378\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4389\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3243\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2198\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1908\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1753\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 317.9533 - mae: 0.0457 - batch_ndcg: 0.6768 - val_loss: 244.9433 - val_mae: 0.0281 - val_batch_ndcg: 0.3772\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 271.3685 - mae: 0.0392 - batch_ndcg: 0.7521 - val_loss: 239.1310 - val_mae: 0.0270 - val_batch_ndcg: 0.3867\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 267.0024 - mae: 0.0386 - batch_ndcg: 0.7581 - val_loss: 235.7792 - val_mae: 0.0272 - val_batch_ndcg: 0.3929\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 262.5186 - mae: 0.0378 - batch_ndcg: 0.7677 - val_loss: 232.9367 - val_mae: 0.0265 - val_batch_ndcg: 0.3952\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.4955\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.8652\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7587\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4320\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2625\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2224\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1938\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1701\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 317.2755 - mae: 0.0454 - batch_ndcg: 0.6753 - val_loss: 245.9333 - val_mae: 0.0281 - val_batch_ndcg: 0.3754\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 273.1997 - mae: 0.0392 - batch_ndcg: 0.7550 - val_loss: 237.5354 - val_mae: 0.0271 - val_batch_ndcg: 0.3862\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.6982 - mae: 0.0387 - batch_ndcg: 0.7674 - val_loss: 233.1114 - val_mae: 0.0261 - val_batch_ndcg: 0.3902\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 261.3864 - mae: 0.0378 - batch_ndcg: 0.7687 - val_loss: 232.9487 - val_mae: 0.0266 - val_batch_ndcg: 0.3965\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.9804\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7753\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6891\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4372\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2807\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2311\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2299\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2369\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 316.8927 - mae: 0.0459 - batch_ndcg: 0.6786 - val_loss: 243.5394 - val_mae: 0.0277 - val_batch_ndcg: 0.3801\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.0165 - mae: 0.0384 - batch_ndcg: 0.7563 - val_loss: 236.1421 - val_mae: 0.0264 - val_batch_ndcg: 0.3908\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 264.9367 - mae: 0.0381 - batch_ndcg: 0.7654 - val_loss: 233.7068 - val_mae: 0.0264 - val_batch_ndcg: 0.3886\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.1291 - mae: 0.0387 - batch_ndcg: 0.7755 - val_loss: 231.3595 - val_mae: 0.0263 - val_batch_ndcg: 0.3917\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.3366\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7204\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7253\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4243\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3078\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2571\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1763\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1799\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 320.1765 - mae: 0.0459 - batch_ndcg: 0.6753 - val_loss: 243.5819 - val_mae: 0.0272 - val_batch_ndcg: 0.3774\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 267.2113 - mae: 0.0386 - batch_ndcg: 0.7509 - val_loss: 238.3783 - val_mae: 0.0278 - val_batch_ndcg: 0.3878\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 264.4221 - mae: 0.0383 - batch_ndcg: 0.7605 - val_loss: 233.1832 - val_mae: 0.0271 - val_batch_ndcg: 0.3949\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 258.0151 - mae: 0.0373 - batch_ndcg: 0.7695 - val_loss: 231.9639 - val_mae: 0.0264 - val_batch_ndcg: 0.3926\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 17.7521\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.7621\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7291\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4337\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3007\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2110\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1836\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1691\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 314.6702 - mae: 0.0451 - batch_ndcg: 0.6752 - val_loss: 243.2815 - val_mae: 0.0275 - val_batch_ndcg: 0.3842\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 265.9127 - mae: 0.0384 - batch_ndcg: 0.7480 - val_loss: 235.1227 - val_mae: 0.0263 - val_batch_ndcg: 0.3851\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 260.3757 - mae: 0.0376 - batch_ndcg: 0.7636 - val_loss: 232.4808 - val_mae: 0.0269 - val_batch_ndcg: 0.3973\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 255.8019 - mae: 0.0369 - batch_ndcg: 0.7677 - val_loss: 232.0687 - val_mae: 0.0268 - val_batch_ndcg: 0.4015\n",
            "Epoch 1/8\n",
            " 1/38 [..............................] - ETA: 0s - loss: 41.5912WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0075s). Check your callbacks.\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.0971\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7989\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7076\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4362\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2990\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2320\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1819\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1693\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 321.3197 - mae: 0.0458 - batch_ndcg: 0.6809 - val_loss: 242.5539 - val_mae: 0.0278 - val_batch_ndcg: 0.3813\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 270.7223 - mae: 0.0392 - batch_ndcg: 0.7600 - val_loss: 234.8708 - val_mae: 0.0266 - val_batch_ndcg: 0.3899\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 269.5192 - mae: 0.0391 - batch_ndcg: 0.7706 - val_loss: 231.5528 - val_mae: 0.0262 - val_batch_ndcg: 0.3919\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 262.4474 - mae: 0.0380 - batch_ndcg: 0.7758 - val_loss: 230.7841 - val_mae: 0.0258 - val_batch_ndcg: 0.3970\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 17.8182\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7756\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6860\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4297\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2754\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2100\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2010\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1568\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 313.3970 - mae: 0.0450 - batch_ndcg: 0.6779 - val_loss: 242.7017 - val_mae: 0.0271 - val_batch_ndcg: 0.3836\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 265.6475 - mae: 0.0383 - batch_ndcg: 0.7559 - val_loss: 234.9225 - val_mae: 0.0268 - val_batch_ndcg: 0.3878\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 261.4444 - mae: 0.0379 - batch_ndcg: 0.7673 - val_loss: 234.3978 - val_mae: 0.0279 - val_batch_ndcg: 0.3938\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 255.1894 - mae: 0.0370 - batch_ndcg: 0.7725 - val_loss: 230.5596 - val_mae: 0.0263 - val_batch_ndcg: 0.3956\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 17.7725\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7051\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7408\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4341\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3505\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2444\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1777\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1518\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 313.7888 - mae: 0.0448 - batch_ndcg: 0.6844 - val_loss: 241.0411 - val_mae: 0.0279 - val_batch_ndcg: 0.3781\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 261.3602 - mae: 0.0379 - batch_ndcg: 0.7512 - val_loss: 233.8106 - val_mae: 0.0272 - val_batch_ndcg: 0.3889\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 259.9149 - mae: 0.0377 - batch_ndcg: 0.7700 - val_loss: 231.2403 - val_mae: 0.0263 - val_batch_ndcg: 0.3999\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 256.8897 - mae: 0.0372 - batch_ndcg: 0.7797 - val_loss: 229.0457 - val_mae: 0.0264 - val_batch_ndcg: 0.4019\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 18.0627\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.7077\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6808\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4722\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2876\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2149\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1971\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.1597\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 310.1808 - mae: 0.0443 - batch_ndcg: 0.6763 - val_loss: 241.4028 - val_mae: 0.0277 - val_batch_ndcg: 0.3829\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 260.8259 - mae: 0.0377 - batch_ndcg: 0.7551 - val_loss: 234.4756 - val_mae: 0.0266 - val_batch_ndcg: 0.3895\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 258.2682 - mae: 0.0374 - batch_ndcg: 0.7687 - val_loss: 231.0057 - val_mae: 0.0269 - val_batch_ndcg: 0.3960\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 257.8275 - mae: 0.0374 - batch_ndcg: 0.7785 - val_loss: 228.6438 - val_mae: 0.0257 - val_batch_ndcg: 0.4010\n",
            "CPU times: user 10min 9s, sys: 54.3 s, total: 11min 3s\n",
            "Wall time: 8min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyiH-cvg5Mhp",
        "outputId": "9eab3809-c54d-436d-9f41-9791cbf2dd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "show_history(total_hist, 'loss', 'batch_ndcg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOTxwtdA5Ufn",
        "outputId": "6640e6e4-6ced-4557-f014-fa7236fb4b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "pred = test_predictor(test_q, model, n_item, batch_size)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 880,  171,  189, ..., 1631,  338,    4],\n",
              "       [  22,   33, 1046, ..., 1045,  168,   32],\n",
              "       [ 541,  788,  891, ...,    4,   60,  545],\n",
              "       ...,\n",
              "       [  38,    3,  128, ...,  113,  425,   39],\n",
              "       [  51,  104,  420, ...,  206,  434,  132],\n",
              "       [  44,  127,  669, ...,  189,   23,  662]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCyaS5wkJGoj",
        "outputId": "9d1d781e-002c-4598-9c35-47c753ea6fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "m_ndcg, m_recall, m_precision, map_k = evaluation(test_a, pred)\n",
        "print(f'nDCG: {m_ndcg:.5f}',\n",
        "      f'\\nRecall: {m_recall:.5f}',\n",
        "      f'\\nPrecision: {m_precision:.5f}',\n",
        "      f'\\nMAP: {map_k:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nDCG: 0.52839 \n",
            "Recall: 0.20607 \n",
            "Precision: 0.17194 \n",
            "MAP: 0.13966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RQJclIQcbyM"
      },
      "source": [
        "### 3. Mult-DAE"
      ]
    }
  ]
}